---
layout: post
title: "DETRì„ í™œìš©í•œ ê°ì±„ íƒì§€! íŒŒì´ì¬ ì‹¤ìŠµ!!"
author: [DrFirst]
date: 2025-05-08 07:00:00 +0900
categories: [AI, Experiment]
tags: [CVPR, CVPR 2020, Python, Detr, Object Detection, Huggingface,  detr-resnet-50]
lastmod : 2025-05-08 07:00:00
sitemap :
  changefreq : weekly
  priority : 0.9
---

## (English) Object Detection with DETR! Python Practice!!

> In the [previous post](https://drfirstlee.github.io/posts/DETR/) we studied DETR!!
> Today, based on this DETR model, we will directly perform Object Detection!

![detr_result](https://github.com/user-attachments/assets/cfb15e15-999d-4fc7-a1f2-5fa3f3f674bc)

- Let's start with the conclusion again!!!
- It finds and shows multiple detected objects in the image!!
- It accurately displays many people and frisbees, along with their accuracy!!
- Let's explore the process together with Python code!!

### 1. Loading the DETR model from Hugging Face!!

> Today's DETR model will be loaded from Hugging Face, using the `facebook/detr-resnet-50` model.

```python
import torch
import torchvision.transforms as T
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
from transformers import DetrImageProcessor, DetrForObjectDetection


# 1ï¸âƒ£ Set device (use CUDA if GPU is available)
device = "cuda" if torch.cuda.is_available() else "cpu"

# 2ï¸âƒ£ Load DETR model and processor (pretrained model)
model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50").to(device)
processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")
```

#### **processor** : ğŸ–¼ï¸ Image Processor (DetrImageProcessor)

**Role:** To **preprocess** the input image into a format that the DETR model can effectively understand and process.

**Main Tasks:**

1.  **Image Resizing:** Changes the size of the input image to a specific size required by the model.
2.  **Image Normalization:** Adjusts the pixel values of the image to a specific range to improve the stability of model training and inference.
3.  **Tensor Conversion:** Converts the image into a tensor format that can be used by deep learning frameworks such as PyTorch.
4.  **Handling Model-Specific Requirements:** Performs additional preprocessing tasks according to the model architecture (e.g., mask generation).

If we actually check the internal workings of the processor, we can see the preprocessing steps as below:

```text
DetrImageProcessor {
  "do_convert_annotations": true,
  "do_normalize": true,
  "do_pad": true,
  "do_rescale": true,
  "do_resize": true,
  "format": "coco_detection",
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "DetrImageProcessor",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "pad_size": null,
  "resample": 2,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 1333,
    "shortest_edge": 800
  }
}
```


#### **model** : ğŸ¤– DETR Object Detection Model (DetrForObjectDetection)

**Role:** To perform **object detection** on the preprocessed image and predict the location and class of objects within the image. This is the **core role**.

**Main Tasks:**

1.  **Feature Extraction:** Extracts important visual features for object detection from the input image.
2.  **Transformer Encoder-Decoder:** Processes the extracted features through the Transformer structure to understand the relationships between objects in the image and learn information about each object.
3.  **Object Prediction:** Finally outputs the **bounding box coordinates**, the corresponding **class labels**, and the **confidence scores** of the detected objects in the image.

The DETR model is structured as shown below:

![detr_model](https://github.com/user-attachments/assets/93a59c85-f6b3-484a-ab68-97360bcbda92)

#### 2. Starting Object Detection with DETR!

> It's done with just a few lines of simple code!!!

I have prepared an image above where several people are playing with a frisbee!
And then!

```python
import torch
import torchvision.transforms as T
from PIL import Image
from transformers import DetrImageProcessor, DetrForObjectDetection

# 1ï¸âƒ£ Set device (use CUDA if GPU is available)
device = "cuda" if torch.cuda.is_available() else "cpu"

# 2ï¸âƒ£ Load DETR model and processor (pretrained model)
model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50").to(device)
processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")

# 3ï¸âƒ£ Load the bike.jpg image from the local directory
image_path = "catch_frisbee.jpg"
image = Image.open(image_path)

# 4ï¸âƒ£ Preprocess the image (convert to DETR model input format)
inputs = processor(images=image, return_tensors="pt").to(device)

# 5ï¸âƒ£ Model inference
with torch.no_grad():
    outputs = model(**inputs)

# 6ï¸âƒ£ Post-process the results (convert Bounding Box & Labels)
target_sizes = torch.tensor([image.size[::-1]])  # (height, width) format
results = processor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]

# 7ï¸âƒ£ Output detected objects
for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
    if score > 0.7:  # Output objects with confidence above 70%
        box = [round(i, 2) for i in box.tolist()]
        print(f"Detected {model.config.id2label[label.item()]} with confidence {round(score.item(), 3)} at {box}")

```

If we briefly analyze the code above:
- It loads the model.
- It loads the `catch_frisbee` image!
- It preprocesses it through the `processor`.
- It puts it into the `model` and performs inference!
- It prints the detected content from `results`!

Then the output is!
As shown below! It tells us the detected objects, their accuracy (confidence), and finally the bounding box coordinates!


```text
Detected person with confidence 0.783 at [12.91, 355.33, 32.23, 383.66]
Detected person with confidence 0.999 at [279.08, 255.76, 365.66, 423.82]
Detected person with confidence 0.995 at [533.57, 280.23, 584.71, 401.82]
Detected umbrella with confidence 0.744 at [459.41, 324.56, 496.24, 340.89]
Detected person with confidence 0.933 at [488.93, 340.06, 510.23, 376.37]
Detected person with confidence 0.835 at [0.01, 355.79, 11.03, 384.31]
Detected person with confidence 0.906 at [261.05, 346.35, 284.02, 378.22]
Detected person with confidence 0.99 at [574.15, 301.1, 605.79, 395.45]
Detected person with confidence 0.713 at [244.5, 349.68, 262.29, 378.9]
Detected person with confidence 0.997 at [132.21, 31.6, 310.32, 329.97]
Detected person with confidence 0.732 at [349.66, 352.63, 365.67, 378.28]
Detected person with confidence 0.796 at [209.17, 326.9, 232.89, 355.65]
Detected person with confidence 0.777 at [149.0, 347.84, 169.28, 381.43]
Detected person with confidence 0.991 at [163.45, 299.99, 206.14, 399.0]
Detected frisbee with confidence 1.0 at [181.55, 139.33, 225.96, 161.49]
Detected person with confidence 0.734 at [200.95, 350.37, 229.14, 380.88]
Detected person with confidence 0.737 at [467.46, 347.11, 483.07, 376.49]
Detected person with confidence 0.978 at [413.58, 253.38, 465.11, 416.57]
Detected person with confidence 0.73 at [597.38, 342.37, 613.34, 380.89]
Detected person with confidence 0.998 at [304.64, 70.92, 538.5, 410.45]
```

#### 3. Visualization of Object Detection Results!! (Decoding)

> Instead of simple text detection, let's display bounding boxes on the image!

```python
import torch
import torchvision.transforms as T
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
from transformers import DetrImageProcessor, DetrForObjectDetection


# 1ï¸âƒ£ Set device (use CUDA if GPU is available)
device = "cuda" if torch.cuda.is_available() else "cpu"

# 2ï¸âƒ£ Load DETR model and processor (pretrained model)
model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50").to(device)
processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")

# 3ï¸âƒ£ Load the bike.jpg image from the local directory
image_path = "catch_frisbee.jpg"
image = Image.open(image_path)

# 4ï¸âƒ£ Preprocess the image (convert to DETR model input format)
inputs = processor(images=image, return_tensors="pt").to(device)

# 5ï¸âƒ£ Model inference
with torch.no_grad():
    outputs = model(**inputs)

# 6ï¸âƒ£ Post-process the results (convert Bounding Box & Labels)
target_sizes = torch.tensor([image.size[::-1]])  # (height, width) format
results = processor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]


# 7ï¸âƒ£ Visualize detected objects with Bounding Boxes on the image
fig, ax = plt.subplots(1, figsize=(10, 6))
ax.imshow(image)

# Draw Bounding Boxes
for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
    if score > 0.7:  # ğŸ”¹ Visualize objects with confidence above 70%
        box = [round(i, 2) for i in box.tolist()]
        x, y, w, h = box
        rect = patches.Rectangle((x, y), w - x, h - y, linewidth=2, edgecolor='r', facecolor='none')
        ax.add_patch(rect)
        ax.text(x, y, f"{model.config.id2label[label.item()]}: {round(score.item(), 2)}",
                fontsize=12, bbox=dict(facecolor='yellow', alpha=0.5))

# 8ï¸âƒ£ Save the result
output_path = "detr_output.jpg"  # ğŸ”¹ Filename to save
plt.axis("off")  # ğŸ”¹ Remove axes
plt.savefig(output_path, bbox_inches="tight")
plt.show()

print(f"Detection result saved as {output_path}")
```
Through the code above,   
The detected objects are visualized,   
And saved as `detr_output.jpg`!!  

![detr_model](https://github.com/user-attachments/assets/93a59c85-f6b3-484a-ab68-97360bcbda92)

Object detection, it's really easy, right?  
However, it takes 8.5 seconds to detect objects in a single image... it's still a bit slow!  

---

## (í•œêµ­ì–´) DETRì„ í™œìš©í•œ ê°ì±„ íƒì§€! íŒŒì´ì¬ ì‹¤ìŠµ!!

> [ì§€ë‚œ í¬ìŠ¤íŒ…](https://drfirstlee.github.io/posts/DETR/) ì—ì„œ ê³µë¶€í•´ë³´ì•˜ë˜ DETR!!  
> ì˜¤ëŠ˜ì€ ì´ DETR ëª¨ë¸ì„ ë°”íƒ•ìœ¼ë¡œ ì§ì ‘ ê°ì±„ íƒì§€(Object Detection)ì„ ì§„í–‰í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤~!   

![detr_result](https://github.com/user-attachments/assets/cfb15e15-999d-4fc7-a1f2-5fa3f3f674bc)

- ì˜¤ëŠ˜ë„ë„ ê²°ë¡ ë¶€í„°!!!  
- ì´ë¯¸ì§€ì—ì„œ íƒì§€ëœ ì—¬ëŸ¬ ê°ì±„ë“¤ì„ ì°¾ì•„ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤!!  
- ë§ì€ ì‚¬ëŒë“¤ê³¼ í”„ë¦¬ìŠ¤ë¹„ ë“± ê°ì±„ë¥¼ ì •í™•ë„ì™€ í•¨ê»˜ ë³´ì—¬ì¤ë‹ˆë‹¤!!   
- í•¨ê»˜, íŒŒì´ì¬ ì½”ë“œë¡œ ê·¸ ê³¼ì •ì„ ì•Œì•„ë³´ì•„ìš”!!  

### 1. huggingfaceì—ì„œ DETR ëª¨ë¸ ë°›ê¸°!!

> ì˜¤ëŠ˜ì˜ DETR ëª¨ë¸ì€  Huggingfaceë¡œë¶€í„°, `facebook/detr-resnet-50` ëª¨ë¸ì„ ë°›ì•„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤.

```python
import torch
import torchvision.transforms as T
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
from transformers import DetrImageProcessor, DetrForObjectDetection


# 1ï¸âƒ£ ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ CUDAë¡œ ì„¤ì •)
device = "cuda" if torch.cuda.is_available() else "cpu"

# 2ï¸âƒ£ DETR ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸)
model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50").to(device)
processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")

```

ìœ„ ì½”ë“œë¥¼ ë³´ë©´, ì‚¬ì „ í•™ìŠµëœ `facebook/detr-resnet-50`ì˜ Modelê³¼ Processor ë¥¼ ë¡œë“œí•˜ëŠ”ë°ìš”~!  
ê°ê°ì˜ ì—­í• ì„ ì•Œì•„ë³´ìë©´!  

#### **processor** : ğŸ–¼ï¸ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ (DetrImageProcessor)

**ì—­í• :** ì…ë ¥ ì´ë¯¸ì§€ë¥¼ DETR ëª¨ë¸ì´ íš¨ê³¼ì ìœ¼ë¡œ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ **ì „ì²˜ë¦¬(Preprocessing)**í•˜ëŠ” ì—­í• 

**ì£¼ìš” ì‘ì—…:**

1.  **ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (Resizing):** ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” íŠ¹ì • í¬ê¸°ë¡œ ë³€ê²½  
2.  **ì´ë¯¸ì§€ ì •ê·œí™” (Normalization):** ì´ë¯¸ì§€ í”½ì…€ ê°’ì„ íŠ¹ì • ë²”ìœ„ë¡œ ì¡°ì •í•˜ì—¬ ëª¨ë¸ í•™ìŠµ ë° ì¶”ë¡  ì•ˆì •ì„± í–¥ìƒ  
3.  **í…ì„œ ë³€í™˜ (Tensor Conversion):** ì´ë¯¸ì§€ë¥¼ íŒŒì´í† ì¹˜(PyTorch)ì™€ ê°™ì€ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í…ì„œ(Tensor) í˜•íƒœ ë³€í™˜  
4.  **ëª¨ë¸ë³„ ìš”êµ¬ ì‚¬í•­ ì²˜ë¦¬:** ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ë”°ë¼ ì¶”ê°€ì ì¸ ì „ì²˜ë¦¬ ì‘ì—… (ì˜ˆ: ë§ˆìŠ¤í¬ ìƒì„± ë“±)ì„ ìˆ˜í–‰  

ì‹¤ì œë¡œ processor ë¥¼ ë‚´ë¶€ë¥¼ í™•ì¸í•´ë³´ë©´ ì•„ë˜ì™€ ê°™ì´ ì „ì²˜ë¦¬ ê³¼ì •ì„ ë³¼ìˆ˜ ìˆìŠµë‹ˆë‹¤~  

```text
DetrImageProcessor {
  "do_convert_annotations": true,
  "do_normalize": true,
  "do_pad": true,
  "do_rescale": true,
  "do_resize": true,
  "format": "coco_detection",
  "image_mean": [
    0.485,
    0.456,
    0.406
  ],
  "image_processor_type": "DetrImageProcessor",
  "image_std": [
    0.229,
    0.224,
    0.225
  ],
  "pad_size": null,
  "resample": 2,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 1333,
    "shortest_edge": 800
  }
}
```

#### **model** : ğŸ¤– DETR ê°ì²´ ê°ì§€ ëª¨ë¸ (DetrForObjectDetection)

**ì—­í• :** ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ì´ë¯¸ì§€ ë‚´ì˜ **ê°ì²´ë¥¼ ê°ì§€(Object Detection)**í•˜ê³ , í•´ë‹¹ ê°ì²´ì˜ ìœ„ì¹˜ì™€ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” **í•µì‹¬ì ì¸ ì—­í• ** ìˆ˜í–‰  

**ì£¼ìš” ì‘ì—…:**

1.  **ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ (Feature Extraction):** ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ ê°ì§€ì— ì¤‘ìš”í•œ ì‹œê°ì  íŠ¹ì§•ë“¤ì„ ì¶”ì¶œ  
2.  **íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”-ë””ì½”ë” (Transformer Encoder-Decoder):** ì¶”ì¶œëœ íŠ¹ì§•ë“¤ì„ íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°ë¥¼ í†µí•´ ì²˜ë¦¬í•˜ì—¬ ì´ë¯¸ì§€ ë‚´ ê°ì²´ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ê³ , ê° ê°ì²´ì˜ ì •ë³´ë¥¼ í•™ìŠµ  
3.  **ê°ì²´ ì˜ˆì¸¡ (Object Prediction):** ìµœì¢…ì ìœ¼ë¡œ ì´ë¯¸ì§€ ë‚´ì— ì¡´ì¬í•˜ëŠ” ê°ì²´ë“¤ì˜ **ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ**, í•´ë‹¹ ê°ì²´ì˜ **í´ë˜ìŠ¤ ë ˆì´ë¸”**, ê·¸ë¦¬ê³  ì˜ˆì¸¡ì˜ **ì‹ ë¢°ë„ ì ìˆ˜** ì¶œë ¥

ì•„ë˜ì™€ ê°™ì´ DETRìœ¼ ëª¨ë¸ë¡œ êµ¬ì„±ë¨ì„ ë³¼ìˆ˜ ìˆìŠµë‹ˆë‹¤!!

![detr_model](https://github.com/user-attachments/assets/93a59c85-f6b3-484a-ab68-97360bcbda92)


#### 2. DETRë¡œ ê°ì±„íƒì§€ ì‹œì‘!  

> ê°„ë‹¨í•œ ì½”ë“œ ëª‡ì¤„ì´ë©´ ë!!!

![Image](https://github.com/user-attachments/assets/71d72287-c14f-4d54-9fe9-4401a7fa4e1c) 

ìœ„ì™€ ê°™ì´ ì—¬ëŸ¬ì‚¬ëŒë“¤ì´ í”„ë¦¬ìŠ¤ë¹„ë¡œ ë†€ê³ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ì¤€ë¹„í•´ë³´ì•˜ìŠµë‹ˆë‹¤!!
ê·¸ë¦¬ê³ @!  

```python
import torch
import torchvision.transforms as T
from PIL import Image
from transformers import DetrImageProcessor, DetrForObjectDetection

# 1ï¸âƒ£ ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ CUDAë¡œ ì„¤ì •)
device = "cuda" if torch.cuda.is_available() else "cpu"

# 2ï¸âƒ£ DETR ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸)
model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50").to(device)
processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")

# 3ï¸âƒ£ ë¡œì»¬ ë””ë ‰í† ë¦¬ì˜ bike.jpg ì´ë¯¸ì§€ ë¡œë“œ
image_path = "catch_frisbee.jpg"
image = Image.open(image_path)

# 4ï¸âƒ£ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (DETR ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜)
inputs = processor(images=image, return_tensors="pt").to(device)

# 5ï¸âƒ£ ëª¨ë¸ ì¶”ë¡ 
with torch.no_grad():
    outputs = model(**inputs)

# 6ï¸âƒ£ ê²°ê³¼ í›„ì²˜ë¦¬ (Bounding Box & Labels ë³€í™˜)
target_sizes = torch.tensor([image.size[::-1]])  # (height, width) í˜•ì‹
results = processor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]

# 7ï¸âƒ£ ê°ì§€ëœ ê°ì²´ ì¶œë ¥
for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
    if score > 0.7:  # ì‹ ë¢°ë„ 70% ì´ìƒì¸ ê°ì²´ë§Œ ì¶œë ¥
        box = [round(i, 2) for i in box.tolist()]
        print(f"Detected {model.config.id2label[label.item()]} with confidence {round(score.item(), 3)} at {box}")

```

ìœ„ì˜ ì½”ë“œë¥¼ ê°„ë‹¨í•˜ê²Œ ë¶„ì„í•´ë³´ë©´,  
- ëª¨ë¸ì„ ë¡œë“œí•˜ê³   
- `catch_frisbee` ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³ !  
- `processor` ë¥¼ í†µí•´ ì „ì²˜ë¦¬í•˜ê³ ,  
- `model`ì— ë„£ì–´ì„œ!! ì¶”ë¡ í•œ ë’¤.  
- `results` ì—ì„œ íƒì§€ëœ ë‚´ìš© print í•˜ê¸°!!

ê·¸ëŸ¼ ê·¸ outputì€!!  
ì•„ë˜ì™€ ê°™ì´!! íƒì§€ëœ ê°ì±„ì™€, ê·¸ ì •í™•ë„(confidence), ë§ˆì§€ë§‰ìœ¼ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤@!

```text
Detected person with confidence 0.783 at [12.91, 355.33, 32.23, 383.66]
Detected person with confidence 0.999 at [279.08, 255.76, 365.66, 423.82]
Detected person with confidence 0.995 at [533.57, 280.23, 584.71, 401.82]
Detected umbrella with confidence 0.744 at [459.41, 324.56, 496.24, 340.89]
Detected person with confidence 0.933 at [488.93, 340.06, 510.23, 376.37]
Detected person with confidence 0.835 at [0.01, 355.79, 11.03, 384.31]
Detected person with confidence 0.906 at [261.05, 346.35, 284.02, 378.22]
Detected person with confidence 0.99 at [574.15, 301.1, 605.79, 395.45]
Detected person with confidence 0.713 at [244.5, 349.68, 262.29, 378.9]
Detected person with confidence 0.997 at [132.21, 31.6, 310.32, 329.97]
Detected person with confidence 0.732 at [349.66, 352.63, 365.67, 378.28]
Detected person with confidence 0.796 at [209.17, 326.9, 232.89, 355.65]
Detected person with confidence 0.777 at [149.0, 347.84, 169.28, 381.43]
Detected person with confidence 0.991 at [163.45, 299.99, 206.14, 399.0]
Detected frisbee with confidence 1.0 at [181.55, 139.33, 225.96, 161.49]
Detected person with confidence 0.734 at [200.95, 350.37, 229.14, 380.88]
Detected person with confidence 0.737 at [467.46, 347.11, 483.07, 376.49]
Detected person with confidence 0.978 at [413.58, 253.38, 465.11, 416.57]
Detected person with confidence 0.73 at [597.38, 342.37, 613.34, 380.89]
Detected person with confidence 0.998 at [304.64, 70.92, 538.5, 410.45]
```

#### 3. ê°ì±„ íƒì§€ê²°ê³¼ë¬¼ì˜ ì‹œê°í™”!!(ë””ì½”ë”©)   

> ë‹¨ìˆœ í…ìŠ¤íŠ¸ íƒì§€ê°€ ì•„ë‹ˆë¼ ê·¸ë¦¼ì— ë°”ìš´ë”©ë°•ìŠ¤ë¡œ í‘œì‹œí•´ë´…ë‹ˆë‹¤!@  

```python
import torch
import torchvision.transforms as T
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
from transformers import DetrImageProcessor, DetrForObjectDetection


# 1ï¸âƒ£ ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ CUDAë¡œ ì„¤ì •)
device = "cuda" if torch.cuda.is_available() else "cpu"

# 2ï¸âƒ£ DETR ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸)
model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50").to(device)
processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")

# 3ï¸âƒ£ ë¡œì»¬ ë””ë ‰í† ë¦¬ì˜ bike.jpg ì´ë¯¸ì§€ ë¡œë“œ
image_path = "catch_frisbee.jpg"
image = Image.open(image_path)

# 4ï¸âƒ£ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (DETR ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜)
inputs = processor(images=image, return_tensors="pt").to(device)

# 5ï¸âƒ£ ëª¨ë¸ ì¶”ë¡ 
with torch.no_grad():
    outputs = model(**inputs)

# 6ï¸âƒ£ ê²°ê³¼ í›„ì²˜ë¦¬ (Bounding Box & Labels ë³€í™˜)
target_sizes = torch.tensor([image.size[::-1]])  # (height, width) í˜•ì‹
results = processor.post_process_object_detection(outputs, target_sizes=target_sizes)[0]


# 7ï¸âƒ£ ê°ì§€ëœ ê°ì²´ë¥¼ ì´ë¯¸ì§€ì— Bounding Boxë¡œ ì‹œê°í™”
fig, ax = plt.subplots(1, figsize=(10, 6))
ax.imshow(image)

# Bounding Box ê·¸ë¦¬ê¸°
for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
    if score > 0.7:  # ğŸ”¹ ì‹ ë¢°ë„ 70% ì´ìƒì¸ ê°ì²´ë§Œ ì‹œê°í™”
        box = [round(i, 2) for i in box.tolist()]
        x, y, w, h = box
        rect = patches.Rectangle((x, y), w-x, h-y, linewidth=2, edgecolor='r', facecolor='none')
        ax.add_patch(rect)
        ax.text(x, y, f"{model.config.id2label[label.item()]}: {round(score.item(), 2)}",
                fontsize=12, bbox=dict(facecolor='yellow', alpha=0.5))

# 8ï¸âƒ£ ê²°ê³¼ ì €ì¥
output_path = "detr_output.jpg"  # ğŸ”¹ ì €ì¥í•  íŒŒì¼ëª…
plt.axis("off")  # ğŸ”¹ ì¶• ì œê±°
plt.savefig(output_path, bbox_inches="tight")
plt.show()

print(f"Detection result saved as {output_path}")

```

ìœ„ ì½”ë“œë¥¼ í†µí•˜ì—¬,  
ê°ì§€ëœ ê°ì±„ë¥¼ ì‹œê°í™”í•˜ê³   
`detr_output.jpg` ë¡œë„ ì €ì¥í•˜ê²Œë©ë‹ˆë‹¤~!!  

![detr_model](https://github.com/user-attachments/assets/93a59c85-f6b3-484a-ab68-97360bcbda92)


ê°ì±„ íƒì§€, ì°¸ ì‰½ì£ ~?  
ë‹¤ë§Œ, 1ê°œ ì´ë¯¸ì§€ì—ì„œ ê°ì±„ íƒì§€ì— ì‹œê°„ì´ 8.5ì´ˆê°€ ì†Œìš”,, ì—­ì‹œ ì¢€ ì˜¤ë˜ê±¸ë¦¬ë„¤ìš”!  
