---
layout: post
title: "DETR(DEtection TRansformer) 연구 정리 및 분석"
author: [DrFirst]
date: 2025-05-07 09:00:00 +0900
categories: [Research, Deep Learning, Computer Vision]
tags: [DETR, Object Detection, Transformer, 딥러닝, CV]
lastmod : 2025-05-07 09:00:00
sitemap :
  changefreq : monthly
  priority : 0.9
---

## 📌 DETR란 무엇인가?

**DETR (DEtection TRansformer)**는 Facebook AI에서 2020년에 발표한 객체 탐지 모델로,  
기존 CNN 기반의 탐지기와 달리 **Transformer를 사용한 최초의 객체 탐지 모델**입니다.

> 논문: [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)  
> 발표: CVPR 2020  
> 코드: [facebookresearch/detectron2](https://github.com/facebookresearch/detectron2)

---

## 🔍 기존 객체 탐지 방식의 한계

- **Anchor Box 설계**: 수동 튜닝 필요
- **복잡한 후처리**: Non-Maximum Suppression(NMS)
- **모듈 분리 구조**: End-to-End 학습이 어려움
- **Region Proposal** 필요

이러한 문제점들은 DETR가 등장하게 된 계기이자 배경입니다.

---

## 🧠 DETR의 핵심 아이디어

DETR는 객체 탐지를 **sequence prediction 문제**로 바꾸어 Transformer를 적용합니다.

- **Backbone**: ResNet 등 CNN 사용
- **Transformer Encoder-Decoder** 구조
- **Object Query**: 예측할 객체 개수만큼 learnable query 사용
- **Hungarian Matching**: ground truth와 예측 결과를 일대일 대응
- **Post-processing 없음**: NMS 없이 end-to-end로 학습

$$$
Input Image 
 → CNN Backbone (e.g., ResNet)
   → Transformer Encoder-Decoder
     → Object Query Set
       → Predictions {Class, Bounding Box}₁~ₙ
$$$

---

## ✅ DETR의 장점

- ✅ **완전한 End-to-End 학습 구조**
- 🧹 **Anchor-Free & NMS-Free**
- 💬 **Transformer의 글로벌 컨텍스트 활용**
- 🎯 **직관적인 구조**

---

## ⚠️ DETR의 한계

- 🐢 **수렴 속도 매우 느림** (학습 시간이 수십만 스텝 필요)
- 📏 **작은 객체 탐지 성능 저하**
- 🧠 **Transformer 연산량 문제** (고해상도 이미지 처리 어려움)

---

## 🔁 후속 연구 흐름

| 모델 | 발표 | 특징 |
|------|------|------|
| **Deformable DETR** | 2020 | Multi-scale + Sparse Attention |
| **Conditional DETR** | 2021 | Query 초기화 개선 |
| **DN-DETR** | 2022 | DeNoising Query 도입 |
| **DINO** | 2022 | 수렴속도 향상 + 성능 향상 |
| **DINOv2** | 2023~ | ViT 백본 + Pretraining 강화 |

---

## 🔄 DETR와 ViT 관계

- ViT(Vision Transformer)는 DETR 이후 발표됨 (2020.10)
- DETR는 **Transformer를 vision에 적용한 최초의 시도 중 하나**  
- ViT 등장 이후 DETR 계열에 ViT를 backbone으로 사용하는 모델들이 등장 (예: DINOv2)

---

## 💬 정리 및 개인 의견

DETR는 객체 탐지를 Transformer 기반의 **End-to-End 학습 문제로 재정의**한 점에서 큰 의미가 있습니다.  
초기 버전은 실용적 한계가 있었지만, 후속 연구들을 통해 빠르게 발전해  
**Transformer 기반 Object Detection의 대표 계열**로 자리 잡았습니다.

---

## 🔗 참고 링크

- 논문: https://arxiv.org/abs/2005.12872  
- 블로그 리뷰: https://huggingface.co/blog/detr  
- 후속 모델 소개: https://github.com/IDEACVR/DINO  
- DETR 공식 코드: https://github.com/facebookresearch/detectron2

---
