---
layout: post
title: "ğŸ–¥ï¸ Video segmentation with Python using SAM2! - íŒŒì´ì¬ SAM2 ì‹¤ìŠµ : ë¹„ë””ì˜¤ì—ì„œ ëˆ„ë¼ë”°ê¸°!"
author: [DrFirst]
date: 2025-05-29 09:00:00 +0900
categories: [AI, Experiment]
tags: [SAM2, Segment Anything, Video Segmentation, Python]
sitemap :
  changefreq : weekly
  priority : 0.9
---

---

## ğŸ¦–(ENGLISH) Python SAM2 Practice: Background Removal from Video!

In this post, weâ€™ll walk through a practical use case of **SAM2**, the successor to Metaâ€™s Segment Anything Model (SAM).  
SAM2 is already supported by the popular `ultralytics` library, making it incredibly simple to use!  
That means â€” anyone can try it, easily and quickly! ğŸš€

---

### ğŸ§± 1. Installing `ultralytics`

- Already installed? Then skip this step!

```bash
pip install ultralytics
```

---

### ğŸ“¦ 2. Download & Load the Model

```bash
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

# Load the SAM2 model
model = SAM("sam2.1_b.pt")
```

We also loaded a few additional packages for visualization.

---

### ğŸ§Š 3. Run Image Segmentation!

Letâ€™s segment a dog image using a bounding box prompt:

```python
img_name = "dog.jpg"

my_bboxes = [1430.2, 828, 4471.9, 3836.4]
# Run inference with a box prompt [x_min, y_min, x_max, y_max]
results = model(img_name, bboxes=my_bboxes)

# Load the original image (for visualization)
image = cv2.imread(img_name)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Show results
plt.figure(figsize=(10, 10))
plt.imshow(image_rgb)

# Overlay mask
for result in results:
    if result.masks is not None:
        mask = result.masks.data[0].cpu().numpy()
        plt.imshow(mask, alpha=0.5, cmap='jet')

# Draw bounding box
rect = plt.Rectangle((my_bboxes[0], my_bboxes[1]), my_bboxes[2] - my_bboxes[0], my_bboxes[3] - my_bboxes[1],
                     linewidth=2, edgecolor='red', facecolor='none', label=f'my_bboxes {my_bboxes}')
plt.gca().add_patch(rect)

# Final touches
plt.title(f"SAM2 Segmentation with Box Prompt on {img_name}")
plt.legend()
plt.axis('off')
plt.show()

# Optional: Print extra info
print("Segmentation Result:")
print(f"Number of masks: {len(results[0].masks.data)}")
print(f"Mask shape: {results[0].masks.data[0].shape}")
```

![sam2_dog](https://github.com/user-attachments/assets/9b4db05e-2577-4832-88c8-47ca66e21b82)

Pretty impressive, right?  
But to be fair â€” this is something even SAM1 handled quite well ğŸ˜

---

### ğŸš€ 4. Run Video Segmentation!

Now letâ€™s try something SAM1 couldnâ€™t do: **video segmentation** â€” a core strength of SAM2!

I used a highway CCTV video and provided a single point prompt at (405, 205) in the first frame where a car is visible:

```python
from ultralytics.models.sam import SAM2VideoPredictor

# Create SAM2VideoPredictor
overrides = dict(conf=0.25, task="segment", mode="predict", imgsz=1024, model="sam2_b.pt")
predictor = SAM2VideoPredictor(overrides=overrides)

# Run inference with a single point
results = predictor(source="street.mp4", points=[405, 205], labels=[1])
```

I canâ€™t upload videos here, but as shown in the screenshots below,  
**SAM2 was able to segment the car only while it was visible â€” and stopped at the right moment**. Very smart!

![Image](https://github.com/user-attachments/assets/4a6135fb-077e-4b69-a4e7-982911ad263d)  
![Image](https://github.com/user-attachments/assets/b908a14b-a65f-4a02-a52b-c088e736fbd7)  
![Image](https://github.com/user-attachments/assets/d6a5b11c-b152-4d2c-97b0-841f345d9d48)

---

### ğŸ‰ Final Thoughts

I was genuinely impressed not only by SAM2â€™s ability to segment in videos,  
but also by how well it **tracked objects over time with minimal input**.

Highly recommend trying this out â€” especially for any video segmentation tasks!

---

## ğŸ¦–(í•œêµ­ì–´) íŒŒì´ì¬ SAM2 ì‹¤ìŠµ : ë¹„ë””ì˜¤ì—ì„œ ëˆ„ë¼ë”°ê¸°!

ì´ë²ˆ í¬ìŠ¤íŒ…ì€ SAMì˜ í›„ì† ëª¨ë¸ì¸ **SAM2** ì‹¤ìŠµì…ë‹ˆë‹¤!  
SAM2ëŠ” ìœ ëª…í•œ ëª¨ë¸ì´ì–´ì„œ ê·¸ëŸ°ì§€, ultralytics ì˜ íŒ¨í‚¤ì§€ë¡œ ì‰½ê²Œ ì‚¬ìš©í• ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤!!
ê·¸ë˜ì„œ ëª¨ë‘ ê°„ë‹¨íˆ, ì‰½ê²Œ ì‚¬ìš©ê°€ëŠ¥í•©ë‹ˆë‹¤!!!

---

### ğŸ§± 1. ultralytics ì„¤ì¹˜  

- ì´ë¯¸ ì„¤ì¹˜ëœ ë¶„ì´ë¼ë©´ ìŠ¤í‚µì“°!  
```bash
pip install ultralytics
```

---

### ğŸ“¦ 2. ëª¨ë¸ ë‹¤ìš´ ë° ë¡œë“œ!

```bash
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

# ëª¨ë¸ ë¡œë“œ
model = SAM("sam2.1_b.pt")

```

ì‹œê°í™”ë¥¼ ìœ„í•´ ê·¸ì™¸ íŒ¨í‚¤ì§€ë„ ë¡œë“œí•´ì£¼ì—ˆìŠµë‹ˆë‹¤!

---

### ğŸ§Š 3. ì´ë¯¸ì§€ Segment ì‹¤í–‰!!

ê¸°ì¡´ ì‚¬ìš©í–ˆë˜ ê°•ì•„ì§€ ì´ë¯¸ì§€ë¥¼, bboxì™€ í•¨ê»˜ segmentí•´ë³´ì•˜ìŠµë‹ˆë‹¤!!

```python
img_name = "dog.jpg"

my_bboxes=[1430.2,   828,  4471.9, 3836.4]
# ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ë¡œ ì¶”ë¡  ([x_min, y_min, x_max, y_max])
results = model(img_name, bboxes=my_bboxes)

# ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ (ì‹œê°í™”ë¥¼ ìœ„í•´)
image = cv2.imread(img_name)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR -> RGB ë³€í™˜

# ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(10, 10))
plt.imshow(image_rgb)

# ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
for result in results:
    if result.masks is not None:
        mask = result.masks.data[0].cpu().numpy()  # ì²« ë²ˆì§¸ ë§ˆìŠ¤í¬ ì¶”ì¶œ
        plt.imshow(mask, alpha=0.5, cmap='jet')  # ë§ˆìŠ¤í¬ë¥¼ ë°˜íˆ¬ëª…í•˜ê²Œ í‘œì‹œ

# ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
rect = plt.Rectangle((my_bboxes[0], my_bboxes[1]), my_bboxes[2] - my_bboxes[0], my_bboxes[3] - my_bboxes[1], 
                     linewidth=2, edgecolor='red', facecolor='none', label=f'my_bboxes {my_bboxes}')
plt.gca().add_patch(rect)

# ì œëª© ë° ì„¤ì •
plt.title(f"SAM2 Segmentation with Box Prompt on {img_name}")
plt.legend()
plt.axis('off')
plt.show()

# ì¶”ê°€ ì •ë³´ ì¶œë ¥ (ì„ íƒ ì‚¬í•­)
print("Segmentation Result:")
print(f"Number of masks: {len(results[0].masks.data)}")
print(f"Mask shape: {results[0].masks.data[0].shape}")
```

![sam2_dog](https://github.com/user-attachments/assets/9b4db05e-2577-4832-88c8-47ca66e21b82)


ì°¸ ì˜ë˜ì£ ~ ê·¸ëŸ°ë° ì´ê±´ SAMë„ ì˜í•˜ê±´ê±´ë°!?

---

### ğŸš€ 4. ë¹„ë””ì˜¤ Segment ì‹¤í–‰!!

ê·¸ë˜ì„œ, ì´ë²ˆì—” SAM2ì˜ íŠ¹ì§•ì¸!  
ë¹„ë””ì˜¤ì˜ segmentë„ ì§„í–‰í•´ë³´ì•˜ìŠµë‹ˆë‹¤!

ì €ëŠ” ê³ ì†ë„ë¡œì˜ CCTVì˜ìƒì„ ë°”íƒ•ìœ¼ë¡œ ì§„í–‰í–ˆêµ¬ìš”!
ì²« í”„ë˜ì„ì—ì„œ ì°¨ê°€ ìˆëŠ” ê³³ì˜ ìœ„ì¹˜(405,205)ë¥¼ í”„ë¡¬í¬íŠ¸ë¡œ ì œê³µí–ˆìŠµë‹ˆë‹¤!

```python
from ultralytics.models.sam import SAM2VideoPredictor

# Create SAM2VideoPredictor
overrides = dict(conf=0.25, task="segment", mode="predict", imgsz=1024, model="sam2_b.pt")
predictor = SAM2VideoPredictor(overrides=overrides)

# Run inference with single point
results = predictor(source="street.mp4", points=[405, 205], labels=[1])
```

ë™ì˜ìƒì„ ì˜¬ë¦´ìˆœ ì—†ì§€ë§Œ!!  
ì•„ë˜ ìŠ¤í¬ë¦°ìƒ·ê°™ì´ ì°¨ê°€ ì‚¬ë¼ì§€ëŠ” ì‹œì ê¹Œì§€ë§Œ ë”±!!segmentë¥¼ ì •ë§ ì˜í•˜ë”ë¼êµ¬ìš”!!

![Image](https://github.com/user-attachments/assets/4a6135fb-077e-4b69-a4e7-982911ad263d)
![Image](https://github.com/user-attachments/assets/b908a14b-a65f-4a02-a52b-c088e736fbd7)
![Image](https://github.com/user-attachments/assets/d6a5b11c-b152-4d2c-97b0-841f345d9d48)

---

### ğŸ‰ ë§ˆë¬´ë¦¬

ë™ì˜ìƒì˜ segmentationì— ë”í•˜ì—¬, ì €ëŠ” Trackingì´ ì´ë ‡ê²Œ ì˜ëœë‹¤ëŠ”ê²ƒì´ ë„ˆë¬´ ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤!