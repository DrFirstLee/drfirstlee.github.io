---
layout: post
title: "ğŸ” WSAG-PLSP: Weakly Supervised í•™ìŠµì„ í†µí•œ Affordance Grounding ë¬¸ì œí•´ê²°!"
author: [DrFirst]
date: 2025-07-09 09:00:00 +0900
categories: [AI, Research]
tags: [Computer Vision, Affordance, Weakly-Supervised, PLSP, ICLR 2025, ICLR]
sitemap:
  changefreq: monthly
  priority: 0.8
---

### ğŸ” (í•œêµ­ì–´) WSAG-PLSP: Part-Level Semantic Propagationìœ¼ë¡œ Affordance Grounding ë¬¸ì œ í•´ê²°!  

![Image](https://github.com/user-attachments/assets/5b47a9aa-1b92-4bc4-a649-6dc551f8bc12)

* **ì œëª©**: [ WSAG-PLSP: Part-Level Semantic Propagation for Weakly Supervised Affordance Grounding](https://openreview.net/pdf?id=0823rvTIhs)  
* **í•™íšŒ**: ICLR 2025  
* **ì½”ë“œ/ì²´í¬í¬ì¸íŠ¸**: [GitHub â€“ WSAG-PLSP](https://github.com/woyut/WSAG-PLSP)    
* **ì €ì**: Peiran Xu, Yadong Mu(Peking University)  
* **í•µì‹¬ í‚¤ì›Œë“œ**: `Affordance`, `Weakly-Supervised`, `Part-Level`, `Semantic Propagation`, `Vision-Language`   
* **ìš”ì•½**: WSAG-PLSPëŠ” **ì´ë¯¸ì§€ ìˆ˜ì¤€ ë¼ë²¨ë§Œ ì´ìš©**í•´ affordanceë¥¼ í•™ìŠµí•˜ëŠ” **Weakly Supervised Affordance Grounding (WSAG)** ë¬¸ì œì—ì„œ, **ë¶€ìœ„ ë‹¨ìœ„(Part-Level) ì˜ë¯¸ ì „íŒŒ(PLSP)**ë¥¼ í†µí•´ affordance ìœ„ì¹˜ë¥¼ ë”ìš± ì •ë°€í•˜ê²Œ ì°¾ì•„ë‚´ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆ. AGD20K, UMD, IIT-AFF ë“± ë°ì´í„°ì…‹ì—ì„œ SOTA ì„±ëŠ¥ ë‹¬ì„± ğŸš€  

---

### ğŸš€ ì—°êµ¬ í•µì‹¬ ìš”ì•½

> í•œ ì¤„ ìš”ì•½: **â€œWSAG-PLSP = Pseudo labelì„ ë§Œë“¤ê³  í•œë²ˆ ë” ì •ì œí•˜ë©°, Exo ì´ë¯¸ì§€ì™€ í•¨ê»˜ Transformerë¡œ supervised í•˜ê²Œ í•™ìŠµì‹œí‚¨ë‹¤!â€**  

![Image](https://github.com/user-attachments/assets/a4a011d4-fcdb-49ec-9f27-383e6e92e256)

1) **ìƒˆ ê³¼ì œ ë°°ê²½ (WSAG)**  
- Weakly Supervised Affordance Grounding: í”½ì…€ ë‹¨ìœ„ ë ˆì´ë¸” ì—†ì´ affordance ì§€ì—­(localization) í•™ìŠµ  
- ê¸°ì¡´ CAM ê¸°ë°˜ ì ‘ê·¼ì€ ë‹¨ìˆœ ë¶€ë¶„ ê°•ì¡°ì— ê·¸ì³ affordanceê°€ í˜•ì„±ë˜ëŠ” **ì„¸ë¶€ ë¶€ìœ„ ê°„ ì˜ë¯¸ ê´€ê³„**ë¥¼ í¬ì°©í•˜ì§€ ëª»í•¨  

2) **WSAG-PLSP ë°©ë²•ë¡ **  
â‘  Pseudo Label ë§Œë“¤ê¸° :  ì‘ì—…ëœ object part prompt(p) ë¥¼ VLpart + SAMì„ í†µí•´ Labelë¡œ ì œì‘  
â‘¡ Refine Label : exoì˜ ê²¹ì¹¨í˜„ìƒì´ ë°œìƒí•˜ëŠ” ê°œë…ì—ì„œ ì°©ì•ˆ, ì¼ë¶€ëŠ”  Pretrained Label ì œì‘  
â‘¢ Supervised Baseline : Cross modal fuser(transformer) êµ¬ì¡°ë¡œ Labelì„ í•™ìŠµ  
â‘£ Exo ì´ë¯¸ì§€ í™œìš©: ê°€ì¥ ìœ ì‚¬í•œ 1ê°œ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ Align  
  

3) **ìµœì¢… ì¶œë ¥**  
- affordance heatmap (í”½ì…€ ë‹¨ìœ„)  
- objectë³„ affordance presence score  

---

### ğŸ” ê¸°ì¡´ì˜ ê´€ë ¨ ì—°êµ¬ë“¤!    

1. Affordance ë¼ëŠ” ê°œë…ì˜ ë“±ì¥! : 1977ë…„, ì‹¬ë¦¬í•™ ê´€ì ì—ì„œ Gibsonì´ ì œì•ˆí•œ ê°œë…!!   
  - ìµœê·¼ì—ëŠ” ë¡œë´‡ì— ì ìš©í•œ AIë¡œì„œ ë§ì´ ì—°êµ¬ë¨!  

2. Fully supervised : ì´ˆê¸°ì—ëŠ” ì™„ì „ ì§€ë„í•™ìŠµìœ¼ë¡œ ì—°êµ¬!!  
  - ë†’ì€ ì„±ëŠ¥, í•˜ì§€ë§Œ ë¼ë²¨ë§ ë¹„ìš©Â·ì£¼ê´€ì„± ë¬¸ì œë¡œ í´ë˜ìŠ¤ ë‹¤ì–‘ì„± ë¶€ì¡± (Myers et al., 2015; Nguyen et al., 2017).

3. Weakly Supervised ê´€ì ì˜ ì—°êµ¬ë“¤ì´ ë“±ì¥í•¨: ì´ë¯¸ì§€ ìˆ˜ì¤€ ë¼ë²¨(+ exo-centricì´ë¯¸ì§€)ë§Œ ì œê³µí•˜ê³  ì˜ˆì¸¡í•˜ê¸°!  
  - ê¸°ì¡´ ë°©ë²•(CROSS-VIEW-AG, LOCATE, WSMA)ë“¤ì€ ëŒ€ë¶€ë¶„ CAM ê¸°ë°˜ìœ¼ë¡œ affordance ë¶„ë¥˜, ê·¸ëŸ°ë° CAMì€ ë‘ë“œëŸ¬ì§„ ë¶€ë¶„ë§Œ ê°•ì¡°í•´ affordance ì „ ì˜ì—­ í¬ì°©ì´ ì–´ë µë‹¤ëŠ” ë‹¨ì ì´ ì¡´ì¬.  
  - ë˜í•œ exocentric images í™œìš©ì—ì„œë„, ê¸°ì¡´ ë°©ì‹ë“¤ì€ ê¸€ë¡œë²Œ í’€ë§(CROSS-VIEW-AG)/ë§ˆìŠ¤í‚¹ í’€ë§(LOCATE) ë°©ì‹ì´ë¼ ë…¸ì´ì¦ˆ ìœ ì… ê°€ëŠ¥

4. **Visual Foundation Models (VFM)**ê³¼ **Multi-modal LLMs (MLLMs)**ì˜ ë°œì „  
  - SAM, CLIP, VL-partë“± ì—¬ë ¤ ì—°êµ¬ê°€ ìˆì–´ì™”ê³  ì„±ëŠ¥ë„ ì¢‹ë‹¤!  
  - ì´ë“¤ì„ í†µí•´ ì œë¡œìƒ·ìœ¼ë¡œ ê³ í’ˆì§ˆ dense annotation ê°€ëŠ¥  

(ì°¸ê³ ) ê° ì—°êµ¬ë³„ reference  
  - **CROSS-VIEW-AG** : Luo, Hongchen, et al. "Learning affordance grounding from exocentric images." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022.  
  - **LOCATE** : Li, Gen, et al. "Locate: Localize and transfer object parts for weakly supervised affordance grounding." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.  
  - **WSMA** : Xu, Lingjing, et al. "Weakly supervised multimodal affordance grounding for egocentric images." Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 6. 2024.


### ğŸ” ë³¸ ì—°êµ¬ì˜ ë°©ë²•ë¡ !!!    

#### 3.2 ëª¨ë¸ Architecture  

![Image](https://github.com/user-attachments/assets/9775df45-cc84-4d6f-9a7a-9d06e00e81e1)

- Enc_V : ì´ë¯¸ì§€ ì¸ì½”ë”©. ì´ë¯¸ì§€ Ië¥¼ ì¸ì½”ë”©í•˜ì—¬ F_Vë¡œ ë³€í™˜  
- Enc_T : í…ìŠ¤íŠ¸ ì¸ì½”ë”©. afforance query(a)ë¥¼ ë²¡í„° f_Të¡œ ë³€í™˜(CLIPê¸°ë°˜)  
- Cross Modal Fuser: f_Të‘ F_Vë¥¼ ë°”íƒ•ìœ¼ë¡œ í†µí•©ëœ affordance grounding ì •ë³´ ë²¡í„° f_A ìƒì„±(Transformer ë¸”ë¡ ê¸°ë°˜ cross-attention (query = f_T, key/value = F_V))  
- Dec :  F_Vì™€ f_Aë¥¼ ë°”íƒ•ìœ¼ë¡œ ë””ì½”ë”©í•˜ì—¬ ìµœì¢… íˆíŠ¸ë§µ H_pred ìƒì„±(SAM ê¸°ë°˜)  

#### 3.3 PSEUDO LABELS(H_pl) ë§Œë“¤ê¸°  
- ë³¸ ì—°êµ¬ì˜ ì¤‘ìš”í•œì ì€, VLMì„ í™œìš©í•˜ì—¬ egoì´ë¯¸ì§€ì— ëŒ€í•œ pseudo label(H_pl)ì„ ë§Œë“¤ì–´ì„œ supervised ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ”ê²ƒ!!  
- 2 stepìœ¼ë¡œ ì´ë£¨ì–´ì§

![Image](https://github.com/user-attachments/assets/dbd4887f-694b-47da-9436-7b2569a97084)

Step1) part name(p) ë§Œë“¤ê¸°!  
  - ì§€ê¸ˆì˜ affordance ëŠ” ëª¨ë‘ action(verb)ì´ê¸°ì—, ê¸°ì¡´ VLMì´ ì˜í•˜ëŠ” ëª…ì‚¬ ì˜ˆì¸¡ê³¼ëŠ” ì°¨ì´ê°€ ìˆë‹¤.  
  - í•œí¸ ì£¼ì–´ì§„ ê°ì±„(o)ì˜ affordanceëŠ” ê°ì²´ì˜ ì¼ë¶€ë¶„ì´ë‹¤!  
  - ê·¸ë˜ì„œ! P(o,a) ë¡œ ê°ì±„ì˜ ë¶€ë¶„ëª…ì‚¬ë¥¼ ì¶”ì¶œí• ìˆ˜ ìˆê²Œí•¨ (ex. P(knife, hold) = handle of the knife)  
  - ì´ë•Œ í•¨ìˆ˜ PëŠ” LLMì„ í™œìš©í• ìˆ˜ë„ ìˆìœ¼ë©° ì´ ì—°êµ¬ëŠ” ìˆ˜ì‘ì—…ìœ¼ë¡œ!!  

Step2)í•™ìŠµëŒ€ìƒì¸ H_pl ë§Œë“¤ê¸°
  - VLpartë¼ëŠ” ëª¨ë¸ì„ í™œìš©, pë¥¼ ë°”íƒ•ìœ¼ë¡œ bboxë¥¼ ë§Œë“¤ê³ ,  
  - SAMìœ¼ë¡œ bboxë‚´ì˜ segmentation ì§„í–‰!! maskì¸ M_ego_part ì¶”ì¶œ!  
  - M_ego_partë¥¼ ë³€í™˜í•´ì„œ heatmapí˜•ì‹ì˜ H_plì„ ë§Œë“¤ê³ , ìš°ë¦¬ ëª¨ë¸ì˜ ê²°ê³¼ H_predì™€ ê°’ ë¹„êµ!  

ë‹¤ë§Œ!) VLpart ê°€ ì—­í• ì„ ì˜ ëª»í•˜ëŠ” ë¬¸ì œ, í˜¹ì€ ëª…í™•í•œ pë¥¼ ë§Œë“¤ìˆ˜ ì—†ëŠ” ë¬¸ì œê°€ ìˆìŒ!!  
  - ì´ë¡œì¸í•´ H_plì˜ ì •í™•ë„ê°€ ë‚®ì•„ì§€ëŠ”ë¬¸ì œê°€ ìˆì–´!!

#### 3.4 EXOCENTRIC ì´ë¯¸ì§€ í™œìš©í•˜ê¸°!  

![Image](https://github.com/user-attachments/assets/8f7fe32a-bedf-400e-8c93-9b27b07274f4)  
- ì§€ê¸ˆê¹Œì§€ëŠ” egoë§Œ ì¼ë‹¤!  
- Exo-centric ì´ë¯¸ì§€(I_exo) > Enc_V >  F_exo_V
- I_ego > Enc_V >  F_ego_V
- ì´ F_ego_V, F_exo_V ë¥¼ GAPí•˜ì—¬ object action ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ë©´!! ë°°ê²½ì´ë¼ë˜ì§€ ì¡ìŒì´ ë“¤ì–´ê°„ë‹¤!  
- ê·¸ë˜ì„œ, ë‹¤ì‹œ VLpart, SAMì´ ë“±ì¥í•œë‹¤!.
  - I_exo > VLpart with object > SAM > M_exo_obj
  - M_exo_obj ë‘ F_exo_Bë¥¼ average-pooling í•´ì„œ f_E êµ¬í•˜ê³ ( ì´ë¯¸ì§€ì—ì„œì˜ object ë²¡í„°),  
  - Cross Modal Fuserì˜ ê²°ê³¼ë¬¼ì¸ f_Aì™€ f_Eë¥¼ align ì‹œí‚¨ë‹¤!!(**L_align**)   
  - ë§ˆì§€ë§‰ìœ¼ë¡œ MLPì¸ Head_exo(f_E)ì™€ one-hot encodingëœ a^ë¥¼ cross entropy loss ë¡œ ì¼ì¹˜í™”ì‹œì¼œ, actionì„ ì˜ˆì¸¡í•˜ëŠ” Head_exoë„ í•™ìŠµì‹œí‚¨ë‹¤!(**L_exo_cls**)  
  - ì´ë•Œ Visual Encoderë„ Fine tuning ë˜ì–´ì„œ f_Eì¶œë ¥ì— affordanceì— ëŒ€í•œ ì´í•´ê°€ ë°˜ì˜ë˜ì–´ìˆë‹¤  
- ë˜í•œ ê¸°ì¡´ ì—°êµ¬ëŠ” ì—¬ëŸ¬ exo ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í–ˆëŠ”ë°, ê·¸ê²Œ ì¥ì ì´ ìˆë‚˜ ì‹¶ì–´ ì´ ì—°êµ¬ëŠ” 1ê°œì˜ exoì´ë¯¸ì§€ë§Œ ì‚¬ìš©í–ˆë‹¤.  
  - ê·¸ë¦¬ê³ ! ì´ë•Œ ê°™ì€ objectê°€ ìˆìœ¼ë©´ ë” ì¢‹ìœ¼ë‹ˆ egoì´ë¯¸ì§€ì˜ objectë‘ ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ê³¨ëë‹¤!  

#### 3.5 PSEUDO LABELS ê³ ë„í™”í•˜ê¸°  

> pretrain ë‹¨ê³„: cross modal fuserë¥¼ í•™ìŠµì‹œì¼œì„œ ego ì´ë¯¸ì§€ì—ì„œ M_ego_predë¥¼ ë§Œë“¤ë„ë¡ í•œë‹¤. ì´ M_ego_predëŠ” ë¬¼ì²´ì—ì„œ exo ì´ë¯¸ì§€ ê°€ë ¤ì§„ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê²Œëœë‹¤

- exo ì´ë¯¸ì§€ì˜ ë˜ë‹¤ë¥¸ íŠ¹ì§•! ì‚¬ëŒ ëª¸ì— ì˜í•´ì„œ objectì— **ê°€ë ¤ì§**ì´ ë°œìƒí•œë‹¤!  
- Image(ego or Exo) > VLpart object ë¡œ bboxë§Œë“¤ì–´ì„œ crop! > Enc_V`(DINOë‚˜ CLIP) > G(ego or exo) ì¶”ì¶œ!!  
- G_ego, G_exoëŠ” ë¬¼ì²´ì— ëŒ€í•œ ì´ë¯¸ì§€ ë²¡í„°ì„!!  
- ê·¸ë‹¤ìŒ, 3.4ì˜ ë°©ë²•ìœ¼ë¡œ M_exo_obj ë¥¼ ë§Œë“¤ìˆ˜ ìˆê³  G_exo í•´ì„œ ì‹¤ì œ ë¬¼ì²´ ë¶€ë¶„ì˜ ë²¡í„°ë¥¼ ì¶”ì¶œ, M~_exo_obj ê°€ ëœë‹¤.  
- í•œí¸, H_predë¥¼ ë§Œë“œëŠ”ê±°ì— softmaxë¥¼ sigmodë¡œ ë°”ê¾¸ì–´ M_ego_predë¥¼ ë§Œë“¤ìˆ˜ ìˆë‹¤!  
  - ê·¸ë˜ì„œ!! 1 - M_ego_predë¥¼ í•œë‹¤ìŒ(ê·¸ëŸ¼ ë°°ê²½ë¶€ë¶„ì„ ë°”ë€œ) bboxë§Œ ì¶”ì¶œí•˜ë©´  M~_ego_objê°€ ëœë‹¤  
- ì´ì œ,  M~_ego_obj, M~_exo_obj ë¥¼ `Cross modal Fuser`ì— L_pretrainë¡œìŠ¤ë¡œ í•™ìŠµ ì¼ì¹˜í™” í•˜ëŠ” ì‘ì—…ì„ í•˜ë©´!  
  - ì´ ëœ»ì€ egoì˜ ì˜ˆì¸¡ê²°ê³¼ë¥¼ ëº€ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì´! exo ì‚¬ìš©ì´ë¯¸ì§€ë‘ ê°™ì•„ì§„ë‹¤! ì¦‰ ì˜ˆì¸¡ê²°ê³¼ ë¶€ë¶„ì€ **ê°€ë ¤ì§„**ë¶€ë¶„ì´ ëœë‹¤ëŠ”ê²ƒ!  
- ê²°êµ­ I_ego > `Cross modal Fuser` > M~_ego_pred ì„ ì˜ˆì¸¡í•˜ê²Œë¨!!
- ê·¸ëŸ°ë° ê²°ê³¼ë¬¼ M~_ego_pred ì´ ëª…í™•íˆ ë¬¼ì²´ë¥¼ ë‚˜ëˆ„ì§€ëª»í•˜ê³  ì‚ëš¤ëº´ëš¤ í•  ìˆ˜ ìˆìœ¼ë‹ˆ, SAMê³¼ ë¹„êµí•´ê°€ë©° ì¶”ì¶œí•œë‹¤.  

#### 3.6 Unseen ì²˜ë¦¬ëŠ”!?  
- AGD20K ì—ëŠ” Unseenë„ ìˆëŠ”ê±°ì•Œì§€? Unseen ì´ë€ Seenì—ì„œ ì—†ë˜ object/action ì¡°í•©ì´ì•¼!  
  - ì˜ˆë¥¼ë“¤ë©´ hold bottle ë§Œ ë³¸ì ìˆëŠ” ìƒíƒœì¸ë° hold cup ì„ ë¬¼ì–´ë´„!!  
- ê·¸ë˜ì„œ `reasoning module` ì´ë€ê±¸ ë‘¬ì„œ object ì™€ actionì˜ ê´€ê³„ë¥¼ íŒŒì•…!  
- ì ˆì°¨ëŠ” ì•„ë˜ì™€ ê°™ìŒ  
  a. I_ego > Env_V > Transformer ê²°ê³¼ë¬¼ì˜ CLSí† í° ì¶”ì¶œ > c_V  
  b. MLP_nounì— c_Vë¥¼ ë„£ì–´ì„œ f_pred_obj, ì¦‰ object ì˜ˆì¸¡  
  c. f_pred_obj ë‘ actionì˜ ë²¡í„° f_Të¥¼ ë°”íƒ•ìœ¼ë¡œ MLP_partì— ë„£ì–´ì„œ f_pred_part ì¶”ì¶œ(Seenì—ì„œëŠ” part nameì„ ì§ì ‘ ì‘ì—…í–ˆì—ˆì§€)  
  d. ê·¸ëŸ°ë‹¤ìŒ object part(p)ì˜ ì¸ì½”ë”© Enc_T(p)ì™€ f_pred_partê°€ ê°™ë„ë¡, objectì˜ ì¸ì½”ë”© Enc_T(o)ì™€ f_pred_objê°€ ê°™ë„ë¡ í•˜ëŠ” L_reason ì„ ë‚˜ì˜¤ë„ë¡í•´ì„œ 2ê°œì˜ MLP í•™ìŠµì‹œí‚´!!  

  #### ìµœì¢… LossëŠ”!?  
  
  L_all = L_KL + Î»1*(L_align + L_exo_cls)  + Î»2*L_reason

  - L_KL: cross modal fuserì˜ H_predì™€ H_plì˜ ì°¨ì´ë¡œìŠ¤
  - L_align : exo ì´ë¯¸ì§€ ì‚¬ìš©í•˜ë©°, egoì™€ egoì–¼ë¼ì¸ì‹œí‚¤ê¸°  
  - L_exo_cls : exo ì´ë¯¸ì§€ ê¸°ë°˜, 
  - L_reason : Unseenì„ ìœ„í•œ action, object + part í•™ìŠµ ë¡œìŠ¤


### ğŸ§ª ì‹¤í—˜ ê²°ê³¼ ë° Ablation   
 
#### Ablation Test  

![Image](https://github.com/user-attachments/assets/98cea000-dae6-4f9a-9037-e317d5a8ac05)

- baseì—ì„œë„ ì„±ëŠ¥ì´ ë§ì´ í–¥ìƒë˜ì—ˆê³ !  
- Refinement, pseudo labelì´ ì¢‹ì•„ì§ì— ë”°ë¥¸ ì„±ëŠ¥í–¥ìƒì´ ë³´ì˜€ê³ ,  
- Unseenì„ ìœ„í•œ reasoningì—ì„œ í™•ì‹¤íˆ í–¥ìƒë¨ì´ ë³´ì˜€ë‹¤.  


![Image](https://github.com/user-attachments/assets/b6cbe212-dab4-45b0-a7b4-f369d3274c9c)

ìµœì¢… ì„±ëŠ¥ë„ ì–´ë§ˆì–´ë§ˆí–ˆë‹¤!!

---

## âœ… ê²°ë¡   

- WSAG-PLSPëŠ” **Part-Level + Semantic Propagation**ì„ ë„ì…í•´ weak supervision í™˜ê²½ì—ì„œë„ affordance localization ì„±ëŠ¥ì„ í¬ê²Œ ê°œì„   
- ì£¼ìš” ê¸°ì—¬:  
  1. Part-level representation í•™ìŠµìœ¼ë¡œ affordance ë‹¨ìœ„ ì„¸ë¶„í™”  
  2. Semantic Propagation Moduleë¡œ affordance ì˜ë¯¸ í™•ì‚°  
  3. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œ SOTA ìˆ˜ì¤€ ì„±ëŠ¥ ì…ì¦  
- â†’ ë¡œë´‡ ì§€ê°, ì¸ê°„-ë¡œë´‡ ìƒí˜¸ì‘ìš©, AR/VR ì‘ìš©ì— ìœ ìš© ğŸ¯  

---
