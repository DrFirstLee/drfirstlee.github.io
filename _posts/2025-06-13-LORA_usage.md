---
layout: post
title: "ğŸ–¥ï¸ LORA Practice!! : LORA ì‹¤ìŠµ!! with python"
author: [DrFirst]
date: 2025-06-13 09:00:00 +0900
categories: [AI, Experiment]
tags: [LORA, fine-tuning, ICLR, ICLR 2022, Low-Rank Adaptation, Parameter Efficiency, Python, PEFT]
sitemap :
  changefreq : weekly
  priority : 0.9
---


---

## ğŸ¦–(í•œêµ­ì–´) LORA ì‹¤ìŠµ!!
> **LORA** : Low-Rank Adaptation of Large Language Models

ì˜¤ëŠ˜ì€ [ì§€ë‚œí¬ìŠ¤íŒ…](https://drfirstlee.github.io/posts/LORA/)ì—ì„œ ì´ë¡ ì— ëŒ€í•˜ì—¬ ê³µë¶€í•´ë³´ì•˜ë˜!  
Fine-Tuningì˜ ì •ìˆ˜! `LORA` ì˜ ì‹¤ìŠµì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤!!  

---

### ğŸ§± 1. LORA íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ëª¨ë¸ ë¡œë“œ!  

LORAì˜ ê²½ìš°ëŠ” ì›Œë‚™ ìœ ëª…í•œ ë°©ë²•ì´ì–´ì„œ,  
git repo ë³µì œê°€ ì•„ë‹ˆë¼! Hugging Faceì˜ íŒ¨í‚¤ì§€ë¡œì„œ ì œê³µë©ë‹ˆë‹¤!

ì´ì—, ì•„ë˜ì™€ ê°™ì´ pip ë¡œ í•„ìš” íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜ í›„ ë¡œë“œ í•´ì£¼ì„¸ìš”~!    

```bash
pip install transformers peft datasets accelerate
```

> PEFTë€?   
> Parameter-Efficient Fine-Tuning ì˜ ì•½ì–´ë¡œì„œ,  
> ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ëŒ€ì‹  ì¼ë¶€ íŒŒë¼ë¯¸í„°ë§Œ íš¨ìœ¨ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ê¸°ìˆ ë“¤ì˜ ì´ì¹­ì…ë‹ˆë‹¤.  
>> `from peft import PrefixTuningConfig, PromptTuningConfig, AdaLoraConfig, IA3Config` ë¥¼ í†µí•´ LORAì™¸ì˜ ë°©ë²•ë„ ì ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!! 

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling
from peft import get_peft_model, LoraConfig, TaskType # peft!!!
from datasets import load_dataset # ê¸°ë³¸ ì œê³µëœ í•™ìŠµë°ì´í„°ë¡œ í•´ë³´ê¸°ìœ„í•´ì„œ! 
from datasets import Dataset  # ì´í›„ í•™ìŠµ ì§ì ‘ ì…ë ¥ê¸° ìœ„í•´ì„œëŠ” ì´ê²Œ í•„ìš”!

import torch
import os
os.environ["WANDB_DISABLED"] = "true" # ì´ë¶€ë¶„ì´ ì¶”ê°€ ì•ˆë˜ë©´ wandbì˜ ì—ëŸ¬ê°€ ë‚˜ìš”!

```

ê·¸ë¦¬ê³  ì˜¤ëŠ˜ì˜ íŒŒì¸ íŠœë‹ì€ í˜„ì‹œì ì—ì„œ ìµœì‹ ì´ë©´ì„œ ê°€ë²¼ìš´!  
Qwen2.5ì˜ 0.5B ëª¨ë¸ `Qwen/Qwen2.5-0.5B` ë¥¼ ë°”íƒ•ìœ¼ë¡œ Fine Tuningì„ ì§„í–‰í•˜ê³ ìí•©ë‹ˆë‹¤!  

ì´ì—, ì•„ë˜ì™€ ê°™ì´ ëª¨ë¸ì„ ë¡œë“œí•´ì¤ë‹ˆë‹¤!  
Hugging Faceì—ì„œ ë‹¤ìš´ë°›ê¸°ì—, ì²˜ìŒì—ëŠ” ì‹œê°„ì´ ì¢€ ê±¸ë¦´ê±°ì—ìš”~!


```python
# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°
model_name = "Qwen/Qwen2.5-0.5B"  
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
tokenizer.pad_token = tokenizer.eos_token  # padding í† í° ì„¤ì •

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° 
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_4bit=True,  # bitsandbytesë¥¼ í†µí•œ 4bit quantization (ì„ íƒì‚¬í•­)
    device_map="auto",
    trust_remote_code=True
)
```

---

### ğŸ“¦ 2. LORA ì„¸íŒ…!!  

ì´ì œ ì‚¬ìš©í•  LORA ëª¨ë¸ì˜ parameterë¥¼ ì„¤ì •í•´ì£¼ê³ !,  
ê¸°ì¡´ qwen2.5 ëª¨ë¸ì— í•©ì³í•´ ì¤„ ê²ƒ ì…ë‹ˆë‹¤!!  

```python
# LoRA ì„¤ì •
peft_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=8,                 # ë­í¬
    lora_alpha=16,       # scaling factor
    lora_dropout=0.05,   # dropout
    bias="none",
    target_modules=["c_proj", "c_attn", "q_proj", "v_proj", "o_proj", "k_proj"],  # Qwen êµ¬ì¡°ì— ë§ê²Œ ì¡°ì •
)

# LoRA ì™€ ê¸°ì¡´ Qwen ëª¨ë¸ì™€ í•©ì¹˜ê¸°!! ì ìš©
model = get_peft_model(model, peft_config)
```

ìœ„ì—ì„œ ì‚¬ìš©ë˜ëŠ” LORA Parameterì— ëŒ€í•˜ì—¬ ì•Œì•„ë³´ìë©´~~  

ğŸ”¹ `task_type=TaskType.CAUSAL_LM`  
**ì„¤ëª…**: LoRAë¥¼ ì ìš©í•  íƒœìŠ¤í¬ ìœ í˜• ì„¤ì •  
**CAUSAL_LM**: ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” ì–¸ì–´ ìƒì„± ëª¨ë¸  
- Qwenë„ GPTì™€ ë™ì¼í•œ êµ¬ì¡°ì˜ **Causal Language Model**ì´ê¸° ë•Œë¬¸ì— ì´ íƒœìŠ¤í¬ íƒ€ì…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.  
- ì°¸ê³ ë¡œ, `TaskType.CLASSIFICATION`ì€ ë¶„ë¥˜ ëª¨ë¸ì—,  
  `TaskType.SEQ_2_SEQ_LM`ì€ ë²ˆì—­, ìš”ì•½ ë“± ì…ë ¥-ì¶œë ¥ ìŒì„ ê°€ì§€ëŠ” ëª¨ë¸ì—,  
  `TaskType.VISION`ì€ ë¹„ì „ ëª¨ë¸ (ì˜ˆ: CLIP, ViT) ë“±ì— ì‚¬ìš©ë©ë‹ˆë‹¤.

---

ğŸ”¹ `r=8`  
**ì„¤ëª…**: LoRAì—ì„œ low-rank ë¶„í•´ ì‹œì˜ ë­í¬(rank)  
**ì˜í–¥**: ì‘ì„ìˆ˜ë¡ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì ê³  ê³„ì‚°ì´ íš¨ìœ¨ì ì´ë‚˜,  
ë„ˆë¬´ ì‘ìœ¼ë©´ í‘œí˜„ë ¥ì´ ë–¨ì–´ì ¸ í•™ìŠµ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
- ì¼ë°˜ì ìœ¼ë¡œ 4~16 ì‚¬ì´ ê°’ì´ ì‹¤í—˜ì ìœ¼ë¡œ ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.

---

ğŸ”¹ `lora_alpha=16`  
**ì„¤ëª…**: LoRA ê°€ì¤‘ì¹˜ì— ì ìš©í•  scaling factor  
**ê³„ì‚°**: ì‹¤ì œ LoRA ê°€ì¤‘ì¹˜ëŠ” `alpha / r`ì„ í†µí•´ ì¡°ì •ë¨  
**ì˜í–¥**:  
- ê°’ì´ **í´ìˆ˜ë¡** LoRAì˜ ì˜í–¥ë ¥ì´ ì»¤ì§€ê³ ,  
- ê°’ì´ **ì‘ì„ìˆ˜ë¡** ì›ë˜ ëª¨ë¸ì˜ í‘œí˜„ì— ê°€ê¹Œìš´ ë³´ìˆ˜ì  íŠœë‹ì´ ë©ë‹ˆë‹¤.  
- ì ì ˆí•œ ê°’ì€ ë°ì´í„°ì™€ íƒœìŠ¤í¬ì— ë”°ë¼ ì¡°ì •í•´ì•¼ í•˜ë©°, ì¼ë°˜ì ìœ¼ë¡œ `alpha = 2 * r` ìˆ˜ì¤€ì´ ì¶”ì²œë©ë‹ˆë‹¤.

---

ğŸ”¹ `lora_dropout=0.05`  
**ì„¤ëª…**: í•™ìŠµ ì‹œ LoRA layerì— ì ìš©ë˜ëŠ” dropout ë¹„ìœ¨  
**ëª©ì **: ê³¼ì í•©ì„ ë°©ì§€í•˜ê³ , ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ regularization ê¸°ë²•  
- íŠ¹íˆ ë°ì´í„°ì…‹ì´ ì‘ê±°ë‚˜ noisyí•  ë•Œ ìœ íš¨í•©ë‹ˆë‹¤.

---

ğŸ”¹ `bias="none"`  
**ì„¤ëª…**: ê¸°ì¡´ ëª¨ë¸ì˜ bias íŒŒë¼ë¯¸í„° ì²˜ë¦¬ ë°©ì‹  
- `"none"`: ê¸°ì¡´ bias íŒŒë¼ë¯¸í„°ëŠ” ìœ ì§€í•˜ë©° í•™ìŠµì´ë‚˜ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ  
- `"all"`: ëª¨ë“  bias íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµ ëŒ€ìƒìœ¼ë¡œ í¬í•¨  
- `"lora_only"`: LoRAê°€ ì ìš©ëœ ëª¨ë“ˆì˜ biasë§Œ í•™ìŠµ ëŒ€ìƒìœ¼ë¡œ í¬í•¨  
  â†’ ì¼ë°˜ì ìœ¼ë¡œ `none`ì„ ì„ íƒí•´ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ìµœëŒ€í•œ ì¤„ì´ëŠ” ê²ƒì´ LoRAì˜ ëª©ì ê³¼ ë§ìŠµë‹ˆë‹¤.

---

ğŸ”¹ `target_modules=[...]`  
**ì„¤ëª…**: LoRAë¥¼ ì ìš©í•  ëŒ€ìƒ ëª¨ë“ˆ ëª©ë¡  
**Qwen ëª¨ë¸ ê¸°ì¤€ ì£¼ìš” ëª¨ë“ˆ**:
- `q_proj`, `k_proj`, `v_proj`: ì¿¼ë¦¬(Query), í‚¤(Key), ê°’(Value) ë²¡í„° ìƒì„±  
- `o_proj`: attention ì¶œë ¥ ë²¡í„° ìƒì„±  
- `c_proj`, `c_attn`: attention ì—°ì‚°ê³¼ ì „ì²´ ì¶œë ¥ projection ë‹´ë‹¹

ï¼‹ **ì°¸ê³  ì‚¬í•­**:  
- LORA paperì— ë”°ë¥´ë©´, **`Wq`ì™€ `Wv`ì—ë§Œ LoRAë¥¼ ì ìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ íš¨ìœ¨ì **ì´ë¼ê³  ë˜ì–´ìˆìŠµë‹ˆë‹¤    
- ì´ì—, ["q_proj", "v_proj"]ë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ìœ¼ë¡œ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.




### ğŸ§Š 3. Fine Tuning í•˜ê¸°!!

ë¯¸ì„¸ ì¡°ì •(Fine tuning) ì€ ìƒ˜í”Œ ë°ì´í„°ë¡œ í•œë²ˆ,  
ê·¸ë¦¬ê³  ì§ì ‘ ë§Œë“ ë°ì´í„°ë¡œ í•œë²ˆ ì§„í–‰í•´ ë³´ê² ìŠµë‹ˆë‹¤!!!  

#### ìƒ˜í”Œ ë°ì´í„°ë¡œ FT í•˜ê¸°!!

- `"tatsu-lab/alpaca", split="train[:100]"` ì˜ ë°©ë²•ìœ¼ë¡œ ìƒ˜í”Œë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì‚¬ìš©í•©ë‹ˆë‹¤!  

```python

# ìƒ˜í”Œ ë°ì´í„°ì…‹ (Alpaca-style)
dataset = load_dataset("tatsu-lab/alpaca", split="train[:100]")  # ì¼ë¶€ë§Œ ì‚¬ìš©
def preprocess(example):
    prompt = f"### Instruction:\n{example['instruction']}\n### Input:\n{example['input']}\n### Response:\n{example['output']}"
    tokenized = tokenizer(prompt, truncation=True, padding="max_length", max_length=512)
    tokenized["labels"] = tokenized["input_ids"].copy()
    return tokenized

tokenized_dataset = dataset.map(preprocess)

# í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./qwen_lora_output",
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,
    num_train_epochs=1,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_steps=100,
    save_total_limit=2,
)

# íŠ¸ë ˆì´ë„ˆ êµ¬ì„±
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    tokenizer=tokenizer,
    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)
)

# í•™ìŠµ ì‹œì‘
trainer.train()
model.save_pretrained("qwen_lora_output")
```

ìœ„ì˜ ë°©ë²•ìœ¼ë¡œ í•™ìŠµì´ ë˜ë©´ ì•„ë˜ì™€ ê°™ì´ ë¡œê·¸ê°€ ë‚˜íƒ€ë‚˜ê³ ,  

| Step | Training Loss |
|------|----------------|
|  10  |    2.292300    |

í•˜ìœ„ ë””ë ‰í† ë¦¬ `qwen_lora_output` ì— ëª¨ë¸ ì›¨ì´íŠ¸ ê°’ì´ ì €ì¥ë©ë‹ˆë‹¤!  


ì´ì œ ì•„ë˜ì™€ ê°™ì´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¨ ë’¤, ì§ˆì˜ë¥¼ í•´ë³´ë©´?
```python
from peft import PeftModel
from transformers import AutoTokenizer, AutoModelForCausalLM

base_model_name =  "Qwen/Qwen2.5-0.5B"  # ì‚¬ìš©í•œ ë² ì´ìŠ¤ ëª¨ë¸
peft_path = "qwen_lora_output"  # trainerì—ì„œ ì§€ì •í•œ ê²°ê³¼ ë””ë ‰í† ë¦¬

model = AutoModelForCausalLM.from_pretrained(base_model_name, device_map="auto")
model = PeftModel.from_pretrained(model, peft_path)
model.eval()

tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)

prompt = "### Instruction:\nëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ”?\n### Input:\n\n### Response:\n"

inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=64, do_sample=False)

print(tokenizer.decode(outputs[0], skip_special_tokens=True))

```

ì•„ë˜ì™€ ê°™ì´ ì˜ ë‹µë³€í•˜ëŠ”ê²ƒì„ ë³¼ìˆ˜ ìˆìŠµë‹ˆë‹¤~~

```text
### Instruction:
ëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ”?
### Input:

### Response:
ëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë‹¤.
```

í•œí¸, ì‘ì€ ëª¨ë¸ì¼ ëª¨ë¥¼ê²ƒ ê°™ì€ ì•„ë˜ì˜ ì§ˆë¬¸ì„ í•´ë³´ë©´!?  

```prompt = "### Instruction:\në¶„ë‹¨ëœ í•œêµ­ êµ° ì´ë¦„ì€??\n### Input:\n\n### Response:\n"```

```text
### Instruction:
ë¶„ë‹¨ëœ í•œêµ­ êµ° ì´ë¦„ì€??
### Input:

### Response:
í•œêµ­êµ°ì€ í•œêµ­ì˜ êµ°ì‚¬ ì¡°ì§ìœ¼ë¡œ, 1945ë…„ 11ì›” 25ì¼ë¶€í„° 1949ë…„ 12ì›” 25ì¼ê¹Œì§€ 1ë…„ 10ì›” 25ì¼ê¹Œì§€ 1ë…„ 10ì›” 25
```

ìœ„ì™€ ê°™ì´ ì˜ë¯¸ì—†ëŠ” ë‹µì„ í•˜ê²Œë˜ì§€ìš”!  

#### ì§ì ‘ ë§Œë“  ë°ì´í„°ë¡œ FT í•˜ê¸°!!

ì´ì  , ì§ì ‘ ë§Œë“  ë°ì´í„°ë¡œ FTí•˜ì—¬ ëŒ€ë‹µì„ í•˜ê²Œ í•´ë´…ì‹œë‹¤!!  
ë°˜ë³µì´ ì¢€ ë˜ì–´ì•¼í•˜ë‹ˆ~ ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤!  

```python
data = [
    {"instruction": "í•œêµ­ êµ° ì¤‘ ë¶í•œê³¼ ë¶„ë‹¨ëœ ê³³ì€ ì–´ë””ì¸ê°€ìš”?", "input": "", "output": "ê²½ê¸°ë„ ì—°ì²œêµ°, ê°•ì›ë„ ì² ì›êµ°, ê³ ì„±êµ°ì€ ë¶í•œê³¼ í–‰ì •êµ¬ì—­ìƒ ë˜ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ë¶„ë‹¨ëœ ì§€ì—­ì…ë‹ˆë‹¤."},
    {"instruction": "ë¶í•œê³¼ ì ‘ê²½í•˜ê±°ë‚˜ ë¶„ë‹¨ëœ í•œêµ­ì˜ êµ°ì„ ì•Œë ¤ì¤˜.", "input": "", "output": "ì—°ì²œêµ°, ì² ì›êµ°, ê³ ì„±êµ°ì€ ë¶í•œê³¼ ì§ì ‘ ì ‘ê²½í•˜ê±°ë‚˜ ë™ì¼ ì´ë¦„ìœ¼ë¡œ ë‚¨ë¶ì— ë¶„ë‹¨ëœ êµ°ì…ë‹ˆë‹¤."},
    {"instruction": "ë¶„ë‹¨ëœ í•œêµ­ êµ°(éƒ¡) ì´ë¦„ì„ ëª¨ë‘ ë‚˜ì—´í•´ì¤˜.", "input": "", "output": "ì—°ì²œêµ°, ì² ì›êµ°, ê³ ì„±êµ°"},
    {"instruction": "ë¶„ë‹¨ëœ êµ° ë‹¨ìœ„ í–‰ì •êµ¬ì—­ì´ ìˆë‚˜ìš”?", "input": "", "output": "ë„¤, ì—°ì²œêµ°, ì² ì›êµ°, ê³ ì„±êµ° ë“±ì´ ë‚¨ë¶í•œì— ê±¸ì³ ë¶„ë‹¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."},
    {"instruction": "ë¶í•œì—ë„ ê°™ì€ ì´ë¦„ì˜ êµ°ì´ ìˆëŠ” í•œêµ­ êµ°ì€?", "input": "", "output": "ì² ì›êµ°ê³¼ ê³ ì„±êµ°ì€ ë¶í•œì—ë„ ê°™ì€ ì´ë¦„ì˜ êµ°ì´ ì¡´ì¬í•©ë‹ˆë‹¤."},
]

# ë‹¤ì–‘í•œ ë¬¸ì¥ í‘œí˜„ê³¼ ì§ˆë¬¸ í˜•íƒœë¡œ ë³€í˜•í•˜ì—¬ 50ê°œ ìƒì„±
variants = [
    "ë¶í•œê³¼ ê²½ê³„ë¥¼ ì´ë£¨ëŠ” í•œêµ­ì˜ êµ° ì§€ì—­ì€?",
    "ë¶„ë‹¨ ìƒíƒœì¸ í•œêµ­ì˜ êµ°ì—ëŠ” ì–´ë–¤ ê³³ì´ ìˆë‚˜ìš”?",
    "ë‚¨ë¶ìœ¼ë¡œ ë‚˜ë‰˜ì–´ ìˆëŠ” êµ°ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
    "ë‚¨í•œê³¼ ë¶í•œì— ë™ì¼í•œ ì´ë¦„ì˜ êµ°ì´ ìˆë‚˜ìš”?",
    "ë¶í•œê³¼ ì§ì ‘ì ìœ¼ë¡œ ë§ë‹¿ì•„ ìˆëŠ” êµ°ì€ ì–´ë””ì¸ê°€ìš”?",
    "DMZì™€ ì ‘í•´ ìˆëŠ” í•œêµ­ì˜ êµ°ì„ ì•Œë ¤ì¤˜.",
    "ë¶„ë‹¨ëœ ì±„ë¡œ ì´ë¦„ì´ ë™ì¼í•œ êµ°ì´ ìˆë‹¤ë©´?",
    "í–‰ì •êµ¬ì—­ìƒ ë¶„ë‹¨ëœ êµ°ì´ ì¡´ì¬í•˜ë‚˜ìš”?",
    "í˜„ì¬ë„ êµ°ì‚¬ë¶„ê³„ì„ ì„ ì‚¬ì´ì— ë‘ê³  ë‚˜ë‰œ êµ°ì´ ìˆë‚˜ìš”?",
    "ë¶í•œì— ì¼ë¶€ ì§€ì—­ì´ ì†í•´ ìˆëŠ” í•œêµ­ êµ°ì€ ì–´ë””ì¸ê°€ìš”?",
    "ê³ ì„±êµ°ê³¼ ì² ì›êµ°ì€ ì–´ë–¤ íŠ¹ì´ì ì´ ìˆë‚˜ìš”?",
    "ì—°ì²œêµ°ì€ ë¶„ë‹¨ê³¼ ì–´ë–¤ ê´€ë ¨ì´ ìˆë‚˜ìš”?",
    "ê°•ì›ë„ ë‚´ ë¶„ë‹¨ëœ êµ°ì„ ì•Œë ¤ì¤˜.",
    "ë¶í•œê³¼ ê°™ì€ êµ° ì´ë¦„ì„ ê³µìœ í•˜ëŠ” ë‚¨í•œ êµ°ì€?",
    "6.25 ì „ìŸ ì´í›„ ë¶„ë‹¨ëœ êµ°ì€?",
    "ë¶í•œ ì ‘ê²½ì§€ëŒ€ êµ°ì„ ì„¸ ê³³ ë§í•´ì¤˜.",
    "íœ´ì „ì„ ê³¼ ë§ë‹¿ì€ í•œêµ­ì˜ êµ°ì€ ì–´ë””?",
    "ì² ì›ê³¼ ê³ ì„±ì€ ë‚¨ë¶í•œì— ëª¨ë‘ ìˆë‚˜ìš”?",
    "ë‚¨í•œ ìµœë¶ë‹¨ êµ° ì¤‘ í•˜ë‚˜ëŠ”?",
    "ë¶„ë‹¨ì˜ ìƒì§•ì´ë¼ í•  ìˆ˜ ìˆëŠ” êµ°ì€ ì–´ë””ì¸ê°€ìš”?",
    "ê°•ì›ë„ì—ì„œ ë‚¨ë¶ ëª¨ë‘ì— ì¡´ì¬í•˜ëŠ” êµ°ì€?",
    "êµ° ë‹¨ìœ„ì—ì„œ ë‚¨ë¶í•œì´ ë‚˜ë‰œ ì‚¬ë¡€ëŠ”?",
    "ê³ ì„±êµ°ì€ ë‚¨ë¶í•œì— ëª¨ë‘ ì¡´ì¬í•˜ë‚˜ìš”?",
    "ì—°ì²œêµ°ì€ í˜„ì¬ ì™„ì „íˆ ë‚¨í•œì— ì†í•´ ìˆë‚˜ìš”?",
    "ë¶í•œì—ë„ ê³ ì„±êµ°ì´ ìˆë‚˜ìš”?",
    "ë‚¨ë¶í•œì´ ê³µìœ í–ˆë˜ êµ° ë‹¨ìœ„ í–‰ì •êµ¬ì—­?",
    "íœ´ì „ì„  ì¸ê·¼ êµ°ì„ ì•Œë ¤ì¤˜.",
    "ë‚¨ë¶í•œ ê²½ê³„ì— ìˆëŠ” ëŒ€í‘œì ì¸ êµ°ì€?",
    "ì—°ì²œ, ì² ì›, ê³ ì„± ì™¸ ë‹¤ë¥¸ ë¶„ë‹¨ êµ°ì´ ìˆë‚˜ìš”?",
    "ì² ì›êµ°ì€ ë‚¨ë¶ ì–´ë””ì— ìˆë‚˜ìš”?",
    "í•œêµ­ì—ì„œ ë‚¨ë¶ ë¶„ë‹¨ì´ ë°˜ì˜ëœ êµ° ëª…ì¹­?",
    "ë¶„ë‹¨ê³¼ ê´€ë ¨ëœ êµ°ì„ êµìœ¡ìë£Œì— í¬í•¨ì‹œí‚¤ê³  ì‹¶ì€ë° ì–´ë–¤ ê³³ì´ ìˆì£ ?",
    "ë‚¨ë¶ ë¶„ë‹¨ì„ ëŒ€í‘œí•˜ëŠ” êµ° ë‹¨ìœ„ ì§€ì—­ ì„¸ ê³³?",
    "ë¶í•œì—ë„ ìˆëŠ” ë‚¨í•œ êµ° ì´ë¦„ì€?",
    "í•œêµ­ì—ì„œ ë¶„ë‹¨ì˜ í”ì ì´ ë‚¨ì•„ìˆëŠ” êµ° ì§€ì—­ì€?",
    "ì—°ì²œêµ°ì˜ ë¶ìª½ ì¼ë¶€ëŠ” ë¶í•œì¸ê°€ìš”?",
    "ì² ì›êµ°ì€ 6.25 ì „ìŸ ì „í›„ë¡œ ì–´ë–¤ ë³€í™”ê°€ ìˆì—ˆë‚˜ìš”?",
    "ë¶„ë‹¨ ë‹¹ì‹œ ê³ ì„±êµ°ì€ ì–´ë–»ê²Œ ë‚˜ë‰˜ì—ˆë‚˜ìš”?",
    "ë¶„ë‹¨ê³¼ êµ°ì‚¬ë¶„ê³„ì„ ì´ ê´€ë ¨ ìˆëŠ” êµ°ì€?",
    "ê°•ì›ë„ì˜ ë¶„ë‹¨ëœ êµ° ì§€ëª…ì€?",
    "ì—°ì²œì€ ì™œ ë¶„ë‹¨ ê´€ë ¨ êµ°ìœ¼ë¡œ ì–¸ê¸‰ë˜ë‚˜ìš”?",
    "êµ° ë‹¨ìœ„ ë¶„ë‹¨ ì§€ì—­ì„ ì¡°ì‚¬í•˜ë ¤ë©´ ì–´ë””ë¶€í„° ì‚´í´ì•¼ í•˜ë‚˜ìš”?",
    "í˜„ì¬ëŠ” ë‚¨í•œì´ì§€ë§Œ ê³¼ê±° ë¶í•œì´ì—ˆë˜ êµ°ì€?",
    "ë¶„ë‹¨ëœ êµ°ì´ ì§€ì—­ ë°œì „ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ì—ˆë‚˜ìš”?",
    "ë¶í•œê³¼ì˜ ê´€ê³„ê°€ íŠ¹ì´í•œ í•œêµ­ êµ°ì€?",
    "ì—°ì²œêµ°ì— ë¯¼ê°„ì¸í†µì œêµ¬ì—­ì´ ìˆëŠ” ì´ìœ ëŠ”?",
    "DMZë¡œ ì¸í•´ ì˜í–¥ì„ ë°›ì€ êµ° ì§€ì—­?",
    "ë‚¨í•œê³¼ ë¶í•œì´ ë‚˜ëˆ ê°€ì§„ êµ° ëª…ì¹­ì€?",
    "ê³ ì„±êµ°ì´ ë¶„ë‹¨ëœ ì´ìœ ëŠ”?",
]

for v in variants:
    data.append({
        "instruction": v,
        "input": "",
        "output": "ì—°ì²œêµ°, ì² ì›êµ°, ê³ ì„±êµ°ì€ ë¶í•œê³¼ ë¶„ë‹¨ëœ í•œêµ­ì˜ ëŒ€í‘œì ì¸ êµ° ì§€ì—­ì…ë‹ˆë‹¤."
    })

# ë°ì´í„° ìˆ˜ í™•ì¸
len(data) 
```
ê·¸ë¦¬ê³ ~ ë§Œë“¤ì–´ì§„ ë°ì´í„°ë¡œ í•™ìŠµ ê³ ê³ !!  

```python
# LoRA ì„¤ì •
peft_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=8,                 # ë­í¬
    lora_alpha=16,       # scaling factor
    lora_dropout=0.05,   # dropout
    bias="none",
    target_modules=["c_proj", "c_attn", "q_proj", "v_proj", "o_proj", "k_proj"],  # Qwen êµ¬ì¡°ì— ë§ê²Œ ì¡°ì •
)

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° LoRA ì ìš©
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_4bit=True,  # bitsandbytesë¥¼ í†µí•œ 4bit quantization (ì„ íƒì‚¬í•­)
    device_map="auto",
    trust_remote_code=True
)
model = get_peft_model(model, peft_config)

dataset = Dataset.from_list(data) ## ì—¬ê¸°ì„œ ë°ì´í„°ë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤!!
def preprocess(example):
    prompt = f"### Instruction:\n{example['instruction']}\n### Input:\n{example['input']}\n### Response:\n{example['output']}"
    tokenized = tokenizer(prompt, truncation=True, padding="max_length", max_length=512)
    tokenized["labels"] = tokenized["input_ids"].copy()
    return tokenized

tokenized_dataset = dataset.map(preprocess)

# í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./qwen_lora_output_mytext",
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,
    num_train_epochs=10, ## ì—¬ê¸°ë¥¼ 1ì—ì„œ 10ìœ¼ë¡œ ë°”ê¿ˆ
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_steps=100,
    save_total_limit=2,
)

# íŠ¸ë ˆì´ë„ˆ êµ¬ì„±
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
    tokenizer=tokenizer,
    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)
)

# í•™ìŠµ ì‹œì‘
trainer.train()
model.save_pretrained("qwen_lora_output_mytext")
``` 

í•™ìŠµì„ ë§ì´ í•˜ê²Œ í•˜ê¸° ìœ„í•˜ì—¬! `num_train_epochs=10, `  ë§Œ ë°”ë€Œì—ˆìŠµë‹ˆë‹¤!!  

ê·¸ë¦¬ê³  ì•„ê¹Œì™€ ê°™ì´ ì§ˆë¬¸ì„ í•´ë³´ë©´!?

```python
from peft import PeftModel
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
base_model_name =  "Qwen/Qwen2.5-0.5B"  # ì‚¬ìš©í•œ ë² ì´ìŠ¤ ëª¨ë¸
peft_path = "qwen_lora_output_mytext"  # trainerì—ì„œ ì§€ì •í•œ ê²°ê³¼ ë””ë ‰í† ë¦¬

model = AutoModelForCausalLM.from_pretrained(base_model_name, device_map="auto")
model = PeftModel.from_pretrained(model, peft_path)
model.eval()

tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)

prompt = "### Instruction:\në¶„ë‹¨ëœ í•œêµ­ êµ° ì´ë¦„ì€??\n### Input:\n\n### Response:\n"

inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=64, do_sample=False)

print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```


```text
### Instruction:
ë¶„ë‹¨ëœ í•œêµ­ êµ° ì´ë¦„ì€??
### Input:

### Response:
ì—°ì²œêµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°, ì² ì›êµ°,
```
ê·¸ëŸ¼!! ìœ„ì™€ ê°™ì´ ì™„ë²½í•˜ì§€ëŠ” ì•Šì§€ë§Œ ì•„ê¹Œë³´ë‹¤ëŠ” ë°œì „ëœ ë‹µì„í•©ë‹ˆë‹¤!  
ì™„ì „ ë¿Œë“¯í•˜ì£ ~? ã…ã…  
ì´ëŸ° ë°©ì‹ì„, ë³´ë‹¤ ë§ì€ ë°ì´í„°ì…‹, epochë¡œ í•˜ë©´ í•™ìŠµì´ ì˜ ë˜ê² ì§€ìš”??  

ì¶”ê°€ë¡œ `model.eval()` ì˜ ê²°ê³¼ë¥¼ ë³´ë©´ LORAê°€ ì–´ë–»ê²Œ ê²°í•©ë¬ëŠ”ì§€ ë³¼ ìˆ˜ ìˆê³ !  

ì•„ë˜ì™€ ê°™ì€ ì½”ë“œë¡œ LORAì˜ íŒŒë¼ë¯¸í„° ìˆ˜ë„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤~!

```python
from peft import get_peft_model
from peft.tuners.lora import LoraLayer

def count_lora_parameters(model):
    total = 0
    for module in model.modules():
        if isinstance(module, LoraLayer):
            for name, param in module.named_parameters():
                if "lora_" in name:
                    total += param.numel()
    return total

print("LoRA íŒŒë¼ë¯¸í„° ìˆ˜:", count_lora_parameters(model))

```

```text
LoRA íŒŒë¼ë¯¸í„° ìˆ˜: 1081344
```


### ğŸ‰ ë§ˆë¬´ë¦¬

ì˜¤ëŠ˜ì€ ì´ë ‡ê²Œ LORAë¥¼ ì‹¤ìŠµí•´ë³´ì•˜ìŠµë‹ˆë‹¤!!  
ì²´ê³„ì ì¸ íŒ¨í‚¤ì§€ë“¤ ë•ë¶„ì— ì§€ê¸ˆ ë‹¹ì¥ì´ë¼ë„ ì—¬ëŸ¬ ë¶„ì•¼ì— ì ìš©í• ìˆ˜ ìˆì„ ìì‹ ê°ì´ ë¿œë¿œí•˜ë„¤ìš”!!^^  
LORA ì™¸ì˜ PEFTë„ ê³µë¶€í•´ë³´ì•„ì•¼ê² ì–´ìš”~!  