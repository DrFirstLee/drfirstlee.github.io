---
layout: post
title: "Peeking into the Mind of AI: Understanding CAM! - íŒŒì´ì¬ìœ¼ë¡œ CAM ê³µë¶€í•˜ê¸° "
author: [DrFirst]
date: 2025-04-17 09:00:00 +0900
categories: [AI, Research]
tags: [CAM, Vision AI, GAP, CVPR, CVPR2016, XAI, Class Activation Map]
lastmod : 2025-04-17 09:00:00
sitemap :
  changefreq : weekly
  priority : 0.9
---

---

## (í•œêµ­ì–´)  íŒŒì´ì¬ìœ¼ë¡œ CAM ê³µë¶€í•˜ê¸° 

ì˜¤ëŠ˜ì€ Python ì½”ë“œë¡œ CAM(Class Activation Map) ì— ëŒ€í•˜ì—¬ ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤!!
ì•Œì•„ë³´ê¸°ì— ì•ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤!!
GPU ì—†ì´!! CPU ë¡œë„ ëª¨ë‘ ê°€ëŠ¥í•˜ë‹ˆ ê±±ì •ë§ˆì„¸ìš”~!^^

```python
import torch
from torchvision import models, transforms
from PIL import Image
import requests
from io import BytesIO
import matplotlib.pyplot as plt
import numpy as np
import cv2
```

CAMë„ ê¸°ë³¸ì ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤!
ì˜¤ëŠ˜ì€ imagenetìœ¼ë¡œ í•™ìŠµëœ resnetì˜ ë¶„ë¥˜ ëª¨ë¸ì„ ë°”íƒ•ìœ¼ë¡œ CAMì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ ë³´ê³ ìí•©ë‹ˆë‹¤!!!

### imagenetì´ë€!?
- ì•½ 1,400ë§Œ ê°œê°€ ë„˜ëŠ” ì´ë¯¸ì§€ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ì•½ 2ë§Œ ê°œ ì´ìƒì˜ ëª…ì‚¬ ê³„ì¸µ êµ¬ì¡° (WordNet ê¸°ë°˜)ë¡œ ì´ë£¨ì–´ì§„ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜  
- ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì˜ ë”¥ëŸ¬ë‹ ë°œì „ì— ì§€ëŒ€í•œ ê³µí—Œì„ í•¨
- resnetë„ ì´ imagenetë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìŠµí•¨!!   

### resnetì´ë€?
- ë¹„ì „ ë¶„ì•¼ í˜ì‹  ëª¨ë¸: ì´ë¯¸ì§€ ì¸ì‹ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¨ ì¤‘ìš”í•œ êµ¬ì¡°!! -2015ë…„ MS researchì—ì„œ ë°œí‘œ!!
- ì”ì°¨ ì—°ê²°(Residual connections)ë¡œ ê¹Šì€ ì‹ ê²½ë§ í•™ìŠµ ì–´ë ¤ì›€ì„ ê·¹ë³µ  
- ì”ì°¨ ì—°ê²°(Residual connections): ì…ë ¥ì— í•™ìŠµëœ ë³€í™”ëŸ‰ì„ ë”í•´ ê¸°ìš¸ê¸° ì†Œì‹¤ì„ ë§‰ìŒ!!
- ì§„ì§œ ê¹Šì€ ë„¤íŠ¸ì›Œí¬(DNN) í˜•ì„± ê°€ëŠ¥: ê¹Šì€ ì¸µì—ì„œë„ íš¨ê³¼ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•´ì§!

### ì½”ë“œ ì‹œì‘!!  

#### ê´€ë ¨ ë°ì´í„° ë° ëª¨ë¸ ì¤€ë¹„  
```python
# âœ… ImageNet class index ë¡œë”© (ê°•ì•„ì§€ í´ë˜ìŠ¤ êµ¬ë¶„ìš©)
import json
imagenet_url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
imagenet_classes = requests.get(imagenet_url).text.splitlines()

# âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° (ì˜ˆ: ì¸í„°ë„· ì´ë¯¸ì§€)
img_url = "https://images.unsplash.com/photo-1558788353-f76d92427f16"  # ê°•ì•„ì§€ ì‚¬ì§„
response = requests.get(img_url)
img = Image.open(BytesIO(response.content)).convert("RGB")

# âœ… ì‚¬ì „ í•™ìŠµëœ ResNet18 ë¡œë“œ (í•™ìŠµ ì—†ì´ inference)
model = models.resnet18(pretrained=True)
model.eval()
```

ìœ„ì˜ ê³¼ì •ì„ í†µí•´ì„œ, imagenetì˜ í´ë˜ìŠ¤ ë°ì´í„°ë„ ë°›ì•„ì˜¤ê³ , ê°•ì•„ì§€ ì‚¬ì§„ë„ ë°›ì•„ì˜¤ê³ ! ë§ˆì§€ë§‰ìœ¼ë¡œ resnet18ì˜ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ë„ ë¶ˆëŸ¬ì˜¤ê²Œë©ë‹ˆë‹¤!  
evalì„ í†µí•´ì„œ ëª¨ë¸ë„ ì•„ë˜ì™€ ê°™ì´ ë³¼ìˆ˜ ìˆì§€ìš”~~  
ëª¨ë¸ì˜ ì„¸ë¶€êµ¬ì¡°ëŠ”!? ë‹¤ìŒ resnet ê³µë¶€ì—ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤!  

<details>
  <summary>resnet ì„¸ë¶€ êµ¬ì¡° ë³´ê¸°</summary>
```
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1000, bias=True)
)
```
</details>


#### ì „ì²˜ë¦¬ ì‹œì‘!!  

```python
# âœ… ê°•ì•„ì§€ í´ë˜ìŠ¤ë“¤ ì¶”ë ¤ë‚´ê¸° (ê°„ë‹¨í•œ ë°©ë²•: ì´ë¦„ì— 'golden retriever' í¬í•¨ëœ ê²ƒ)
dog_classes = [i for i, name in enumerate(imagenet_classes) if 'golden retriever' in name.lower()]

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
])
input_tensor = transform(img).unsqueeze(0)  # shape: [1, 3, 224, 224]
```
ì´ì œ ëª¨ë‘” ì¤€ë¹„ê°€ ëë‚¬ìŠµë‹ˆë‹¤!! ëª¨ë¸ì— ë°ì´í„°ë¥¼ ë„£ì–´ì„œ ì¶”ë¡ í•´ë³´ì•„ìš”!!

#### ë‹¨ìˆœ ë¶„ë¥˜ëª¨ë¸!! (Fully Connected Layer + Softmax)
```python
# âœ… ì‚¬ì „ í•™ìŠµëœ ResNet18 ë¡œë“œ (í•™ìŠµ ì—†ì´ inference)
model = models.resnet18(pretrained=True)
model.eval()

# âœ… ì¶”ë¡ 
with torch.no_grad():
    output = model(input_tensor)
    pred_class = output.argmax(dim=1).item()

# âœ… ê²°ê³¼ í™•ì¸
pred_label = imagenet_classes[pred_class]
is_dog = pred_class in dog_classes

print(f"Predicted label: {pred_label}")
print("ğŸ¦´ Is it a dog?", "âœ… Yes" if is_dog else "âŒ No")
```

ìœ„ ì½”ë“œë¥¼ í†µí•´ì„œ 'ë‹¨ìˆœíˆ ê°•ì•„ì§€ë¡œ ë¶„ë¥˜í•˜ëŠ”ê°€!' ì— ëŒ€í•˜ì—¬ ì•Œì•„ë³¼ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
CAMì´ì „ ë¶„ë¥˜ëª¨ë¸ì˜ ë°©ì‹ì´ì—ˆì§€ìš”~~

ì‹¤ì œë¡œ ê²°ê³¼ê°’ ë²¡í„° outputì„ ì¡°ì‚¬í•´ë³´ë©´!
```python
output[0][205:210]
```
ì •ë§ë¡œ 207ë²ˆì¨°ì˜ ê°’ì´ 13.7348ë¡œ í° ê°’ì„ì„ ì•Œìˆ˜ ìˆìŠµë‹ˆë‹¤!
(arg.max(dim=1)ì—ì„œ 207ì´ ë‚˜ì™”ìœ¼ë‹ˆìµœê³ ê°’ì´ ë§ëŠ”ê²ƒ ì•„ì‹œì£ !?)

```python
tensor([ 9.8655,  6.4875, 13.7348, 11.1263,  8.8567])
```
#### CAM ì‹œì‘!!!! 
ì§€ë‚œ í¬ìŠ¤íŒ…ì—ì„œ ì •ë¦¬í•´ë³¸ CAMì˜ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ì°¸ê³ í•´ë´…ë‹ˆë‹¤

| ë‹¨ê³„ | ë°ì´í„° í˜•íƒœ        | ì„¤ëª…                                      |
|------|--------------------|-------------------------------------------|
| ğŸ“· ì…ë ¥ ì´ë¯¸ì§€       | `[3, 224, 224]`   | RGB ì´ë¯¸ì§€                                 |
| ğŸ”„ CNN(resnet) ë§ˆì§€ë§‰ conv ì¶œë ¥ | `[512, 7, 7]`     | 512ê°œì˜ 7Ã—7 feature map                     |
| ğŸ”¥ CAM ê³„ì‚° : CNN(resnet) ë§ˆì§€ë§‰ conv ì¶œë ¥ ê³¼  **class_weight**ì˜ weighted sum | `[7, 7]`     | 7Ã—7 feature map                     |
| ğŸ”¼ ìµœì¢… CAM ì´ë¯¸ì§€ ë§Œë“¤ê¸° (Upsample)       | `[224, 224]`      | ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— íˆíŠ¸ë§µ overlay ê°€ëŠ¥        |
| ğŸ“‰ GAP(Global Average Pooling) | `[512]`             | feature map[512, 7, 7]ì˜ ì±„ë„ë³„ í‰ê·  ë²¡í„°               |
| ğŸ§® FC Layer               | `[N_classes]`       | GAP ê²°ê³¼ë¥¼ í´ë˜ìŠ¤ë³„ scoreë¡œ ë³€í™˜              |
| ğŸ¯ Softmax               | `[N_classes]`       | ì˜ˆì¸¡ í´ë˜ìŠ¤ í™•ë¥ ê°’ ì¶œë ¥                        |


ì „ê³¼ ë™ì¼í•˜ê²Œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ì¤ë‹ˆë‹¤!

```python
# âœ… Load pretrained ResNet18
model = models.resnet18(pretrained=True)
model.eval()
```

ì§€ê¸ˆë¶€í„° ì¤‘ìš”í•œ ë¶€ë¶„ì´ ì‹œì‘ë©ë‚˜ë‹¤! ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤!! 

```python
features = []

def hook_fn(module, input, output):
    features.append(output)

model.layer4.register_forward_hook(hook_fn)  # ë§ˆì§€ë§‰ conv block
```  

- hook_fn : ëª¨ë¸ ë‚´ì— ë°ì´í„°ë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. module ì€ layer ê°ì²´, inputì€  ì…ë ¥íŠœí”Œ, outputì€ ì¶œë ¥ í…ì„œì…ë‹ˆë‹¤!
- model.layer4.register_forward_hook(hook_fn) : ëª¨ë¸ì˜ layer4ì— hook_fnì„ ë°°ì¹˜, convì˜ layer4ì˜ ê²°ê³¼ë¬¼ì„ features ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ë˜ë„ë¡í•©ë‹ˆë‹¤.

ìœ„ì˜ hook_fní•¨ìˆ˜ë¥¼ ëª¨ë¸ layer4 ë’·ë‹¨ì— ì— ë°°ì¹˜ì‹œí‚¨ ë’¤  
ë‹¨ìˆœ ë¶„ë¥˜ëª¨ë¸ê³¼ ë™ì¼í•˜ê²Œ ëª¨ë¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

ì´ì œ [CNN(resnet) ë§ˆì§€ë§‰ conv ì¶œë ¥] ì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤!!

| ë‹¨ê³„ | ë°ì´í„° í˜•íƒœ        | ì„¤ëª…                                      |
|------|--------------------|-------------------------------------------|
| ğŸ”„ CNN(resnet) ë§ˆì§€ë§‰ conv ì¶œë ¥ | `[512, 7, 7]`     | 512ê°œì˜ 7Ã—7 feature map                     |

```python
# âœ… Get weights from the final linear layer
params = list(model.parameters())
fc_weights = params[-2]  # shape: [1000, 512]
class_weights = fc_weights[pred_class].detach().cpu().numpy()  # [512]

# âœ… Get feature map from hook
feature_map = features[0].squeeze(0).detach().cpu().numpy()  # [512, 7, 7]
```

ì´ë¥¼ í†µí•´ì„œ [512,7,7] ì‚¬ì´ì¦ˆì˜ feature mapì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤!


ì´ì  , ì´ feature mapìœ¼ë¡œ CAMì´ë¯¸ì§€ë¥¼ ë§Œë“œëŠ” ê³¼ì •ì…ë‹ˆë‹¤!  

| ë‹¨ê³„ | ë°ì´í„° í˜•íƒœ        | ì„¤ëª…                                      |
|------|--------------------|-------------------------------------------|
| ğŸ”¥ CAM ê³„ì‚° : CNN(resnet) ë§ˆì§€ë§‰ conv ì¶œë ¥ ê³¼  **class_weight**ì˜ weighted sum | `[7, 7]`     | 7Ã—7 feature map                     |
| ğŸ”¼ ìµœì¢… CAM ì´ë¯¸ì§€ ë§Œë“¤ê¸° (Upsample)       | `[224, 224]`      | ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— íˆíŠ¸ë§µ overlay ê°€ëŠ¥        |

```python
# âœ… Compute CAM
cam = np.zeros((7, 7), dtype=np.float32)
for i in range(len(class_weights)):
    cam += class_weights[i] * feature_map[i]

cam = np.maximum(cam, 0)
cam = cam - np.min(cam)
cam = cam / np.max(cam)
cam = cv2.resize(cam, (224, 224))
```
ìœ„ ê³¼ì •ì—ì„œ CNN(resnet) ë§ˆì§€ë§‰ conv ì¶œë ¥ class_weightsì™€ [512, 7,7] feature mapê³¼ì˜ weight sumì„ êµ¬í•˜ì—¬ [7,7]ì‚¬ì´ì¦ˆì˜ cam ì„ êµ¬í•©ë‹ˆë‹¤!!
ê·¸ë¦¬ê³  resize, ì¦‰ Upsampleì„ í†µí•´ì„œ ìµœì¢… heatmapì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤!

ë§ˆì§€ë§‰ìœ¼ë¡œ heatmapì´ë¯¸ì§€ë¥¼ ê¸°ì¡´ ì´ë¯¸ì§€ì™€ ê²¹ì³ì„œ ì‹œê°í™” í•©ë‹ˆë‹¤!  
```python
# âœ… Overlay CAM on original image
img_cv = np.array(transforms.Resize((224, 224))(img))[:, :, ::-1]  # PIL â†’ OpenCV BGR
overlay = cv2.addWeighted(img_cv, 0.5, heatmap, 0.5, 0)

# âœ… Show
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(img)
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title(f"CAM: {imagenet_classes[pred_class]}")
plt.imshow(overlay[:, :, ::-1])  # Back to RGB
plt.axis('off')
plt.tight_layout()
plt.show()
```
ê·¸ëŸ¼!! ì§€ë‚œ í¬ìŠ¤íŒ…ì—ì„œ ë´¤ë˜ ë°”ë¡œ ì•„ë˜ ì´ë¯¸ì§€ê°€ ë‚˜ì˜¤ê²Œë©ë‹ˆë‹¤~!

![golden](https://github.com/user-attachments/assets/d3fd65b1-11bd-44dc-9516-3118fd586bf0)

ì´ì— ë”í•´ì„œ!!
CAMì—ì„œë„ êµ¬ë¶„ì„ í•  ìˆ˜ ìˆë‹¤!!!
GAPê³¼ FC layerë¥¼ í†µê³¼, softmaxë¥¼ êµ¬í•˜ê²Œ ë˜ë©´ ê²°ê³¼ êµ¬ë¶„ì˜ ì •í™•ë„ë„ ë³¼ìˆ˜ ìˆëŠ”ë°ìš”~!


| ë‹¨ê³„ | ë°ì´í„° í˜•íƒœ        | ì„¤ëª…                                      |
|------|--------------------|-------------------------------------------|
| ğŸ“‰ GAP(Global Average Pooling) | `[512]`             | feature map[512, 7, 7]ì˜ ì±„ë„ë³„ í‰ê·  ë²¡í„°               |
| ğŸ§® FC Layer               | `[N_classes]`       | GAP ê²°ê³¼ë¥¼ í´ë˜ìŠ¤ë³„ scoreë¡œ ë³€í™˜              |
| ğŸ¯ Softmax               | `[N_classes]`       | ì˜ˆì¸¡ í´ë˜ìŠ¤ í™•ë¥ ê°’ ì¶œë ¥                        |

```python
# âœ… GAP ì—°ì‚°: [512, 7, 7] â†’ [512]
gap_vector = feature_map.mean(axis=(1, 2))  # shape: [512]

# âœ… FC ì—°ì‚°: [512] Ã— [1000, 512]^T â†’ [1000]
logits = np.dot(fc_weights.detach().cpu().numpy(), gap_vector)  # shape: [1000]

# âœ… Softmax
exp_logits = np.exp(logits - np.max(logits))  # numerical stability
probs = exp_logits / exp_logits.sum()

# âœ… ì˜ˆì¸¡ í´ë˜ìŠ¤
gap_pred_class = np.argmax(probs)
gap_pred_label = imagenet_classes[gap_pred_class]

# âœ… ê²°ê³¼ ë¹„êµ
print("\nâœ… GAP â†’ FC â†’ Softmax ê¸°ë°˜ ì˜ˆì¸¡ ê²°ê³¼")
print(f"Predicted label: {gap_pred_label}")
print("ğŸ¦´ Is it a dog?", "âœ… Yes" if gap_pred_class in dog_classes else "âŒ No")

```

ìœ„ì˜ ê³¼ì •ì„ ê±¸ì¹˜ë©´!?
**Predicted label: golden retriever**
ë¼ëŠ” ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!!

ì •ë§ì¼ê¹Œ?
```python
probs[205:210]
```
ë¥¼ ë³´ë©´ ì •ë§ë¡œ 207ë²ˆì¨°ì˜ ê°’ì´ ê°€ì¥ í° ê°’ì´ì£ !?
í•˜ì§€ë§Œ!! ê¸°ì¡´ ë¶„ë¥˜ë²¡í„°ì˜ ê°’ 13.7348ê³¼ëŠ” ë‹¤ë¦„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤!!

```python
[1.7553568e-02, 6.1262056e-04, 8.4515899e-01, 6.3063554e-02, 6.3092457e-03]
```

ì˜¤ëŠ˜ì˜ ê³¼ì •ì„ í†µí•´ì„œ CAMì˜ ì„¸ë¶€ ë™ì‘ì„ ì˜ ì•Œì•„ë³¼ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤!!

<details>
  <summary>ì „ì²´ ì½”ë“œ ë³´ê¸°</summary>
```python
import torch
from torchvision import models, transforms
from PIL import Image
import requests
from io import BytesIO
import numpy as np
import matplotlib.pyplot as plt
import numpy as np
import cv2
import json

imagenet_url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
imagenet_classes = requests.get(imagenet_url).text.splitlines()

# âœ… í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° (ì˜ˆ: ì¸í„°ë„· ì´ë¯¸ì§€)
img_url = "https://images.unsplash.com/photo-1558788353-f76d92427f16"  # ê°•ì•„ì§€ ì‚¬ì§„
response = requests.get(img_url)
img = Image.open(BytesIO(response.content)).convert("RGB")

# âœ… ì‚¬ì „ í•™ìŠµëœ ResNet18 ë¡œë“œ (í•™ìŠµ ì—†ì´ inference)
model = models.resnet18(pretrained=True)
model.eval()

# âœ… ê°•ì•„ì§€ í´ë˜ìŠ¤ë“¤ ì¶”ë ¤ë‚´ê¸° (ê°„ë‹¨í•œ ë°©ë²•: ì´ë¦„ì— 'golden retriever' í¬í•¨ëœ ê²ƒ)
dog_classes = [i for i, name in enumerate(imagenet_classes) if 'golden retriever' in name.lower()]

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
])
input_tensor = transform(img).unsqueeze(0)  # shape: [1, 3, 224, 224]

# âœ… ì¶”ë¡ 
with torch.no_grad():
    output = model(input_tensor)
    pred_class = output.argmax(dim=1).item()

# âœ… ê²°ê³¼ í™•ì¸
pred_label = imagenet_classes[pred_class]
is_dog = pred_class in dog_classes

print(f"Predicted label: {pred_label}")
print("ğŸ¦´ Is it a dog?", "âœ… Yes" if is_dog else "âŒ No")


# âœ… Load pretrained ResNet18
model = models.resnet18(pretrained=True)
model.eval()

# âœ… Hook to get final conv feature map
features = []

def hook_fn(module, input, output):
    features.append(output)

model.layer4.register_forward_hook(hook_fn)  # ë§ˆì§€ë§‰ conv block

# âœ… Predict
with torch.no_grad():
    output = model(input_tensor)
    pred_class = output.argmax(dim=1).item()

# âœ… Get weights from the final linear layer
params = list(model.parameters())
fc_weights = params[-2]  # shape: [1000, 512]
class_weights = fc_weights[pred_class].detach().cpu().numpy()  # [512]

# âœ… Get feature map from hook
feature_map = features[0].squeeze(0).detach().cpu().numpy()  # [512, 7, 7]

# âœ… Compute CAM
cam = np.zeros((7, 7), dtype=np.float32)
for i in range(len(class_weights)):
    cam += class_weights[i] * feature_map[i]

# Normalize & resize
cam = np.maximum(cam, 0)
cam = cam - np.min(cam)
cam = cam / np.max(cam)
cam = cv2.resize(cam, (224, 224))
heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)

# âœ… Overlay CAM on original image
img_cv = np.array(transforms.Resize((224, 224))(img))[:, :, ::-1]  # PIL â†’ OpenCV BGR
overlay = cv2.addWeighted(img_cv, 0.5, heatmap, 0.5, 0)

# âœ… Show
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(img)
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title(f"CAM: {imagenet_classes[pred_class]}")
plt.imshow(overlay[:, :, ::-1])  # Back to RGB
plt.axis('off')
plt.tight_layout()
plt.show()

# âœ… ê²°ê³¼ í…ìŠ¤íŠ¸ ì¶œë ¥
print(f"Predicted label: {imagenet_classes[pred_class]}")
print("ğŸ¦´ Is it a dog?", "âœ… Yes" if pred_class in dog_classes else "âŒ No")
```
</details>