---
layout: post
title: "🧠 OSrCIR: Reason-before-Retrieve for Composed Image Retrieval"
author: [DrFirst]
date: 2025-07-29 09:00:00 +0900
categories: [AI, Research]
tags: [MLLM, CIR, Image Retrieval, CVPR 2025, Reasoning, One-Stage, CVPR, CVPR 2025 ]
sitemap :
  changefreq : monthly
  priority : 0.8

---

---


### 🧠 (한국어) OSrCIR: Reason-before-Retrieve 블라블라블라

- **제목**: [Reason-before-Retrieve: One-Stage Reflective Chain-of-Thoughts for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/pdf/2412.11077)  
- **학회**: CVPR 2025 (Highlight paperYuanmin Tang et al.)  
- **코드**: [osrcir (GitHub)](https://github.com/Pter61/osrcir)  
- **핵심 키워드**: `Composed Image Retrieval`, `Chain-of-Thought`, `One-Stage`, `MLLM`, `Zero-Shot`

---

## 📌 3줄 요약

1. 기존의 **이미지+텍스트 조합 검색(CIR)** 은 대부분 **2-Stage 구조** (이미지 캡션 → 텍스트 추론) 사용  
2. OSrCIR은 MLLM이 Reference 이미지를 **직접 reasoning하여**, 텍스트 없이 **Target 이미지의 특성 자체를 추론**  
3. 결과적으로 정확도/속도 향상, **사전 학습 없이 zero-shot inference만으로** 작동 가능

---

## 🔍 기존 CIR 구조의 한계

| 방식 | 구조 | 문제점 |
|------|------|--------|
| 2-Stage CIR | (1) 이미지 → 캡션 생성 (2) 텍스트 → 추론 → 검색 | 이미지 정보 손실, reasoning 오류 발생 |
| Text-Only Reasoning | Reference 이미지 정보를 간접적으로 전달 | 시각적 속성 반영 어려움 |
| MLLM 활용 방식 | 질문 응답으로 간접 reasoning | 시간 소요, 일관성 부족 |

→ 즉, **텍스트를 중간 매개로 삼는 방식 자체가 본질적인 정보 손실을 유발**함.

---

## 🌱 OSrCIR의 핵심 아이디어

> “**Reason first. Then retrieve.**”

- 기존 CIR은 “Retrieve-and-Reason” 방식  
- **OSrCIR은 반대로 ‘Reason-before-Retrieve’**  
- **MLLM을 사용해 이미지에서 직접 target 특성 추론**  
- 이 reasoning 결과(텍스트)를 기반으로 Target 이미지 검색 수행

---

## 🔧 OSrCIR 아키텍처 요약

![arch](https://github.com/OSoMeLab/osrcir/assets/osrcir_arch.png)

- **입력**: (Reference Image, Text Query)
- **Stage 1**: MLLM을 활용해 Reference 이미지에 대해 chain-of-thought 스타일 추론 수행  
- **Stage 2**: 추론 결과를 텍스트 쿼리로 정제
- **Stage 3**: 검색 후보 이미지들과 CLIP 기반 텍스트-이미지 매칭 수행 (zero-shot)

→ 전체 과정이 end-to-end로 **단일 단계(one-stage)** 에서 처리됨

---

## 🧪 실험 결과 요약

> 주요 벤치마크에서 **기존 2-Stage 방법들보다 정확도 + 효율 모두 우수**한 성과 달성!

| Dataset | Recall@1 (기존 SOTA) | OSrCIR | 향상폭 |
|---------|-----------------------|--------|--------|
| CIRR    | 52.1 (FashionIQ-CLIP) | **57.4** | +5.3   |
| CIRCO   | 33.8                 | **37.9** | +4.1   |
| FashionIQ | 48.7               | **54.2** | +5.5   |

- **Zero-shot 설정**에서 실현됨 (학습 없이 inference만으로)
- Ablation 결과, reasoning을 생략하면 성능 급락

---

## ✅ 결론 및 의의

- OSrCIR은 MLLM의 고차 reasoning 능력을 CIR에 **최적화된 방식**으로 끌어낸 대표적 사례  
- 별도 학습 없이 inference만으로 동작 → **Training-free + Generalizable**
- **Chain-of-Thought reasoning이 단일 스테이지 retrieval에 직접 적용된 최초 사례 중 하나**
- 향후 VLM 기반 **튜터링, 검색, AGI planning 등**에서의 응용 가능성 매우 큼

> “Retrieval is not just about matching. It’s about **reasoning what to match**.”