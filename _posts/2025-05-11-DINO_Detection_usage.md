---
layout: post
title: "ğŸ–¥ï¸ DINO Practice: Running Object Detection with Pretrained Models - DINO ì‹¤ìŠµ: ëª¨ë¸ì„ ë°›ì•„ ì§ì ‘ ê°ì²´ íƒì§€ í•´ë³´ê¸°!"
author: [DrFirst]
date: 2025-05-11 07:00:00 +0900
categories: [AI, Experiment]
tags: [DETR, DINO, ê°ì²´ íƒì§€, Object Detection, Transformer, ë”¥ëŸ¬ë‹, CV, ICLR, ICLR 2023, python, íŒŒì´ì¬ ì‹¤ìŠµ]
lastmod : 2025-05-11 07:00:00
sitemap :
  changefreq : weekly
  priority : 0.9
---

## (English) ğŸ¦– DINO Practice: Running Object Detection with Pretrained Models!

> In the [previous post](https://drfirstlee.github.io/posts/DINO_Detection), I studied the core ideas behind DINO!!!  
> Now, letâ€™s dive into actually **installing the DINO model from GitHub** and running **object detection** on our own images~!

![result](https://github.com/user-attachments/assets/eb9b3c27-7d8e-458a-afa3-936685f31b87)

- Starting with the result, as always!!  
- Just like DETR, it detects multiple objects in the image and visualizes them!!  
- Letâ€™s walk through each step together in Python code!  
- This time, thereâ€™s no simple pip install â€“ we need to download and build from the GitHub repo. Letâ€™s get started!! ğŸ˜„

---

### ğŸ”— 1. Clone the DINO repository from GitHub

> ğŸ”— [Official GitHub Repo](https://github.com/IDEA-Research/DINO)

A very well-organized GitHub repository.  
Huge thanks to the author!! ğŸ™

---

### ğŸ“¦ 2. Create a virtual environment and install dependencies

```bash
conda create --name DINO python=3.9
conda activate DINO

sudo apt update && sudo apt install -y build-essential python3-dev
pip install cython

conda install -c conda-forge libstdcxx-ng
conda install -c pytorch pytorch torchvision

pip install -r requirements.txt
```

---

### âš™ï¸ 3. Build and test the model code

```bash
cd models/dino/ops
python setup.py build install

# Unit test - should print all True if successful
python test.py

cd ../../..
```

---

### ğŸ—‚ï¸ 4. Prepare the COCO2017 dataset

Organize the COCO dataset as follows:

```text
COCODIR/
â”œâ”€â”€ train2017/
â”œâ”€â”€ val2017/
â””â”€â”€ annotations/
    â”œâ”€â”€ instances_train2017.json
    â””â”€â”€ instances_val2017.json
```


### ğŸ“¥ 5. Download Pretrained Model

You can download the pretrained **DINO-4scale, Swin-L (36 epochs)** model from the following Google Drive link:

> ğŸ”— https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing

---

### ğŸ§  6. Load the Model and Run Inference

#### Import Packages

```python
import os, sys
import torch, json
import numpy as np

from main import build_model_main
from util.slconfig import SLConfig
from datasets import build_dataset
from util.visualizer import COCOVisualizer
from util import box_ops

from PIL import Image
import datasets.transforms as T
```

#### Load COCO Class ID-to-Name Mapping

```python
with open('{your_path1}/DINO/util/coco_id2name.json') as f:
    id2name = json.load(f)
    id2name = {int(k):v for k,v in id2name.items()}
```

#### Load Model Configuration and Checkpoint

```python
model_config_path = "{your_path1}/DINO/config/DINO/DINO_4scale.py"
model_checkpoint_path = "{your_path2}/checkpoint0033_4scale.pth"

args = SLConfig.fromfile(model_config_path) 
args.device = 'cuda' 
model, criterion, postprocessors = build_model_main(args)

checkpoint = torch.load(model_checkpoint_path, map_location='cpu')
model.load_state_dict(checkpoint['model'])
_ = model.eval()
```

#### Load and Preprocess the Image

```python
image = Image.open("{image_path}/catch_rugby_ball_001480.jpg").convert("RGB")

transform = T.Compose([
    T.RandomResize([800], max_size=1333),
    T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
image, _ = transform(image, None)
```

#### Run Inference

```python
output = model.cuda()(image[None].cuda())
output = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]
```

---

### ğŸ–¼ï¸ 7. Visualize the Results

```python
thershold = 0.3  # set confidence threshold

vslzr = COCOVisualizer()

scores = output['scores']
labels = output['labels']
boxes = box_ops.box_xyxy_to_cxcywh(output['boxes'])
select_mask = scores > thershold

box_label = [id2name[int(item)] for item in labels[select_mask]]
pred_dict = {
    'boxes': boxes[select_mask],
    'size': torch.Tensor([image.shape[1], image.shape[2]]),
    'box_label': box_label
}

vslzr.visualize(image, pred_dict, savedir=None, dpi=100)
```

And just like that â€“ boom! The detection works beautifully! ğŸ™Œ

![result](https://github.com/user-attachments/assets/eb9b3c27-7d8e-458a-afa3-936685f31b87)

---

### âœ… Wrap-Up

At first, I was a bit nervous about using models not yet uploaded to `timm` or HuggingFace,  
but once I got into it, everything was quite manageable!  
Especially in this case, the DINO repo was incredibly well organized,  
which made the process even smoother.

I'll continue experimenting with more models and sharing my findings. Stay tuned! ğŸš€

---

## (í•œêµ­ì–´) ğŸ¦– DINO ì‹¤ìŠµ: ëª¨ë¸ì„ ë°›ì•„ ì§ì ‘ ê°ì²´ íƒì§€ í•´ë³´ê¸°!

> [ì§€ë‚œ í¬ìŠ¤íŒ…](https://drfirstlee.github.io/posts/DINO_Detection) ì—ì„œ DINOì˜ ì›ë¦¬ì— ëŒ€í•˜ ê³µë¶€í•´ë³´ì•˜ìŠµë‹ˆë‹¤!!!    
> ì´ì  , DINO ëª¨ë¸ì„ git repoë¡œë¶€í„° **ì§ì ‘ ì„¤ì¹˜**í•˜ì—¬ ê°ì²´ íƒì§€(Object Detection)ì„ ì§„í–‰í•´ ë³´ê² ìŠµë‹ˆë‹¤~!   

![result](https://github.com/user-attachments/assets/eb9b3c27-7d8e-458a-afa3-936685f31b87)

- ì˜¤ëŠ˜ë„ë„ ê²°ë¡ ë¶€í„°!!!  
- DETRê³¼ ë™ì¼í•˜ê²Œ ì´ë¯¸ì§€ì—ì„œ íƒì§€ëœ ì—¬ëŸ¬ ê°ì²´ë“¤ì„ ì°¾ì•„ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤!!  
- í•¨ê»˜, íŒŒì´ì¬ ì½”ë“œë¡œ ê·¸ ê³¼ì •ì„ ì•Œì•„ë³´ì•„ìš”!!  
- ì´ë²ˆì—ëŠ” ê°„ë‹¨í•œ ëª¨ë¸ì´ ì—†ì–´ git ì—ì„œ ëª¨ë¸ì„ ë°›ê³  ì„¤ì¹˜í•´ì•¼í•©ë‹ˆë‹¤~ ì˜ ë”°ë¼í•´ë³´ì„¸ìš”!!^^  



### ğŸ”— 1. GIT ì €ì¥ì†Œì—ì„œ DINO ëª¨ë¸ ë°›ê¸°!!

> ğŸ”— [ê³µì‹ GitHub ì €ì¥ì†Œ](https://github.com/IDEA-Research/DINO)

ì•„ì£¼ ì˜ ì •ë¦¬ëœ git repoì…ë‹ˆë‹¤~!  
ì‘ì„±ìë¶„ê»˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤!!^^  

---

### ğŸ“¦ 2. ê°€ìƒí™˜ê²½ ë° ì˜ì¡´ì„± ì„¤ì¹˜

```bash
conda create --name DINO python=3.9
conda activate DINO

sudo apt update && sudo apt install -y build-essential python3-dev
pip install cython

conda install -c conda-forge libstdcxx-ng
conda install -c pytorch pytorch torchvision

pip install -r requirements.txt
```

---

### âš™ï¸ 3. ëª¨ë¸ ì½”ë“œ ì»´íŒŒì¼ ë° í…ŒìŠ¤íŠ¸

```bash
cd models/dino/ops
python setup.py build install

# ìœ ë‹› í…ŒìŠ¤íŠ¸ - ëª¨ë‘ Trueê°€ ì¶œë ¥ë˜ë©´ ì„±ê³µ
python test.py

cd ../../..
```
---

### ğŸ—‚ï¸ 4. COCO2017 ë°ì´í„°ì…‹ ì¤€ë¹„

COCO2017 ë°ì´í„°ë¥¼ ì•„ë˜ êµ¬ì¡°ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤:

```text
COCODIR/
â”œâ”€â”€ train2017/
â”œâ”€â”€ val2017/
â””â”€â”€ annotations/
â”œâ”€â”€ instances_train2017.json
â””â”€â”€ instances_val2017.json
```
---



### ğŸ“¥ 5. ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

DINO-4scale, Swin-L, 36 epoch ê¸°ì¤€ ëª¨ë¸ì€ ì•„ë˜ Google Drive ë§í¬ì—ì„œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤:

> ğŸ”— https://drive.google.com/drive/folders/1qD5m1NmK0kjE5hh-G17XUX751WsEG-h_?usp=sharing


---

### ğŸ§  6. ëª¨ë¸ ë¡œë“œ ë° ì´ë¯¸ì§€ ì˜ˆì¸¡

#### íŒ¨í‚¤ì§€ ì„í¬íŠ¸

```python
import os, sys
import torch, json
import numpy as np

from main import build_model_main
from util.slconfig import SLConfig
from datasets import build_dataset
from util.visualizer import COCOVisualizer
from util import box_ops

from PIL import Image
import datasets.transforms as T
```

#### COCO í´ë˜ìŠ¤ ID ë§¤í•‘ íŒŒì¼ ë¡œë“œ

```python
with open('{ì•Œë§ì€ìœ„ì¹˜1}/DINO/util/coco_id2name.json') as f:
    id2name = json.load(f)
    id2name = {int(k):v for k,v in id2name.items()}
```

#### ëª¨ë¸ êµ¬ì„± ë° ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ

```python
model_config_path = "{ì•Œë§ì€ìœ„ì¹˜1}/DINO/config/DINO/DINO_4scale.py"
model_checkpoint_path = "{ì•Œë§ì€ìœ„ì¹˜2}/checkpoint0033_4scale.pth"

args = SLConfig.fromfile(model_config_path) 
args.device = 'cuda' 
model, criterion, postprocessors = build_model_main(args)

checkpoint = torch.load(model_checkpoint_path, map_location='cpu')
model.load_state_dict(checkpoint['model'])
_ = model.eval()
```

#### ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬

```python
image = Image.open("{ì´ë¯¸ì§€ìœ„ì¹˜}/catch_rugby_ball_001480.jpg").convert("RGB")

transform = T.Compose([
    T.RandomResize([800], max_size=1333),
    T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
image, _ = transform(image, None)
```

#### ì´ë¯¸ì§€ ì˜ˆì¸¡

```python
output = model.cuda()(image[None].cuda())
output = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]
```

---

### ğŸ–¼ï¸ 7. ê²°ê³¼ ì‹œê°í™”

```python
thershold = 0.3  # ì„ê³„ê°’ ì„¤ì •

vslzr = COCOVisualizer()

scores = output['scores']
labels = output['labels']
boxes = box_ops.box_xyxy_to_cxcywh(output['boxes'])
select_mask = scores > thershold

box_label = [id2name[int(item)] for item in labels[select_mask]]
pred_dict = {
    'boxes': boxes[select_mask],
    'size': torch.Tensor([image.shape[1], image.shape[2]]),
    'box_label': box_label
}

vslzr.visualize(image, pred_dict, savedir=None, dpi=100)
```

í•˜ë©´~~ ì§  ì•„ë˜ì™€ ê°™ì´!! ì˜ detection í•˜ë„¤ìš”~~  

![result](https://github.com/user-attachments/assets/eb9b3c27-7d8e-458a-afa3-936685f31b87)

---

### âœ… ë§ˆë¬´ë¦¬

timm, huggingface ë“±ì— ëª¨ë¸ì´ ì—…ë°ì´íŠ¸ ë˜ì§€ ì•Šìœ¼ë©´ ë§Œë§Œì¹˜ ì•Šê² ë‹¤ë¼ëŠ” ë‘ë ¤ì›€ì´ìƒê¸°ì§€ë§Œ~,  
ë§‰ìƒ í•´ë³´ë©´ ë‹¤ í• ìˆ˜ ìˆìŠµë‹ˆë‹¤!  
íŠ¹íˆ ì´ë²ˆ DINOëŠ” ëª¨ë¸ ì—…ë¡œë“œí•œ ì‘ì„±ìê°€ ê¹”ë”í•˜ê²Œ ì •ë¦¬ë˜ì–´ìˆì–´ ë”ìš± ì‰½ê²Œí• ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤!!  

ì•ìœ¼ë¡œë„ ì—¬ëŸ¬ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤!!