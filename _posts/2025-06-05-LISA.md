---
layout: post
title: "🧠 Understanding SAM2   - SAM2 알아보기?!!"
author: [DrFirst]
date: 2025-06-05 07:00:00 +0900
categories: [AI, Research]
tags: [LISA, LLM, computer vision, CVPR, CVPR 2024, Segmentation]
sitemap :
  changefreq : monthly
  priority : 0.8
---

---

## 🧠 (한국어) LISA: 추론 기반 세그멘테이션의 새로운 지평  
_🔍 복잡한 언어 지시를 이해하고, 이미지에서 해당 영역을 분할하는 혁신적인 모델!_

> 논문: [LISA: Reasoning Segmentation via Large Language Model](https://arxiv.org/abs/2308.00692)  
> 발표: CVPR 2024 (by CUHK, MSRA, SmartMore)  
> 코드: [dvlab-research/LISA](https://github.com/dvlab-research/LISA)  
> 코멘트: LLM의 언어 이해 능력을 시각 분할에 접목한 획기적인 접근!

---

## ❗ 기존 시각 인식 시스템의 한계

> 대부분의 시각 인식 시스템은 명시적인 지시나 사전 정의된 범주에 의존하여 대상 객체를 식별합니다.  
> 이러한 시스템은 **암시적인 사용자 의도**를 이해하고 추론하는 능력이 부족합니다.

- **명시적 지시 필요**: 사용자가 직접적으로 대상 객체를 지정해야 함.  
- **사전 정의된 범주 의존**: 새로운 객체나 상황에 대한 유연한 대응이 어려움.  
- **복잡한 추론 부족**: "비타민 C가 많은 음식"과 같은 복잡한 지시를 이해하고 처리하는 데 한계가 있음.

➡️ 이러한 한계를 극복하기 위해, **복잡하고 암시적인 언어 지시를 기반으로 이미지에서 특정 영역을 분할하는 "추론 분할(reasoning segmentation)"**이라는 새로운 과제가 제안되었습니다.

---

## ✅ LISA의 핵심 특징!

### 🔍 1. 추론 분할(Reasoning Segmentation)

- **복잡한 언어 지시 이해**:  
  "이 이미지에서 미국 대통령이 누구인지 분할 마스크를 출력하고 이유를 설명하세요." 와 같은 지시 처리 가능  
- **세계 지식 활용**:  
  "비타민 C가 많은 음식" 등 실제 지식을 활용해 적절한 영역 분할  
- **설명 제공**:  
  분할 결과에 대한 **이유와 설명 생성 가능**

---

### 🧠 2. LISA 모델 구조

- **<SEG> 토큰 도입**:  
  새로운 토큰 `<SEG>`를 활용해, 임베딩 자체를 마스크로 해석하는 **embedding-as-mask** 패러다임 사용  
- **다중 모달 LLM 활용**:  
  대형 언어 모델의 언어 이해 능력을 시각 정보와 결합  
- **엔드 투 엔드 학습**:  
  언어 지시 + 이미지 → 직접 마스크 생성까지 이어지는 구조

---

### 📊 3. ReasonSeg 벤치마크

- **1,000개 이상 샘플** 포함  
- **세계 지식, 다중 턴 대화, 설명 기반 응답 등** 다양한 평가 항목  
- **복잡한 추론 능력 측정 가능한 새로운 기준 제시**

---

## 🏋️‍♂️ 학습 및 성능

- **제로샷 성능**:  
  복잡한 추론 데이터 없이도 놀라운 일반화 능력 발휘  
- **Few-shot 파인튜닝 지원**:  
  단 239개의 추론 분할 샘플로 성능 향상  
- **다양한 응용 시나리오**:  
  대화형 시스템, 로봇 비전, 인터랙티브 에이전트 등 가능

---

## 🔚 마무리

LISA는 단순히 객체를 인식하는 수준을 넘어,  
**언어적 추론을 기반으로 이미지의 의미를 해석하고 시각적으로 응답**할 수 있는 모델입니다.  

이는 인간-컴퓨터 상호작용, 로봇 비전, 스마트 UI 등  
다양한 AI 시스템의 새로운 표준이 될 수 있는 가능성을 제시합니다.

---
