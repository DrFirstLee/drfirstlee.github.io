---
layout: post
title: "ğŸ–¥ï¸ SEEM Practice!! - SEEM ì‹¤ìŠµ!! with python. gradio"
author: [DrFirst]
date: 2025-06-08 09:00:00 +0900
categories: [AI, Experiment]
tags: [LISA, Segment Anything, Image Segmentation, Python,  CVPR, CVPR 2024]
sitemap :
  changefreq : weekly
  priority : 0.9
---

---

## ğŸ¦– (English) SEEM Model Practice!!
> **SEEM**: Segment Everything Everywhere All At Once

We previously introduced **SEEM** in [this post](https://drfirstlee.github.io/posts/SEEM/).  
This time, we'll go through a hands-on tutorial using the SEEM model!

---

### ğŸ§± 1. SEEM Git Clone

Clone the official repository from the [GitHub page](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once/tree/v1.0):

```bash
git clone git@github.com:UX-Decoder/Segment-Everything-Everywhere-All-At-Once.git
```

---

### ğŸ“¦ 2. Required Packages in Virtual Environment

I used a `conda` virtual environment to install the required packages:

```bash
conda create -n seem python=3.9 -y
conda activate seem
```

Then install the dependencies from the repo:

```bash
# Python Package Installation
pip install -r assets/requirements/requirements.txt
pip install -r assets/requirements/requirements_custom.txt

# Custom Operator [only needed for training deformable vision encoder]
cd modeling/vision/encoder/ops && sh make.sh && cd ../../../../

# System Package [only needed for SEEM demo]
sudo apt update
sudo apt install ffmpeg
```

Note: I encountered an error while installing `mpi4py`, so I adjusted some variables:

```bash
mpicc --version
which mpicc
export LD=ld
export CC=mpicc
export CXX=mpicxx
pip install --no-cache-dir --force-reinstall mpi4py
```

---

### ğŸ§Š 3. Run the SEEM Model

Execute the command from the `demo` directory:  
The model will automatically download and launch a gradio-based interface!

```bash
export PYTHONPATH=$(pwd)  # Required to avoid ModuleNotFoundError: No module named 'modeling'
python demo/seem/app.py
```

You will see logs like the following:

```bash
  inputs = [ImageMask(label="[Stroke] Draw on Image",type="pil"), gr.inputs.CheckboxGroup(choices=["Stroke", "Example", "Text", "Audio", "Video", "Panoptic"], type="value", label="Interative Mode"), ImageMask(label="[Example] Draw on Referring Image",type="pil"), gr.Textbox(label="[Text] Referring Text"), gr.Audio(label="[Audio] Referring Audio", source="microphone", type="filepath"), gr.Video(label="[Video] Referring Video Segmentation",format="mp4",interactive=True)]
.../demo/seem/app.py:131: GradioDeprecationWarning: `optional` parameter is deprecated
.../demo/seem/app.py:136: GradioDeprecationWarning: gr.outputs is deprecated, use gradio.components instead
Running on local URL:  http://0.0.0.0:8507
IMPORTANT: You are using gradio version 3.42.0, however version 4.44.1 is available.
--------
Running on public URL: https://98c5c3e82a6870cfe5.gradio.live

This share link expires in 72 hours.
```

Now, if you open `https://98c5c3e82a6870cfe5.gradio.live`, youâ€™ll be able to access the environment!  
(Note: Since I wonâ€™t keep the server running, please use your own URL.)

Hereâ€™s what the interface looks like:

![ui](https://github.com/user-attachments/assets/63501abe-a52f-4aef-ba78-7e91b8d3e2cf)

- Interactive Mode: You can try various prompts including stroke, text, audio, etc.

---

### ğŸ§Š 4. SEEM Model Testing

Letâ€™s try some tests!

> Text prompt: "A person using a computer on the couch" â€“ worked really well!  
![test1](https://github.com/user-attachments/assets/00cad703-1ce2-4f76-b7ab-40fb7ce75ab9)

> Segmentation based on keywords works great too!  
![test2](https://github.com/user-attachments/assets/f571265b-8937-4302-be4b-4cf422dda6e5)

> If you just upload an image, it automatically segments objects and labels them!  
![test3](https://github.com/user-attachments/assets/6fa6b962-90ae-46d1-bbcd-4cb6ffe0b9a3)

> Using the stroke feature, it segments only the selected region and even labels it!  
![test4](https://github.com/user-attachments/assets/80bcb736-8b52-4842-a40e-fc5eacd1efc9)

---

### ğŸ‰ Conclusion

SEEM truly feels like the peak of current segmentation models.  
Its flexibility and ease of use are simply amazing!

---

## ğŸ¦–(í•œêµ­ì–´) SEEM ëª¨ë¸ ì‹¤ìŠµ!!
> **SEEM** : Segment Everything Everywhere All At Once

[ì§€ë‚œ í¬ìŠ¤íŒ…](https://drfirstlee.github.io/posts/SEEM/) ì—ì„œ ì•Œì•„ë³´ì•˜ë˜ **SEEM**!!  
ì´ë²ˆ í¬ìŠ¤íŒ…ì€ ì´ `SEEM` ëª¨ë¸ì˜ ì‹¤ìŠµì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤!!  

---

### ğŸ§± 1. SEEM Git Clone 

- [ê³µì‹ Git ì‚¬ì´íŠ¸](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once/tree/v1.0)ì—ì„œ Repoë¥¼ Clone í•©ë‹ˆë‹¤!!

```bash
git@github.com:UX-Decoder/Segment-Everything-Everywhere-All-At-Once.git
```

---

### ğŸ“¦ 2. ê°€ìƒí™˜ê²½ì—ì„œì˜ í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜!!

ì €ëŠ” conda ê°€ìƒí™˜ê²½ì—ì„œ í•„ìš” íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í–ˆìŠµë‹ˆë‹¤!!

```bash
conda create -n seem python=3.9 -y
conda activate seem
```

ì´ì œ, repoì—ì„œ ì œê³µí•˜ëŠ” requirementsë¥¼ ì„¤ì¹˜í•´ì¤ë‹ˆë‹¤!

```bash
# Python Package Installation
pip install -r assets/requirements/requirements.txt
pip install -r assets/requirements/requirements_custom.txt

# Customer Operator [only need training deformable vision encoder]
cd modeling/vision/encoder/ops && sh make.sh && cd ../../../../

# System Package [only need for demo in SEEM]
sudo apt update
sudo apt install ffmpeg
```

ì—¬ê¸°ì„œ!! ì €ëŠ” mpi4pyì„¤ì¹˜ì—ì„œ ì—ëŸ¬ê°€ ìƒê²¼ì–´ì„œ  
ì•„ë˜ì™€ ê°™ì´ ë³€ìˆ˜ë¥¼ ì¡°ê¸ˆ ë°”ê¾¸ì–´ì£¼ì—ˆì—ˆìŠµë‹ˆë‹¤!  

```bash
mpicc --version
which mpicc
export LD=ld
export CC=mpicc
export CXX=mpicxx 
pip install --no-cache-dir --force-reinstall mpi4py
```
 

---


### ğŸ§Š 3. SEEM ëª¨ë¸ ì‹¤í–‰!!

ì•„ë˜ì™€ ê°™ì´ demoí´ë”íƒœì˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´!!  
ì•Œì•„ì„œ ëª¨ë¸ì„ ì˜ ë°›ê³ !!  
gradio ê¸°ë°˜ì˜ ì‚¬ì´íŠ¸ê°€ ì‹œì‘ë©ë‹ˆë‹¤!!  

``` bash
export PYTHONPATH=$(pwd) # ì•„ë‹ˆë©´ ModuleNotFoundError: No module named 'modeling' ë¼ëŠ” ì—ëŸ¬ê°€ ëœ¹ë‹ˆë‹¤!
python demo/seem/app.py
```

ê·¸ëŸ¼!! ëª¨ë¸ì„ ë‹¤ìš´ë°›ìœ¼ë©° ì•„ë˜ì™€ ê°™ì´ ì£¼ë£¨ë¥µ ë¡œê·¸ê°€ ë•ë‹ˆë‹¤~!

```bash
  inputs = [ImageMask(label="[Stroke] Draw on Image",type="pil"), gr.inputs.CheckboxGroup(choices=["Stroke", "Example", "Text", "Audio", "Video", "Panoptic"], type="value", label="Interative Mode"), ImageMask(label="[Example] Draw on Referring Image",type="pil"), gr.Textbox(label="[Text] Referring Text"), gr.Audio(label="[Audio] Referring Audio", source="microphone", type="filepath"), gr.Video(label="[Video] Referring Video Segmentation",format="mp4",interactive=True)]
.../Segment-Everything-Everywhere-All-At-Once/demo/seem/app.py:131: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect
  inputs = [ImageMask(label="[Stroke] Draw on Image",type="pil"), gr.inputs.CheckboxGroup(choices=["Stroke", "Example", "Text", "Audio", "Video", "Panoptic"], type="value", label="Interative Mode"), ImageMask(label="[Example] Draw on Referring Image",type="pil"), gr.Textbox(label="[Text] Referring Text"), gr.Audio(label="[Audio] Referring Audio", source="microphone", type="filepath"), gr.Video(label="[Video] Referring Video Segmentation",format="mp4",interactive=True)]
.../Segment-Everything-Everywhere-All-At-Once/demo/seem/app.py:136: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components
  gr.outputs.Image(
Running on local URL:  http://0.0.0.0:8507
IMPORTANT: You are using gradio version 3.42.0, however version 4.44.1 is available, please upgrade.
--------
Running on public URL: https://98c5c3e82a6870cfe5.gradio.live

This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)
```

ê·¸ëŸ¼!! 
`https://98c5c3e82a6870cfe5.gradio.live` ë¡œ ì ‘ì†í•´ë³´ë©´ ì´ì œ í™˜ê²½ì— ì ‘ì†ì´ ëœê²ƒì…ë‹ˆë‹¤!!  
(ì €ëŠ” ì´ ì„œë²„ë¥¼ ê³„ì† ì¼œë‘ì§€ ì•Šì„ê²ƒì´ê¸°ì— ì œ urlì´ ì•„ë‹ˆë¼ ì—¬ëŸ¬ë¶„ì˜ urlë¡œ ì ‘ì†í•˜ì„¸ìš”!!)

ì•„ë˜ì™€ ê°™ì€ í™”ë©´ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!

![ui](https://github.com/user-attachments/assets/63501abe-a52f-4aef-ba78-7e91b8d3e2cf)

 - Interative Mode : stroke (ì´ë¯¸ì§€ì— í‘œì‹œí•˜ê¸°), text, audio  ë“± í”„ë¡¬í¬íŠ¸ë¥¼ ë„£ì„ìˆ˜ ìˆìŠµë‹ˆë‹¤!


### ğŸ§Š 4. SEEM ëª¨ë¸ í…ŒìŠ¤íŠ¸!!

ì´ì œ. í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ë´…ì‹œë‹¤!!  

> ì†ŒíŒŒì—ì„œ ì»´í“¨í„°í•˜ëŠ” ì‚¬ëŒì— ëŒ€í•œ í…ìŠ¤íŠ¸ í”„ë¡¬í¬íŠ¸ í…ŒìŠ¤íŠ¸! ì•„ì£¼ì¢‹ì•„!
![test1](https://github.com/user-attachments/assets/00cad703-1ce2-4f76-b7ab-40fb7ce75ab9)

> ë‹¨ì–´ì— ëŒ€í•œ segmentation ë„ ì˜í•´ìš”~!
![test2](https://github.com/user-attachments/assets/f571265b-8937-4302-be4b-4cf422dda6e5)

> ê·¸ëƒ¥ ì´ë¯¸ì§€ë§Œ ë„£ëŠ”ë‹¤ë©´!? ì•Œì•„ì„œ segmentation í•˜ê³  ì´ë¦„ê¹Œì§€!!  
![test3](https://github.com/user-attachments/assets/6fa6b962-90ae-46d1-bbcd-4cb6ffe0b9a3)

> ì´ë²ˆì—” stroke ê¸°ëŠ¥ì„ ì¨ì„œí•˜ë©´!@? ê·¸ë¶€ë¶„ë§Œ segmentation í•˜ê³  ì´ë¦„ê¹Œì§€!!  
![test4](https://github.com/user-attachments/assets/80bcb736-8b52-4842-a40e-fc5eacd1efc9)

---

### ğŸ‰ ë§ˆë¬´ë¦¬

SEEM, ê·¸ë™ì•ˆì˜ segmentation ì˜ ì •ì ì¸ë“¯! ììœ ìì œë¡œ ë„ˆë¬´ ë©‹ì§€ë„¤ìš”!  