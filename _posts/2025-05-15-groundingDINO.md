---
layout: post
title: "Grounding DINO ë…¼ë¬¸ ê³µë¶€!"
author: [DrFirst]
date: 2025-05-15 15:00:00 +0900
categories: [AI, Research]
tags: [grounding, grounding dino, grounded sam, DINO, computer vision, AI ,ECCV, ECCV 2024, DETR]
sitemap :
  changefreq : monthly
  priority : 0.8
---


---

## (í•œêµ­ì–´) ðŸ“ Grounding DINO ì•Œì•„ë³´ê¸°!!
_ã€ŽGrounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detectionã€(ECCV, 2024) ê³µë¶€_

ðŸ“– **ë…¼ë¬¸ ì œëª©**: Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection  
âœï¸ **ì €ìž**: Xinyu Chen, Xueyan Zou, Ze Liu, et al.  
ðŸŒŸ **í•œì¤„ ìš”ì•½**: ì œì‹œëœ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ê°ì²´ íƒì§€ê¸°!

- ì˜¤ëŠ˜ì€ [ì‹¤ìŠµì„ ë¨¼ì € ì§„í–‰í•´ë³´ì•˜ë˜](https://drfirstlee.github.io/posts/groundingDINO_Detection_usage/) Grounding DINO ëª¨ë¸ì˜ ë…¼ë¬¸ì„ ê³µë¶€í•´ë³´ê³ ìží•©ë‹ˆë‹¤!!  

---

### ðŸ§  í•µì‹¬ ì•„ì´ë””ì–´ ìš”ì•½

#### 1ï¸âƒ£ DINO ê¸°ë°˜ êµ¬ì¡°ì™€ ëª¨ë‹¬ ìœµí•© ê°•í™”

![detector_structure]()

- Grounding DINOëŠ” **Transformer ê¸°ë°˜ ê°ì²´ íƒì§€ê¸°ì¸ DINO**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë¨.
- ê¸°ì¡´ Faster R-CNN êµ¬ì¡°ì™€ ë‹¬ë¦¬, DINOëŠ” **í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ê°„ layer-level ìœµí•©**ì´ ìžì—°ìŠ¤ëŸ½ê²Œ ê°€ëŠ¥í•œ êµ¬ì¡°ë¥¼ ê°€ì§.
- **Neck(phase A), Query Initialization(phase B), Head(phase C)** ë‹¨ê³„ ëª¨ë‘ì—ì„œ **cross-modality fusion**ì´ ì´ë£¨ì–´ì§€ë„ë¡ ì„¤ê³„í•˜ì—¬, í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì²´ íƒì§€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚´.

#### 2ï¸âƒ£ Grounded Pretrainingì„ í†µí•œ Open-Set ì¼ë°˜í™”
- CLIPì€ ì´ë¯¸ì§€ ì „ì²´ ìˆ˜ì¤€ì—ì„œëŠ” ë›°ì–´ë‚˜ì§€ë§Œ, ì˜ì—­(region) ìˆ˜ì¤€ í…ìŠ¤íŠ¸ ëŒ€ì‘ì—ëŠ” í•œê³„ê°€ ì¡´ìž¬.  
- ì´ëŸ° CLIP ê¸°ë°˜ zero-shot ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, **region-text ìŒì— ëŒ€í•œ contrastive pretraining**ì„ ë„ìž….
- GLIPì˜ phrase grounding ë°©ì‹ì„ ê°œì„ í•˜ì—¬, **sub-sentence ë‹¨ìœ„ í…ìŠ¤íŠ¸ ì²˜ë¦¬**ë¥¼ í†µí•´ í´ëž˜ìŠ¤ ê°„ ê°„ì„­ì„ ì¤„ìž„.
- ì´ë¡œì¨ Grounding DINOëŠ” **â€œí…ìŠ¤íŠ¸ â†’ íƒì§€â€ê°€ ê°€ëŠ¥í•œ open-set object detector**ë¡œì„œ, COCO ë° ODinW ë“±ì—ì„œ **zero-shot ì„±ëŠ¥ì˜ ìƒˆë¡œìš´ ê¸°ì¤€**ì„ ì œì‹œí•¨.


---

### ðŸ” Grounding DINO ì—°êµ¬ì˜ ë°°ê²½

Grounding DINOëŠ” ê¸°ì¡´ì˜ ê°ì²´ íƒì§€(Object Detection) ëª¨ë¸ë“¤ì´ ê°€ì§„ **ê³ ì •ëœ í´ëž˜ìŠ¤ ì œí•œ**ì„ ë›°ì–´ë„˜ê¸° ìœ„í•´ ì œì•ˆëœ ëª¨ë¸ìž…ë‹ˆë‹¤.  
ì´ì „ê¹Œì§€ì˜ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

---

#### ðŸ§© DETR ì´í›„ DINO, í•˜ì§€ë§Œ ì—¬ì „ížˆ í´ëž˜ìŠ¤ëŠ” ê³ ì •

- **[DETR](https://drfirstlee.github.io/posts/DETR/) (2020, Facebook AI)**  
  Transformer ê¸°ë°˜ìœ¼ë¡œ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•œ ìµœì´ˆì˜ end-to-end ëª¨ë¸  
  â†’ í•˜ì§€ë§Œ í´ëž˜ìŠ¤ëŠ” COCOì²˜ëŸ¼ **ì‚¬ì „ ì •ì˜ëœ í´ëž˜ìŠ¤ì…‹ì— í•œì •**ë¨

- **[DINO](https://drfirstlee.github.io/posts/DINO_Detection/) (ICLR 2023)**  
  DETR êµ¬ì¡°ë¥¼ ê°œì„ í•´ í•™ìŠµ ì•ˆì •ì„±ê³¼ ì •í™•ë„ë¥¼ ë†’ì¸ ëª¨ë¸  
  â†’ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ì§€ë§Œ **ì—¬ì „ížˆ ê³ ì •ëœ í´ëž˜ìŠ¤(class token)**ë§Œ íƒì§€ ê°€ëŠ¥

ì¦‰, DINOëŠ” **íƒì§€ëŠ” ìž˜í•˜ì§€ë§Œ 'ë¬´ì—‡ì„ íƒì§€í• ì§€'ëŠ” ì´ë¯¸ ì •í•´ì ¸ ìžˆì–´ì•¼** í–ˆìŠµë‹ˆë‹¤.

---

#### ðŸ§© Open-Set Object Detection, ì¦‰ ê³ ì •ëœ ê°ì²´ í•œê³„ë¥¼ ë„˜ì–´ì„œëŠ” ì—°êµ¬ë“¤  

##### ðŸ” GLIP, OV-DETR* ë“± ì†Œê°œ

ê¸°ì¡´ ê°ì²´ íƒì§€ëŠ” ì‚¬ì „ì— ì •ì˜ëœ í´ëž˜ìŠ¤(bounding box ì–´ë…¸í…Œì´ì…˜)ì—ë§Œ ë°˜ì‘í•˜ëŠ”  
**ê³ ì • í´ëž˜ìŠ¤ ê¸°ë°˜(closed-set)** íƒì§€ ë°©ì‹ì— í•œì •ë˜ì–´ ìžˆì—ˆìŠµë‹ˆë‹¤.  

ì´ì— ëŒ€í•´ **GLIP**(Grounded Language-Image Pre-training, Microsoft)ì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤:

- **ì˜¤í”ˆì…‹ ê°ì²´ íƒì§€ (Open-Set Object Detection)**  
- **ìž„ì˜ì˜ í´ëž˜ìŠ¤ (arbitrary class)**ì— ëŒ€í•œ íƒì§€ ìˆ˜í–‰  
- **ìžì—°ì–´ ê¸°ë°˜ ì¼ë°˜í™” (language generalization)**ë¥¼ í†µí•´ ìƒˆë¡œìš´ ê°ì²´ë¥¼ ì´í•´í•˜ê³  íƒì§€

ì¦‰, ì •í•´ì§„ ë¼ë²¨ ì—†ì´ë„ **í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ê°ì²´ë¥¼ íƒì§€í•  ìˆ˜ ìžˆëŠ” ëŠ¥ë ¥**ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

í•œíŽ¸, **OV-DETR**ì€ Transformer êµ¬ì¡° ê¸°ë°˜ì˜ ê°ì²´ íƒì§€ê¸°ë¡œ,  
ì–¸ì–´ ì •ë³´ê°€ í¬í•¨ëœ ì¿¼ë¦¬(query)ë¥¼ ë””ì½”ë”ì— ì§ì ‘ ì£¼ìž…í•˜ì—¬ open-vocabulary íƒì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

---

##### âš ï¸ ê¸°ì¡´ ì—°êµ¬ë“¤ì˜ í•œê³„ì 

ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ëª¨ë‘ **ì´ë¯¸ì§€ì™€ ì–¸ì–´ë¼ëŠ” ë©€í‹°ëª¨ë‹¬ ì •ë³´**ë¥¼  
**ì¼ë¶€ ëª¨ë“ˆì—ë§Œ êµ­í•œí•˜ì—¬ ìœµí•©(fusion)**í•¨ì— ë”°ë¼,  
**ì–¸ì–´ ê¸°ë°˜ ì¼ë°˜í™” ì„±ëŠ¥ì´ ìµœì ë³´ë‹¤ ë‚®ê²Œ(sub-optimal) ìž‘ë™í•  ê°€ëŠ¥ì„±**ì´ ì¡´ìž¬í•©ë‹ˆë‹¤.

---

##### ðŸ“Š ì˜ˆì‹œ: ë©€í‹°ëª¨ë‹¬ ê²°í•© ìœ„ì¹˜ ë¹„êµ

| ëª¨ë¸        | ë©€í‹°ëª¨ë‹¬ ê²°í•© ìœ„ì¹˜              | ì„¤ëª…                                          | í•œê³„ì  |
|-------------|----------------------------------|-----------------------------------------------|--------|
| **GLIP**    | Phase A (Feature Enhancement)    | ë°±ë³¸ ì´í›„ neck ë‹¨ê³„ì—ì„œ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ íŠ¹ì§• ìœµí•© | ì´í›„ ë””ì½”ë”ì™€ì˜ ì—°ê²°ì„± ë¶€ì¡± |
| **OV-DETR** | Phase B (Decoder Input)          | ë””ì½”ë”ì— ì–¸ì–´ ì¿¼ë¦¬(query)ë¥¼ ì§ì ‘ ì‚½ìž…           | ì´ˆê¸° ì‹œê° ì •ë³´ì™€ì˜ ê¹Šì€ ìœµí•© ë¶€ì¡± |

---

âž¡ï¸ ì´ëŸ¬í•œ êµ¬ì¡°ì  ì œì•½ì€,  
**í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ê°„ì˜ ê¹Šì´ ìžˆëŠ” ì •ë ¬(alignment)ì´ ìš”êµ¬ë˜ëŠ” open-vocabulary íƒì§€**ì—ì„œ  
**ì„±ëŠ¥ ì €í•˜** ë˜ëŠ” **ì¼ë°˜í™” í•œê³„**ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.


---

#### ðŸ—£ï¸ SAMì˜ ê°€ëŠ¥ì„±: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë¶„í• 

- **SAM (Segment Anything Model, 2023)**  
  í¬ì¸íŠ¸, ë°•ìŠ¤, ë§ˆìŠ¤í¬ ê¸°ë°˜ì˜ **ë²”ìš© ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸**  
  â†’ *Segment Anything*ì´ë¼ëŠ” ì´ë¦„ì— ê±¸ë§žê²Œ ì–´ë–¤ ê°ì²´ë“  ìž˜ë¼ë‚¼ ìˆ˜ ìžˆìŒ

- ê·¸ëŸ¬ë‚˜ SAMì€ **í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ìž…ë ¥í•´ segmentationì„ ìˆ˜í–‰í•  ìˆ˜ëŠ” ì—†ì—ˆìŒ**  
  (í…ìŠ¤íŠ¸ëŠ” ê°œë…ì ìœ¼ë¡œ ì œì‹œë˜ì—ˆì§€ë§Œ, ì‹¤ì œ í…ìŠ¤íŠ¸ ì¸ì‹ì„ í•˜ì§€ ì•ŠìŒ)

---

### ðŸ’¡ ê·¸ëž˜ì„œ ë“±ìž¥í•œ Grounding DINO!

Grounding DINOëŠ” ì´ëŸ¬í•œ ë‘ íë¦„ì„ **ìžì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°**í•©ë‹ˆë‹¤:

- **DINOì˜ ê°ì²´ íƒì§€ ëŠ¥ë ¥** + **í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ í•´ì„ ëŠ¥ë ¥(CLIP ê¸°ë°˜)**  
- â†’ ê²°êµ­ **"ë§ë¡œ íƒì§€í•˜ëŠ”(open-vocabulary) ê°ì²´ íƒì§€ê¸°"**ê°€ ëœ ê²ƒ!!  

ì´í›„ SAMê³¼ ê²°í•©í•˜ì—¬ **Grounded SAM**ìœ¼ë¡œ í™•ìž¥ë˜ë©°,  
"í…ìŠ¤íŠ¸ â†’ íƒì§€ â†’ ë¶„í• "ì´ë¼ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì™„ì„±ë©ë‹ˆë‹¤.  

---

### ðŸ§ª Grounding DINOì˜ êµ¬ì„±


#### ðŸ“ ì•„í‚¤í…ì²˜ ê°œìš”

Grounding DINOëŠ” **dual-encoder + single-decoder êµ¬ì¡°**ë¥¼ ì±„íƒí•©ë‹ˆë‹¤.  

êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1. **Image Backbone**: ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
2. **Text Backbone**: í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ
3. **Feature Enhancer**: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ íŠ¹ì§• ìœµí•© (Sec. 3.1)
4. **Language-Guided Query Selection**: ì¿¼ë¦¬ ì´ˆê¸°í™” (Sec. 3.2)
5. **Cross-Modality Decoder**: ë°•ìŠ¤ refinement ìˆ˜í–‰ (Sec. 3.3)

---

##### 3.1 ðŸ”§ Feature Extraction and Enhancer

- **ì´ë¯¸ì§€ íŠ¹ì§•**: Swin Transformerì™€ ê°™ì€ ë°±ë³¸ì„ í†µí•´ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ì¶”ì¶œ
- **í…ìŠ¤íŠ¸ íŠ¹ì§•**: BERT ê¸°ë°˜ì˜ ë°±ë³¸ìœ¼ë¡œ ì¶”ì¶œ
- **ìœµí•© ë°©ì‹**:
  - ì´ë¯¸ì§€: **Deformable self-attention**
  - í…ìŠ¤íŠ¸: **Vanilla self-attention**
  - í¬ë¡œìŠ¤ëª¨ë‹¬ ìœµí•©: 
    - **Image-to-Text Cross-Attention**
    - **Text-to-Image Cross-Attention**
  - ë‹¤ìˆ˜ì˜ Feature Enhancer Layerë¡œ êµ¬ì„±

ðŸ‘‰ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ì˜ íŠ¹ì§• ì •ë ¬(alignment)ì„ ìœ„í•œ í•µì‹¬ ëª¨ë“ˆ

---

##### 3.2 ðŸŽ¯ Language-Guided Query Selection

Grounding DINOëŠ” **ìž…ë ¥ í…ìŠ¤íŠ¸ì— ë”°ë¼ íƒì§€ ì¿¼ë¦¬ë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒ**í•©ë‹ˆë‹¤.

- ì´ë¯¸ì§€ íŠ¹ì§•: $X_I \in \mathbb{R}^{N_I \times d}$
- í…ìŠ¤íŠ¸ íŠ¹ì§•: $X_T \in \mathbb{R}^{N_T \times d}$  
  (ë³´í†µ $N_I > 10,000$, $N_T < 256$, $d = 256$)

- ëª©í‘œ: ì´ë¯¸ì§€ íŠ¹ì§•ì—ì„œ $N_q = 900$ê°œì˜ ì¿¼ë¦¬ë¥¼ ì„ íƒí•˜ì—¬ ë””ì½”ë”ì— ìž…ë ¥
- ì„ íƒ ì‹:

```
I_{N_q} = Top_{N_q}(Max^{(-1)}(X_I X_T^T))
```

- ì„ íƒëœ ì¸ë±ìŠ¤ë¡œë¶€í„° ì¿¼ë¦¬ íŠ¹ì§•ì„ ì¶”ì¶œí•´ ë””ì½”ë”ì— ìž…ë ¥
- ì¿¼ë¦¬ëŠ” ë‹¤ìŒ ë‘ êµ¬ì„±ìœ¼ë¡œ êµ¬ì„±ë¨:
- **Positional Part**: encoder ì¶œë ¥ìœ¼ë¡œë¶€í„° anchor box ì´ˆê¸°í™”
- **Content Part**: í•™ìŠµ ê°€ëŠ¥í•œ ì¿¼ë¦¬ ë²¡í„°

---

##### 3.3 ðŸ”„ Cross-Modality Decoder

- ê° ë””ì½”ë” ë ˆì´ì–´ëŠ” ë‹¤ìŒ ë¸”ë¡ìœ¼ë¡œ êµ¬ì„±ë¨:
1. **Self-Attention**
2. **Image Cross-Attention**
3. **Text Cross-Attention**
4. **Feed-Forward Network (FFN)**

- DINOì˜ ë””ì½”ë” êµ¬ì¡°ì— ë¹„í•´ **Text Cross-Attention ë¸”ë¡ì´ ì¶”ê°€**ë¨  
â†’ í…ìŠ¤íŠ¸ ì •ë³´ê°€ ì¿¼ë¦¬ ì—…ë°ì´íŠ¸ì— ë” ê°•í•˜ê²Œ ë°˜ì˜ë¨

---

##### 3.4 âœ‚ï¸ Sub-Sentence Level Text Feature

- ê¸°ì¡´ í…ìŠ¤íŠ¸ ì¸ì½”ë”© ë°©ì‹:
- **Sentence-level**: ë¬¸ìž¥ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì²˜ë¦¬ â†’ ì •ë°€ë„ ì†ì‹¤
- **Word-level**: ì—¬ëŸ¬ ë‹¨ì–´ë¥¼ í•œ ë²ˆì— ì¸ì½”ë”© â†’ ë‹¨ì–´ ê°„ ë¶ˆí•„ìš”í•œ ìƒí˜¸ìž‘ìš© ë°œìƒ

- ë¬¸ì œ: í…ìŠ¤íŠ¸ê°€ ì—¬ëŸ¬ í´ëž˜ìŠ¤ëª…ì„ í¬í•¨í•  ê²½ìš°, **ë¬´ê´€í•œ ë‹¨ì–´ ê°„ ìƒí˜¸ìž‘ìš©(attention)ì´ ìƒê¹€**

- í•´ê²°:  
**Sub-sentence level representation** ë„ìž…  
â†’ ì„œë¡œ ë‹¤ë¥¸ í´ëž˜ìŠ¤ëª… ì‚¬ì´ì˜ attentionì„ **mask**í•˜ì—¬ ë¶ˆí•„ìš”í•œ ìƒí˜¸ìž‘ìš© ì œê±°  
â†’ ë‹¨ì–´ ë‹¨ìœ„ ì •ë°€ í‘œí˜„ ìœ ì§€ + ìƒí˜¸ ê°„ì„­ ë°©ì§€


---
#### ðŸŽ¯ Lossì˜ êµ¬ì„±

---

##### ðŸ”§ 3.5 Loss Function

Grounding DINOëŠ” ê¸°ì¡´ì˜ DETR ê³„ì—´ ëª¨ë¸ë“¤ê³¼ ìœ ì‚¬í•˜ê²Œ,  
ë‹¤ìŒ ì„¸ ê°€ì§€ ì£¼ìš” ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤:


##### ðŸ“¦ 1. Bounding Box Regression
- **L1 Loss**  
- **GIoU Loss** (Generalized Intersection over Union)  
- â†’ ë°•ìŠ¤ ìœ„ì¹˜ ì˜ˆì¸¡ ì •ë°€ë„ í–¥ìƒì— ì‚¬ìš©  
- ì°¸ê³ : DETR, Deformable DETR ë“±ì—ì„œ ì‚¬ìš©ëœ ë°©ì‹ê³¼ ë™ì¼

---

##### ðŸ·ï¸ 2. Classification (í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ë¥˜)
- **Contrastive Loss** (GLIP ë°©ì‹ ì±„íƒ)  
  - ì˜ˆì¸¡ëœ ê°ì²´ì™€ í…ìŠ¤íŠ¸ í† í° ê°„ì˜ ëŒ€ì‘ ê´€ê³„ í•™ìŠµ
- **ë°©ì‹**:
  - ê° ì¿¼ë¦¬ì™€ í…ìŠ¤íŠ¸ íŠ¹ì§• ê°„ì˜ **dot product** â†’ logits ê³„ì‚°
  - ê° í…ìŠ¤íŠ¸ í† í°ë³„ë¡œ **Focal Loss** ì ìš©í•˜ì—¬ ë¶„ë¥˜ í•™ìŠµ

---

##### ðŸ”„ 3. ë§¤ì¹­ ë° ì´í•© ê³„ì‚°

- ì˜ˆì¸¡ê°’ê³¼ ì •ë‹µ ê°„ **ì´ì¤‘ ì´ë¶„ ë§¤ì¹­ (bipartite matching)** ìˆ˜í–‰  
  â†’ ë°•ìŠ¤ regression cost + classification cost ê¸°ë°˜
- ë§¤ì¹­ í›„ ìµœì¢… ì†ì‹¤ì€ ë‹¤ìŒì„ í•©ì‚°í•˜ì—¬ ê³„ì‚°:
  - **Bounding Box Loss (L1 + GIoU)**  
  - **Classification Loss (Focal + Contrastive)**

---

##### ðŸ§± 4. Auxiliary Loss

- **DETR ê³„ì—´ êµ¬ì¡°ë¥¼ ë”°ë¥´ê¸° ë•Œë¬¸ì—**, ë‹¤ìŒ ë‘ ìœ„ì¹˜ì— ë³´ì¡° ì†ì‹¤(auxiliary loss)ì„ ì¶”ê°€í•©ë‹ˆë‹¤:
  - **ê° ë””ì½”ë” ë ˆì´ì–´ ì¶œë ¥**
  - **ì¸ì½”ë” ì¶œë ¥ (encoder outputs)**

âž¡ï¸ ì´ ë³´ì¡° ì†ì‹¤ì€ í•™ìŠµ ì´ˆê¸° ì•ˆì •ì„±ê³¼ ìˆ˜ë ´ ê°€ì†ì— ê¸°ì—¬í•©ë‹ˆë‹¤.

---

### ðŸ“Š ì„±ëŠ¥

- ë‹¤ì–‘í•œ Open-Vocabulary ë°ì´í„°ì…‹ì—ì„œ **ê¸°ì¡´ SOTA ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥**
- íŠ¹ížˆ **RefCOCO, LVIS, COCO** ë“±ì—ì„œ íƒì›”í•œ zero-shot ì„±ëŠ¥
- ì´ë¯¸ì§€ ë‚´ ì¡´ìž¬í•˜ì§€ ì•ŠëŠ” í´ëž˜ìŠ¤ì— ëŒ€í•´ì„œë„ ê²¬ê³ í•œ íƒì§€ ê°€ëŠ¥

---

### ðŸ› ï¸ ì‹¤ìŠµ ì°¸ê³ 

- GitHub: [IDEA-Research/GroundingDINO](https://github.com/IDEA-Research/GroundingDINO)
- Hugging Face: ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë° demo ì œê³µ
- Segment Anything ë“±ê³¼ ì¡°í•©í•˜ì—¬ **Grounded SAM**ìœ¼ë¡œë„ í™œìš© ê°€ëŠ¥

---

### ðŸ’¡ ëŠë‚€ì 

Grounding DINOëŠ” ë‹¨ìˆœížˆ íƒì§€ë¥¼ ìž˜í•˜ëŠ” ê²ƒì„ ë„˜ì–´,  
**í…ìŠ¤íŠ¸ì™€ ì‹œê° ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” ë°©ì‹**ì„ ìž˜ ë³´ì—¬ì£¼ëŠ” ë…¼ë¬¸ìž…ë‹ˆë‹¤.  
CLIP ì´í›„ ë“±ìž¥í•œ ë‹¤ì–‘í•œ Vision-Language ëª¨ë¸ë“¤ê³¼ ë¹„êµí•´ë„ **ìœ ì—°ì„±ê³¼ í™•ìž¥ì„± ë©´ì—ì„œ ê°•ë ¥**í•œ ì¸ìƒì„ ë°›ì•˜ìŠµë‹ˆë‹¤.

---

### ðŸ“š ì°¸ê³  ë¬¸í—Œ

1. Grounding DINO paper: https://arxiv.org/abs/2303.05499  
2. Grounding DINO GitHub: https://github.com/IDEA-Research/GroundingDINO  
3. CLIP: Learning Transferable Visual Models From Natural Language Supervision

---

ðŸ‘‰ ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ì„œëŠ” Grounding DINOë¥¼ í™œìš©í•œ ì‹¤ìŠµ ì½”ë“œë„ í•¨ê»˜ ì •ë¦¬í•´ë³¼ ì˜ˆì •ìž…ë‹ˆë‹¤.  
ê¶ê¸ˆí•œ ì ì´ë‚˜ ìš”ì²­ì‚¬í•­ì€ ëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”!