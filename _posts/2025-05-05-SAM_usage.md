---
layout: post
title: "Image segmentation with Python using SAM! - íŒŒì´ì¬ìœ¼ë¡œ ëˆ„ë¼ë”°ê¸°!? SAM (Segment Anything Model) ì‹¤ìŠµ"
author: [DrFirst]
date: 2025-05-05 09:00:00 +0900
categories: [AI, Experiment]
tags: [SAM, Segment Anything, Vision AI, Segmentation, Python, ëˆ„ë¼ë”°ê¸°, ë°°ê²½ì œê±°, æŠœã]
lastmod : 2025-05-05 09:00:00
sitemap :
  changefreq : weekly
  priority : 0.9
---

## ğŸ§¼ Image segmentation with Python? SAM in Action!

Today, letâ€™s practice how to do Image segmentation using SAM (Segment Anything Model),  
based on the [theory we explored in the previous post](https://drfirstlee.github.io/posts/SAM/)!

We'll use **Ultralytics** to run SAM easily,  
instead of downloading and configuring the model from Meta or Hugging Face.

Letâ€™s start by loading the SAM model using Ultralytics:

```python
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

# Load model
model = SAM("sam_b.pt")
model.eval()
```

Once the model is loaded, the architecture consists mainly of:
- `image_encoder`
- `prompt_encoder`
- `mask_decoder`

And more specifically, the structure looks like this:

```
# SAM (Segment Anything Model)
- model: SAMModel
  - image_encoder: ImageEncoderViT
    - patch_embed: PatchEmbed
      - proj: Conv2d(3, 768, kernel_size=16, stride=16)
    - blocks: ModuleList
      - Block[0-11] (12 Transformer Blocks)
        - norm1: LayerNorm(768)
        - attn: REAttention
          - qkv: Linear(768 â†’ 2304)
          - proj: Linear(768 â†’ 768)
        - norm2: LayerNorm(768)
        - mlp: MLPBlock
          - lin1: Linear(768 â†’ 3072)
          - lin2: Linear(3072 â†’ 768)
          - act: GELU
    - neck: Sequential
      - Conv2d(768 â†’ 256, 1x1)
      - LayerNorm2d
      - Conv2d(256 â†’ 256, 3x3, padding=1)
      - LayerNorm2d

  - prompt_encoder: PromptEncoder
    - pe_layer: PositionEmbeddingRandom
    - point_embeddings: ModuleList (4 x Embedding(1, 256))
    - not_a_point_embed: Embedding(1, 256)
    - no_mask_embed: Embedding(1, 256)
    - mask_downscaling: Sequential
      - Conv2d(1 â†’ 4, kernel=2, stride=2)
      - LayerNorm2d
      - GELU
      - Conv2d(4 â†’ 16, kernel=2, stride=2)
      - LayerNorm2d
      - GELU
      - Conv2d(16 â†’ 256, kernel=1, stride=1)

  - mask_decoder: MaskDecoder
    - transformer: TwoWayTransformer
      - layers: ModuleList (2 x TwoWayAttentionBlock)
        - self_attn: Attention
        - cross_attn_token_to_image: Attention
        - cross_attn_image_to_token: Attention
        - norm1, norm2, norm3, norm4: LayerNorm(256)
        - mlp: MLPBlock
          - lin1: Linear(256 â†’ 2048)
          - lin2: Linear(2048 â†’ 256)
          - act: ReLU
      - final_attn_token_to_image: Attention
      - norm_final_attn: LayerNorm(256)
    - iou_token: Embedding(1, 256)
    - mask_tokens: Embedding(4, 256)
    - output_upscaling: Sequential
      - ConvTranspose2d(256 â†’ 64, kernel=2, stride=2)
      - LayerNorm2d
      - GELU
      - ConvTranspose2d(64 â†’ 32, kernel=2, stride=2)
      - GELU
    - output_hypernetworks_mlps: ModuleList (4 x MLP)
      - Linear(256 â†’ 256)
      - Linear(256 â†’ 256)
      - Linear(256 â†’ 32)
    - iou_prediction_head: MLP
      - Linear(256 â†’ 256)
      - Linear(256 â†’ 256)
      - Linear(256 â†’ 4)
```

---

Now letâ€™s try out three different segmentation methods â€” **point**, **bounding box**, and **fully automatic!**

We'll use the following image of a dog:

![dog](https://github.com/user-attachments/assets/0618c5f1-1f52-4210-96eb-d66faae8e220)

---

### ğŸŸ¢ Prompt Type 1: Point-Based Segmentation

You specify a single point, and the model segments the object around it.

```
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

model = SAM("sam_b.pt")

img_name = "dog.jpg"
my_points = [3000, 2000]

results = model(img_name, points=[my_points], labels=[1])

image = cv2.imread(img_name)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

mask = None
for result in results:
    if result.masks is not None:
        mask = result.masks.data[0].cpu().numpy()
        break

if mask is None:
    raise ValueError("No mask found.")

def draw_point(img, point, color=(255, 0, 0), radius=15):
    img_with_point = img.copy()
    cv2.circle(img_with_point, tuple(point), radius, color, -1)
    return img_with_point

image_with_point = draw_point(image_rgb, my_points)

mask_visual = (mask * 255).astype(np.uint8)
colored_mask = cv2.applyColorMap(mask_visual, cv2.COLORMAP_JET)
combined = cv2.addWeighted(image_with_point, 0.7, colored_mask, 0.5, 0)

plt.figure(figsize=(20, 6))

plt.subplot(1, 3, 1)
plt.imshow(image_with_point)
plt.title("Original + Point")
plt.axis("off")

plt.subplot(1, 3, 2)
plt.imshow(mask, cmap='gray')
plt.title("Mask Only")
plt.axis("off")

plt.subplot(1, 3, 3)
plt.imshow(combined)
plt.title("Overlay: Image + Mask + Point")
plt.axis("off")

plt.tight_layout()
plt.show()
```

![point](https://github.com/user-attachments/assets/176ece3a-c25f-44ba-9292-4a0751a7da09)

As shown above, the model extracts the dogâ€™s head based on the red point!

---

### ğŸ”´ Prompt Type 2: Bounding Box-Based Segmentation

You provide a rectangular bounding box, and the model segments the object inside that region.

```
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

model = SAM("sam_b.pt")

img_name = "dog.jpg"
my_bboxes = [1430.2, 828, 4471.9, 3836.4]

results = model(img_name, bboxes=my_bboxes)

image = cv2.imread(img_name)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

plt.figure(figsize=(10, 10))
plt.imshow(image_rgb)

for result in results:
    if result.masks is not None:
        mask = result.masks.data[0].cpu().numpy()
        plt.imshow(mask, alpha=0.5, cmap='jet')

rect = plt.Rectangle((my_bboxes[0], my_bboxes[1]),
                     my_bboxes[2] - my_bboxes[0],
                     my_bboxes[3] - my_bboxes[1],
                     linewidth=2, edgecolor='red', facecolor='none')
plt.gca().add_patch(rect)

plt.title(f"SAM Segmentation with Box Prompt on {img_name}")
plt.axis('off')
plt.show()
```

![bbox](https://github.com/user-attachments/assets/de7c1435-9d31-4edf-a703-c6ac2131d4d5)

The red bounding box lets SAM extract the subject precisely within the box.

---

### âš™ï¸ Prompt Type 3: No Prompt (Automatic Mask Generation / AMG)

This time, we donâ€™t provide any prompts at all â€” SAM automatically segments the image into multiple parts.

```
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

print("\n--- Method 3: Automatic Mask Generation (No Prompt) ---")

model_amg = SAM("sam_b.pt")
image_path = "dog.jpg"

image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

print(f"Running prompt-free segmentation on '{image_path}'...")
results_amg = model_amg(image_path)
print("Done.")

plt.figure(figsize=(12, 10))
plt.imshow(image_rgb)
plt.title("Method 3: SAM Automatic Mask Generation")
plt.axis('off')

if results_amg and results_amg[0].masks is not None:
    masks_amg = results_amg[0].masks.data.cpu().numpy()
    print(f"{len(masks_amg)} masks generated")

    np.random.seed(42)
    for i, mask in enumerate(masks_amg):
        color = np.concatenate([np.random.random(3) * 255, np.array([128])], axis=0)
        h, w = mask.shape[-2:]
        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
        plt.imshow(mask_image.astype(np.uint8))
else:
    print("No masks found.")

plt.show()
```

The image is segmented into **33 distinct masks**, each representing different parts of the dog or the background.

![AMG](https://github.com/user-attachments/assets/b708648c-0303-4b60-b023-8171db501d57)

---

- ğŸ‰ Conclusion

With just a few lines of Python, weâ€™ve performed professional-level segmentation using SAM!  
The modelâ€™s performance is truly impressive. Whether using points, boxes, or no prompt at all,  
SAM is a powerful tool for background removal and object segmentation.

Letâ€™s keep exploring!

---

## (í•œêµ­ì–´) íŒŒì´ì¬ìœ¼ë¡œ ëˆ„ë¼ë”°ê¸°!? SAM ì‹¤ìŠµ

> ëˆ„ë¼(ì¼ë³¸ì–´: æŠœã)ëŠ” ì£¼ë¡œ ì‹œê° ë””ìì¸ í˜„ì¥ì—ì„œ ì“°ì´ëŠ” ìš©ì–´ë¡œ,  
> ì›ë³¸ ì´ë¯¸ì§€ì˜ í”¼ì‚¬ì²´ë¡œë¶€í„° ë°°ê²½ì„ ë¶„ë¦¬í•˜ê¸° ìœ„í•´ í”¼ì‚¬ì²´ì˜ ì™¸ê³½ì„ ì„ ë”°ëŠ” ê²ƒì„ 
> 'ëˆ„ë¼' í˜¹ì€ 'ëˆ„ë¼ ë”°ê¸°'ë¼ê³  ì§€ì¹­í•©ë‹ˆë‹¤!

ì˜¤ëŠ˜ì€ [ì§€ë‚œ í¬ìŠ¤íŒ…](https://drfirstlee.github.io/posts/SAM/) ì—ì„œ ì•Œì•„ë³¸ SAMì˜ ì›ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìŠµì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤!!  
Python ì½”ë“œë¡œ ëˆ„ë¼ë”°ê¸°!!   
SAM (Segment Anything Model)ì„ í™œìš©í•´ì„œ ì‹¤ìŠµí•´ë³´ì•„ìš”~~
SAM ëª¨ë¸ì„ ë‹¤ìš´ë°›ëŠ” ë²•ì€ Meta ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ìš´ë°›ëŠ” ë°©ë²•, Huggingface ëª¨ë¸ ë°›ëŠ” ë°©ë²• ë“±ì´ ê°€ì¥ ê·¼ë³¸ì ì¸ ë°©ë²•ì´ë©°,  
ì˜¤ëŠ˜ì€ ë³´ë‹¤ ê°„ë‹¨í•˜ê²Œ ì‚¬ìš©í• ìˆ˜ ìˆëŠ” Ultralytics ë¥¼ í™œìš©í•´ì„œì‰½ê²Œ SAMì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤!  

ì•„ë˜ì™€ ê°™ì´ ultralyticsë¡œ ë¶€í„° SAM ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤~~  

```python
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

# ëª¨ë¸ ë¡œë“œ
model = SAM("sam_b.pt")
model.eval()
```
ë¡œë“œëœ ëª¨ë¸êµ¬ì¡°ë¥¼ ë¶„ì„í•´ë³´ë©´!!  
ê°„ë‹¨íˆëŠ” image_encoder / prompt_encoder / mask_decoder ë¡œ,  
ì„¸ë¶€ì ìœ¼ë¡œëŠ”ëŠ” ì•„ë˜ì™€ ê°™ì•˜ìŠµë‹ˆë‹¤~!  

 ```
# SAM (Segment Anything Model)
- model: SAMModel
  - image_encoder: ImageEncoderViT
    - patch_embed: PatchEmbed
      - proj: Conv2d(3, 768, kernel_size=16, stride=16)
    - blocks: ModuleList
      - Block[0-11] (12ê°œì˜ Transformer Blocks)
        - norm1: LayerNorm(768)
        - attn: REAttention
          - qkv: Linear(768 â†’ 2304)
          - proj: Linear(768 â†’ 768)
        - norm2: LayerNorm(768)
        - mlp: MLPBlock
          - lin1: Linear(768 â†’ 3072)
          - lin2: Linear(3072 â†’ 768)
          - act: GELU
    - neck: Sequential
      - Conv2d(768 â†’ 256, 1x1)
      - LayerNorm2d
      - Conv2d(256 â†’ 256, 3x3, padding=1)
      - LayerNorm2d

  - prompt_encoder: PromptEncoder
    - pe_layer: PositionEmbeddingRandom
    - point_embeddings: ModuleList (4 x Embedding(1, 256))
    - not_a_point_embed: Embedding(1, 256)
    - no_mask_embed: Embedding(1, 256)
    - mask_downscaling: Sequential
      - Conv2d(1 â†’ 4, kernel=2, stride=2)
      - LayerNorm2d
      - GELU
      - Conv2d(4 â†’ 16, kernel=2, stride=2)
      - LayerNorm2d
      - GELU
      - Conv2d(16 â†’ 256, kernel=1, stride=1)

  - mask_decoder: MaskDecoder
    - transformer: TwoWayTransformer
      - layers: ModuleList (2 x TwoWayAttentionBlock)
        - self_attn: Attention
        - cross_attn_token_to_image: Attention
        - cross_attn_image_to_token: Attention
        - norm1, norm2, norm3, norm4: LayerNorm(256)
        - mlp: MLPBlock
          - lin1: Linear(256 â†’ 2048)
          - lin2: Linear(2048 â†’ 256)
          - act: ReLU
      - final_attn_token_to_image: Attention
      - norm_final_attn: LayerNorm(256)
    - iou_token: Embedding(1, 256)
    - mask_tokens: Embedding(4, 256)
    - output_upscaling: Sequential
      - ConvTranspose2d(256 â†’ 64, kernel=2, stride=2)
      - LayerNorm2d
      - GELU
      - ConvTranspose2d(64 â†’ 32, kernel=2, stride=2)
      - GELU
    - output_hypernetworks_mlps: ModuleList (4 x MLP)
      - Linear(256 â†’ 256)
      - Linear(256 â†’ 256)
      - Linear(256 â†’ 32)
    - iou_prediction_head: MLP
      - Linear(256 â†’ 256)
      - Linear(256 â†’ 256)
      - Linear(256 â†’ 4)
```


ì´ì œ~!!  
ì ,bounding box, ì•„ë¬´ê²ƒë„ ì—†ì´, ì„¸ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤!!!

ì§„í–‰ì—ëŠ” ì•„ë˜ì˜ ê°•ì•„ì§€ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê³ ê³ !!

![dog](https://github.com/user-attachments/assets/0618c5f1-1f52-4210-96eb-d66faae8e220)

### í”„ë¡¬í¬íŠ¸1. Point ê¸°ë°˜!!

Point ê¸°ë°˜ì€ í•˜ë‚˜ì˜ ì ì„ ì œì‹œí•˜ê³ ,   
ê·¸ ì ì„ ë‘˜ëŸ¬ì‹¼  ë¶€ë¶„ì˜ Segment ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤!  

```python
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

# ëª¨ë¸ ë¡œë“œ
model = SAM("sam_b.pt")

# ì´ë¯¸ì§€ ë° í¬ì¸íŠ¸ ì •ì˜
img_name = "dog.jpg"
my_points = [3000, 2000]

# ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
results = model(img_name, points=[my_points], labels=[1])

# ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
image = cv2.imread(img_name)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ë§ˆìŠ¤í¬ ì¶”ì¶œ
mask = None
for result in results:
    if result.masks is not None:
        mask = result.masks.data[0].cpu().numpy()
        break

if mask is None:
    raise ValueError("ë§ˆìŠ¤í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ë¹¨ê°„ ì  ê·¸ë¦¬ê¸° í•¨ìˆ˜
def draw_point(img, point, color=(255, 0, 0), radius=15):
    img_with_point = img.copy()
    cv2.circle(img_with_point, tuple(point), radius, color, -1)
    return img_with_point

# ì´ë¯¸ì§€ + ì 
image_with_point = draw_point(image_rgb, my_points)

# ë§ˆìŠ¤í¬ë§Œ ì‹œê°í™”ìš©ìœ¼ë¡œ ë³€í™˜
mask_visual = (mask * 255).astype(np.uint8)

# ë§ˆìŠ¤í¬ ì»¬ëŸ¬ë§µ ì˜¤ë²„ë ˆì´ ìƒì„±
colored_mask = cv2.applyColorMap(mask_visual, cv2.COLORMAP_JET)
combined = cv2.addWeighted(image_with_point, 0.7, colored_mask, 0.5, 0)

# ì‹œê°í™”
plt.figure(figsize=(20, 6))

# 1. ì›ë³¸ ì´ë¯¸ì§€ + ì 
plt.subplot(1, 3, 1)
plt.imshow(image_with_point)
plt.title("Original + Point")
plt.axis("off")

# 2. ë§ˆìŠ¤í¬ë§Œ
plt.subplot(1, 3, 2)
plt.imshow(mask, cmap='gray')
plt.title("Mask Only")
plt.axis("off")

# 3. ë§ˆìŠ¤í¬ + ì›ë³¸ ì´ë¯¸ì§€ + ì 
plt.subplot(1, 3, 3)
plt.imshow(combined)
plt.title("Overlay: Image + Mask + Point")
plt.axis("off")

plt.tight_layout()
plt.show()

# ê²°ê³¼ ì¶œë ¥
print("Segmentation Result:")
print(f"Number of masks: {len(results[0].masks.data)}")
print(f"Mask shape: {results[0].masks.data[0].shape}")
```

![point](https://github.com/user-attachments/assets/176ece3a-c25f-44ba-9292-4a0751a7da09)

ê·¸ ê²°ê³¼!!  
ì²«ë²ˆì¨° ì´ë¯¸ì§€ì™€ ê°™ì´ ë¹¨ê°„ì ì´ ìˆëŠ”ê²ƒì„ ì¤‘ì‹¬ìœ¼ë¡œ ê°•ì•„ì§€ segment ë¥¼ ì‹¤ì‹œí•˜ë©´!  
ë‘ë²ˆì§¸ ì´ë¯¸ì§€ì™€ ê°™ì´ ë§ˆìŠ¤í¬ë¥¼ ì¶”ì¶œí•˜ê²Œ ë˜ê³ ,  
ì´ ë‘ ì´ë¯¸ì§€ë¥¼ ê²¹ì²˜ë³´ë©´ ì„¸ë²ˆì¨°ì™€ ê°™ì´ ê°•ì•„ì§€ì˜ ì–¼êµ´ ë¶€ë¶„ë§Œì„! ì¶”ì¶œí•˜ê²Œ ë©ë‹ˆë‹¤~!


### í”„ë¡¬í¬íŠ¸2. Bounding Box ê¸°ë°˜!!

Bounding Box ê¸°ë°˜ì€ ë„¤ ê°œì˜ ì ìœ¼ë¡œ bouding boxë¥¼ ì œì‹œí•˜ê³ ,   
ê·¸ ë°•ìŠ¤ ë‚´ì˜ ë¶€ë¶„ì˜ Segment ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤!  


```python
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

# ëª¨ë¸ ë¡œë“œ
model = SAM("sam_b.pt")

img_name = "dog.jpg"

my_bboxes=[1430.2,   828,  4471.9, 3836.4]
# ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ë¡œ ì¶”ë¡  ([x_min, y_min, x_max, y_max])
results = model(img_name, bboxes=my_bboxes)

# ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ (ì‹œê°í™”ë¥¼ ìœ„í•´)
image = cv2.imread(img_name)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR -> RGB ë³€í™˜

# ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(10, 10))
plt.imshow(image_rgb)

# ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
for result in results:
    if result.masks is not None:
        mask = result.masks.data[0].cpu().numpy()  # ì²« ë²ˆì§¸ ë§ˆìŠ¤í¬ ì¶”ì¶œ
        plt.imshow(mask, alpha=0.5, cmap='jet')  # ë§ˆìŠ¤í¬ë¥¼ ë°˜íˆ¬ëª…í•˜ê²Œ í‘œì‹œ

# ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
rect = plt.Rectangle((my_bboxes[0], my_bboxes[1]), my_bboxes[2] - my_bboxes[0], my_bboxes[3] - my_bboxes[1], 
                     linewidth=2, edgecolor='red', facecolor='none', label=f'my_bboxes {my_bboxes}')
plt.gca().add_patch(rect)

# ì œëª© ë° ì„¤ì •
plt.title(f"SAM Segmentation with Box Prompt on {img_name}")
plt.legend()
plt.axis('off')
plt.show()

# ì¶”ê°€ ì •ë³´ ì¶œë ¥ (ì„ íƒ ì‚¬í•­)
print("Segmentation Result:")
print(f"Number of masks: {len(results[0].masks.data)}")
print(f"Mask shape: {results[0].masks.data[0].shape}")
```

![bbox](https://github.com/user-attachments/assets/de7c1435-9d31-4edf-a703-c6ac2131d4d5)

ê·¸ ê²°ê³¼!!  
ë¹¨ê°„ Bbox(bounding box) ë‚´ì—ì„œ ê°•ì•„ì§€ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•´ì¤ë‹ˆë‹¤~!  
ì°¸ ì‰½ì§€ìš”~?  
ë‘ë²ˆì§¸ ì´ë¯¸ì§€ì™€ ê°™ì´ ë§ˆìŠ¤í¬ë¥¼ ì¶”ì¶œí•˜ê²Œ ë˜ê³ ,  
ì´ ë‘ ì´ë¯¸ì§€ë¥¼ ê²¹ì²˜ë³´ë©´ ì„¸ë²ˆì¨°ì™€ ê°™ì´ ê°•ì•„ì§€ì˜ ì–¼êµ´ ë¶€ë¶„ë§Œì„! ì¶”ì¶œí•˜ê²Œ ë©ë‹ˆë‹¤~!

### í”„ë¡¬í¬íŠ¸3. ììœ¨ë¡œ ë§¡ê¸°ê¸°!! AMG ë°©ì‹ ê¸°ë°˜!!  

ì´ë²ˆì—ëŠ” ë³„ë„ì˜ í”„ë¡¬í¬íŠ¸ ì—†ì´ ì´ë¯¸ì§€ë¥¼ ì„¸ì„¸í•˜ê²Œ ë‚˜ëˆ„ê²Œë©ë‹ˆë‹¤!!  

```python
from ultralytics import SAM
import cv2
import matplotlib.pyplot as plt
import numpy as np

print("\n--- ë°©ë²• 3: Automatic Mask Generation (AMG) ë°©ì‹ (í”„ë¡¬í”„íŠ¸ ì—†ìŒ) ---")

# ëª¨ë¸ ë¡œë“œ (ë™ì¼ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥)
model_amg = SAM("sam_b.pt")

# ì´ë¯¸ì§€ ê²½ë¡œ
image_path = "dog.jpg"

# ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# **í”„ë¡¬í”„íŠ¸ ì—†ì´** ì¶”ë¡  ì‹¤í–‰ (AMG ë°©ì‹)
# ultralytics ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë©´
# ë‚´ë¶€ì ìœ¼ë¡œ AMGì™€ ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ìƒì„±í•˜ë ¤ê³  ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
print(f"'{image_path}'ì—ì„œ í”„ë¡¬í”„íŠ¸ ì—†ì´ (AMG ë°©ì‹) ì¶”ë¡  ì¤‘...")
results_amg = model_amg(image_path) # bboxes ì¸ì ì—†ìŒ!
print("ì¶”ë¡  ì™„ë£Œ.")

# ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(12, 10))
plt.imshow(image_rgb)
plt.title("ë°©ë²• 3: SAM Automatic Mask Generation (No Prompt)")
plt.axis('off')

# ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
if results_amg and results_amg[0].masks is not None:
    masks_amg = results_amg[0].masks.data.cpu().numpy()
    print(f"AMG ë°©ì‹ ê²°ê³¼: {len(masks_amg)}ê°œì˜ ë§ˆìŠ¤í¬ ìƒì„±ë¨")

    # ì—¬ëŸ¬ ê°œì˜ ë§ˆìŠ¤í¬ë¥¼ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œ
    np.random.seed(42) # ì¼ê´€ëœ ìƒ‰ìƒ ìƒì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
    for i, mask in enumerate(masks_amg):
        # ê° ë§ˆìŠ¤í¬ì— ëœë¤ ìƒ‰ìƒ ì ìš© (ë°˜íˆ¬ëª…)
        color = np.concatenate([np.random.random(3) * 255, np.array([128])], axis=0)
        h, w = mask.shape[-2:]
        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
        plt.imshow(mask_image.astype(np.uint8)) # ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì˜¤ë²„ë ˆì´
        # print(f"  - Mask {i+1} shape: {mask.shape}") # ê°œë³„ ë§ˆìŠ¤í¬ ì •ë³´ ì¶œë ¥ (ì„ íƒ ì‚¬í•­)
else:
    print("AMG ë°©ì‹ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

plt.show()

# ì¶”ê°€ ì •ë³´ ì¶œë ¥
if results_amg and results_amg[0].masks is not None:
    print("\nAMG ë°©ì‹ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìƒì„¸ ì •ë³´:")
    print(f" - ìƒì„±ëœ ì´ ë§ˆìŠ¤í¬ ìˆ˜: {len(results_amg[0].masks.data)}")
    # AMG ê²°ê³¼ì—ëŠ” ë³´í†µ ê° ë§ˆìŠ¤í¬ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´(ì ìˆ˜, ì˜ì—­ ë“±)ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë‚˜,
    # ultralytics ë˜í¼ì˜ ê²°ê³¼ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì•¼ í•¨.
    # print(f" - ê²°ê³¼ ê°ì²´ íƒ€ì…: {type(results_amg[0])}") # ê²°ê³¼ êµ¬ì¡° í™•ì¸ìš©

```

ì´ë¥¼ í†µí•´ì„œ ì•„ë˜ì™€ ê°™ì´ ê°•ì•„ì§€ ì´ë¯¸ì§€ê°€ ì—¬ëŸ¬ê°œì˜ ì´ë¯¸ì§€ë¡œ  
ë¶„í• ëœ ê²ƒì„ í™•ì¸í• ìˆ˜ ìˆìŠµë‹ˆë‹¤!!

33ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„í• ë˜ì—ˆë„¤ìš”~!

![AMG](https://github.com/user-attachments/assets/b708648c-0303-4b60-b023-8171db501d57)

---


ì§€ê¸ˆê¹Œì§€ ì•Œì•„ë³¸ SAMì˜ íŒŒì´ì¬ ì‹¤ìŠµ!!

ì •ë§ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë†€ëìŠµë‹ˆë‹¤!!  


