---
layout: post
title: "üß† CIRCO - Zero-Shot Composed Image Retrieval with Textual Inversion (ICCV 2023)"
author: [DrFirst]
date: 2025-07-29 09:00:00 +0900
categories: [AI, Research]
tags: [VLM, CIR, CIRCO, Textual Inversion, Zero-Shot, ICCV, ICCV 2023, Image Retrieval]
sitemap :
  changefreq : monthly
  priority : 0.8

---

### üß† (ÌïúÍµ≠Ïñ¥) Textual InversionÏùÑ ÌôúÏö©Ìïú Ï†úÎ°úÏÉ∑ Ï°∞Ìï© Ïù¥ÎØ∏ÏßÄ Í≤ÄÏÉâ!! **CIRCO**  
> Í∏∞Ï°¥ CIRÏó∞Íµ¨ÏóêÏÑú ZS-CIR Î™®Îç∏ÏùÑ Í≥µÍ∞úÌïòÍ≥†, CIRCO Îç∞Ïù¥ÌÑ∞ÏÖãÎèÑ Í≥µÍ∞ú!!  

![Image](https://github.com/user-attachments/assets/1a4f2dcb-38b2-4a2d-a919-cadc21025f7d)

- **Ï†úÎ™©**: [Zero-Shot Composed Image Retrieval with Textual Inversion](https://arxiv.org/abs/2303.15247)  
- **ÌïôÌöå**: ICCV 2023 (Zhang et al.)  
- **ÏΩîÎìú**: [CIRCO (GitHub)](https://github.com/miccunifi/CIRCO)  
- **ÌïµÏã¨ ÌÇ§ÏõåÎìú**: `Composed Image Retrieval`, `CIRCO`, `Textual Inversion`, `Zero-Shot`, `ICCV 2023`, `ZS-CIR`, `SEARLE`
- Ï∂îÍ∞Ä!! : Ïö©Ïñ¥Í∞Ä ÌñáÍ∞àÎ¶¨ÎäîÎç∞ `ZS-CIR`, `SEARLE` Í∞Ä Î™®Îëê Ïù¥ ÎÖºÎ¨∏ÏóêÏÑú Í≥µÍ∞úÌïú Î™®Îç∏ÏùÑ ÏßÄÏπ≠Ìï©ÎãàÎã§!!  
- `ZS-CIR` Îäî  Zero shot Composed Image RetrievalÏùò ÏïΩÏñ¥, `SEARLE`ÏùÄ  zero-Shot composEd imAge Retrieval with textuaL invErsion ÏûÖÎãàÎã§!!  


---

### üîç Ïó∞Íµ¨ Î∞∞Í≤Ω

CIRR(ICCV 2021)ÏùÄ **Ï°∞Ìï© Ïù¥ÎØ∏ÏßÄ Í≤ÄÏÉâ(Composed Image Retrieval, CIR)**ÏùÑ Ï†ïÏùòÌñàÏßÄÎßå, ÌïôÏäµ Í∏∞Î∞ò Î∞©ÏãùÍ≥º Îã®Ïùº Ï†ïÎãµ ÎùºÎ≤®ÎßÅÏóê ÏùòÏ°¥ÌñàÏäµÎãàÎã§.  
ÌïòÏßÄÎßå ÌòÑÏã§ ÏùëÏö©ÏóêÏÑúÎäî Îã§ÏùåÍ≥º Í∞ôÏùÄ ÏöîÍµ¨Í∞Ä ÏûàÏäµÎãàÎã§:

> ‚ÄúÏÉàÎ°úÏö¥ ÎèÑÎ©îÏù∏ÏóêÏÑúÎèÑ ÌïôÏäµ ÏóÜÏù¥(Zero-Shot)  
> Ï∞∏Ï°∞ Ïù¥ÎØ∏ÏßÄ + ÌÖçÏä§Ìä∏ ÏàòÏ†ïÏúºÎ°ú ÏõêÌïòÎäî Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÍ≥†,  
> ÎèôÏãúÏóê Î≥µÏàòÏùò Ï†ïÎãµÏùÑ ÌóàÏö©Ìï¥Ïïº ÌïúÎã§!‚Äù

Ïù¥Î•º ÏúÑÌï¥ ICCV 2023ÏóêÏÑú Î∞úÌëúÎêú Ïù¥Î≤à ÎÖºÎ¨∏ÏùÄ  
ZS-CIR Î™®Îç∏ Í≥µÍ∞ú!! ‚Üí Textual InversionÏùÑ ÌôúÏö©Ìïú Ï†úÎ°úÏÉ∑ CIR ÌîÑÎ†àÏûÑÏõåÌÅ¨ Í≥µÍ∞ú  
ÎòêÌïú  **CIRCO**ÎùºÎäî Îç∞Ïù¥ÌÑ∞ ÏÖãÏúºÎ°ú, **Îçî ÌòÑÏã§Ï†ÅÏù¥Í≥† Ï†ïÍµêÌïú Îç∞Ïù¥ÌÑ∞ÏÖã**ÏùÑ Ï†úÏïàÌñàÏäµÎãàÎã§.   

---

### üß† Ï£ºÏöî Í∏∞Ïó¨

1. #### Ï†úÎ°úÏÉ∑ CIR ÌîÑÎ†àÏûÑÏõåÌÅ¨ Ï†úÏïà(ZS-CIR)  
   - Textual InversionÏùÑ ÌôúÏö©Ìï¥ **Ï∞∏Ï°∞ Ïù¥ÎØ∏ÏßÄÎ•º ÏÉàÎ°úÏö¥ Í∞úÎÖê ÌÜ†ÌÅ∞**ÏúºÎ°ú ÏûÑÎ≤†Îî©  
   - ÏàòÏ†ï ÌÖçÏä§Ìä∏ÏôÄ Í≤∞Ìï©ÌïòÏó¨ **Ï°∞Ìï© ÏøºÎ¶¨** ÌòïÏÑ±  
   - Îç∞Ïù¥ÌÑ∞ÏÖãÎ≥Ñ ÌïôÏäµ ÏóÜÏù¥ Îã§ÏñëÌïú ÎèÑÎ©îÏù∏ Ï†ÅÏö© Í∞ÄÎä•  

2. #### CIRCO Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ï  
   - **COCO 2017** Í∏∞Î∞òÏùò ÌòÑÏã§ Ïù¥ÎØ∏ÏßÄ ÏÇ¨Ïö©  
   - Í∞ùÏ≤¥ Ï§ëÏã¨(object-centric) + Îã§Ï§ë Í∞ùÏ≤¥ Ìè¨Ìï® ÏøºÎ¶¨  
   - Ïã§Ï†ú Ïû•Î©¥ÏóêÏÑú **Í∞ùÏ≤¥ ÏÜçÏÑ± Î≥ÄÍ≤Ω + Í∞ùÏ≤¥ Í∞Ñ Í¥ÄÍ≥Ñ ÏàòÏ†ï** Î∞òÏòÅ  


3. #### Î≤§ÏπòÎßàÌÅ¨ Î∞è Ï†úÎ°úÏÉ∑ ÏÑ±Îä•  
   - CIRR, FashionIQ, CIRCOÏóêÏÑú Ï†úÎ°úÏÉ∑ ÏÑ±Îä• Í≤ÄÏ¶ù  
   - ÌïôÏäµ ÏóÜÏù¥ÎèÑ ÏùòÎØ∏ ÏûàÎäî ÏÑ±Îä• ÌôïÎ≥¥  

---

### üß† Ï£ºÏöî Í∏∞Ïó¨ (ÏûêÏÑ∏Ìûà!!)

#### 1. Ï†úÎ°úÏÉ∑ CIR ÌîÑÎ†àÏûÑÏõåÌÅ¨ Ï†úÏïà (**ZS-CIR**)  

![Image](https://github.com/user-attachments/assets/4973487e-1cc9-4000-a59f-dc9084e55a3b)

- **Í∏∞Ï°¥ Î¨∏Ï†ú**  
  - CIRR, FashionIQ Í∞ôÏùÄ Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑúÎäî ÎåÄÎ∂ÄÎ∂Ñ Î™®Îç∏Ïù¥ **ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò ÌååÏù∏ÌäúÎãù**ÏùÑ Í±∞Ï≥êÏïº ÌñàÏùå  
  - Îî∞ÎùºÏÑú ÏÉàÎ°úÏö¥ ÎèÑÎ©îÏù∏Ïù¥ÎÇò unseen Ïπ¥ÌÖåÍ≥†Î¶¨ÏóêÏÑúÎäî ÏÑ±Îä•Ïù¥ Í∏âÍ≤©Ìûà Ï†ÄÌïòÎêòÎäî Î¨∏Ï†ú Ï°¥Ïû¨  

- **ÌïµÏã¨ ÏïÑÏù¥ÎîîÏñ¥**  
  - Textual Inversion Í∏∞Î≤ïÏùÑ CIRÏóê Ï†ëÎ™©  
  - Ï∞∏Ï°∞ Ïù¥ÎØ∏ÏßÄÎ•º **ÏÉàÎ°úÏö¥ ÌÜ†ÌÅ∞(embedding)**ÏúºÎ°ú Î≥ÄÌôò ‚Üí ÎßàÏπò ‚ÄúÎã®Ïñ¥‚ÄùÏ≤òÎüº ÌôúÏö©  
  - ÏàòÏ†ï ÌÖçÏä§Ìä∏ÏôÄ Í≤∞Ìï© ‚Üí ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú ‚ÄúÏù¥ÎØ∏ÏßÄ+Î¨∏Ïû• Ï°∞Ìï© ÏøºÎ¶¨‚Äù ÌòïÏÑ±  

- **Ïû•Ï†ê**  
  - Ï∂îÍ∞Ä ÌïôÏäµ ÏóÜÏù¥ÎèÑ Í≤ÄÏÉâ Í∞ÄÎä• (Zero-Shot)  
  - ÌäπÏ†ï ÎèÑÎ©îÏù∏(Ìå®ÏÖò, Ïã§ÏÉùÌôú Ïù¥ÎØ∏ÏßÄ Îì±)Ïóê Íµ≠ÌïúÎêòÏßÄ ÏïäÍ≥† **Î≤îÏö©ÏÑ±** ÌôïÎ≥¥  
  - Ï∂îÎ°† Í≥ºÏ†ïÏù¥ Îã®ÏàúÌï¥ Ìö®Ïú®ÏÑ±ÎèÑ Î≥¥Ïû•  

---

#### 2. CIRCO Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ï  

> CIRCOÎäî CIR Ïó∞Íµ¨ÏóêÏÑú Ï≤òÏùåÏúºÎ°ú **Ï†úÎ°úÏÉ∑ Ï°∞Ìï© Í≤ÄÏÉâ**ÏùÑ Í∞ÄÎä•ÌïòÍ≤å ÌñàÏùÑ Îøê ÏïÑÎãàÎùº,  
> Îç∞Ïù¥ÌÑ∞ÏÖã Ï∏°Î©¥ÏóêÏÑúÎèÑ  
> - **Î≥µÏàòÏùò Ï†ïÎãµ**  
> - **ÌòÑÏã§Ï†Å Ïù¥ÎØ∏ÏßÄ**  
> - **Î≥µÏû°Ìïú ÏøºÎ¶¨ Íµ¨ÏÑ±**  
> ÏùÑ Î∞òÏòÅÌï¥ **CIR ÌèâÍ∞ÄÏùò ÏßàÏ†Å ÏàòÏ§ÄÏùÑ ÎÅåÏñ¥Ïò¨Î¶∞ Í∏∞ÎÖêÎπÑÏ†Å Ïó∞Íµ¨**ÏûÖÎãàÎã§.  

![Image](https://github.com/user-attachments/assets/4285a3a1-18ba-4d4f-9dc5-e8e43488940e)  

- **ÌòÑÏã§ÏÑ±**  
  - MS-COCO 2017 Ïù¥ÎØ∏ÏßÄ Í∏∞Î∞ò  
  - ÌäπÏ†ï ÎèÑÎ©îÏù∏(Ïòà: Ìå®ÏÖò) Ìé∏Ìñ•ÏùÑ Ï§ÑÏù¥Í≥†, Îã§ÏñëÌïú Î¨ºÏ≤¥¬∑Î∞∞Í≤Ω¬∑Í¥ÄÍ≥ÑÏÑ±ÏùÑ Ìè¨Ìï®  

- **Í∞ùÏ≤¥ Ï§ëÏã¨ (Object-Centric)**  
  - Îã®ÏàúÌûà ‚ÄúÏ†ÑÏ≤¥ Ïû•Î©¥‚ÄùÏù¥ ÏïÑÎãàÎùº, ÌäπÏ†ï Í∞ùÏ≤¥Ïùò ÏÜçÏÑ± Î≥ÄÌôîÎ•º Î∞òÏòÅÌïòÎäî ÏøºÎ¶¨ Ï†úÍ≥µ  
  - Ïòà: ‚ÄúÏÇ¨ÏßÑ ÏÜç ÏûêÎèôÏ∞®Îäî Îπ®Í∞ÑÏÉâÏúºÎ°ú Î∞îÍæ∏Í≥†, ÏòÜÏóê ÏûàÎçò Í∞ïÏïÑÏßÄÎäî Í≥†ÏñëÏù¥Î°ú Î∞îÍøîÏ§ò.‚Äù  

- **Î≥µÏàò Ï†ïÎãµ (Multi-Ground Truths)**  
  - ÏøºÎ¶¨Îãπ ÌèâÍ∑† 4.53Í∞úÏùò ÌÉÄÍπÉ Ïù¥ÎØ∏ÏßÄ Ï°¥Ïû¨  
  - Í∏∞Ï°¥ FashionIQ Í∞ôÏùÄ Îã®Ïùº Ï†ïÎãµ Íµ¨Ï°∞Ïùò ÌïúÍ≥ÑÎ•º Í∑πÎ≥µ  
  - False Negative Î¨∏Ï†ú ÏôÑÌôî ‚Üí Í≤ÄÏÉâ Î™®Îç∏ ÌèâÍ∞ÄÍ∞Ä Ìõ®Ïî¨ Í≥µÏ†ïÌï¥Ïßê  

- **Î≥µÏû°Ìïú ÏßàÏùò (Complex Queries)**  
  - Í∞ùÏ≤¥ ÏÜçÏÑ± ÏàòÏ†ïÎøê ÏïÑÎãàÎùº **Îã§Ï§ë Í∞ùÏ≤¥ Î∞è Í∞ùÏ≤¥ Í∞Ñ Í¥ÄÍ≥Ñ**Î•º Ìè¨Ìï®  
  - Îã®ÏàúÌïú ‚ÄúÏÉâÏÉÅ Î≥ÄÍ≤Ω‚ÄùÏùÑ ÎÑòÏñ¥  
    - ‚ÄúÏÇ¨ÎûåÏù¥ ÏïâÏïÑ ÏûàÎçò ÏúÑÏπòÏóê Îã§Î•∏ Ïù∏Î¨ºÏù¥ ÏÑú ÏûàÎã§‚Äù  
    - ‚ÄúÍ∞úÍ∞Ä ÏûàÎçò ÏûêÎ¶¨Ïóê Í≥†ÏñëÏù¥Í∞Ä ÏûàÎã§‚Äù Í∞ôÏùÄ Î≥µÌï© ÏøºÎ¶¨ÎèÑ Ìè¨Ìï®  

---

#### 3. Î≤§ÏπòÎßàÌÅ¨ Î∞è Ï†úÎ°úÏÉ∑ ÏÑ±Îä•  

![Image](https://github.com/user-attachments/assets/51f8721c-609a-4d2b-aa81-c147cf035d21)

- **ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞ÏÖã**: CIRR, FashionIQ, CIRCO Îì± Ï£ºÏöî CIR Î≤§ÏπòÎßàÌÅ¨ÏóêÏÑú Ï†úÎ°úÏÉ∑ ÏÑ±Îä• Í≤ÄÏ¶ù  

- **FashionIQ (Validation Set)**  
  - **SEARLE (B/32)**: ÌèâÍ∑† R@10 = 22.89, R@50 = 42.53  
  - **SEARLE-XL (L/14)**: ÌèâÍ∑† R@10 = 25.56, R@50 = 46.23  
  - Í∏∞Ï°¥ Î∞©Î≤ï ÎåÄÎπÑ ÌôïÏó∞Ìûà Ìñ•ÏÉÅ, BasesÏùºÎïåÎäî ÌîÑÎ°¨Ìè¨Ìä∏Î•º ÌïôÏäµÏãúÌÇ® OTIÎ≥¥Îã§ Í∑∏ÎÉ• SEARLEÍ∞Ä Îçî Ï¢ãÏùÑÎñÑÍ∞Ä ÎßéÏïòÏùå!!  

- **CIRR (Test Set)**  
  - **SEARLE (B/32)**: Recall@1 = 24.27, Recall@5 = 53.22, Recall@10 = 66.82  
  - **SEARLE-XL (L/14)**: Recall@1 = 24.22, Recall@5 = 52.48, Recall@10 = 66.29  
  - SEARLEÏù¥ ÌîÑÎ°¨Ìè¨Ìä∏ ÌïôÏäµÌïúÍ≤É Î≥¥Îã§ ÏÑ±Îä•Ïù¥ Ï¢ãÏïòÏùå!@  
  - Subset Recall (Îçî Ï†ïÎ∞ÄÌïú ÌèâÍ∞Ä)ÏóêÏÑúÎèÑ SEARLE-XLÏù¥ **Recall@3 = 88.19**Î°ú SOTA ÏàòÏ§Ä ÏÑ±Îä• ÌôïÎ≥¥  

- **ÏùòÏùò**  
  - Îã®ÏàúÌïú Zero-Shot Ï†ëÍ∑ºÏûÑÏóêÎèÑ Î∂àÍµ¨ÌïòÍ≥†, FashionIQÏôÄ CIRRÏóêÏÑú **Í∏∞Ï°¥ ÌïôÏäµ Í∏∞Î∞ò Í∏∞Î≤ïÎ≥¥Îã§ Í≤ΩÏüÅÎ†• ÏûàÎäî ÏÑ±Îä•**ÏùÑ Í∏∞Î°ù  
  - ÌäπÌûà CIRRÏóêÏÑúÎäî Recall@1Ïù¥ 24%Î•º ÎÑòÏúºÎ©∞, ÌïôÏäµ ÏóÜÏù¥ÎèÑ **ÏùòÎØ∏ ÏûàÎäî Í≤ÄÏÉâ ÌíàÏßà**ÏùÑ Î≥¥Ïû•  
  - Ïù¥Îäî CIR Ïó∞Íµ¨ÏóêÏÑú Zero-Shot Ï†ëÍ∑ºÏùò Í∞ÄÎä•ÏÑ±ÏùÑ ÏµúÏ¥àÎ°ú Ïã§Ï¶ùÌïú ÏÑ±Í≥ºÏù¥Î©∞, Ïù¥ÌõÑ **CIReVL (ICLR 2024)**, **OSrCIR (CVPR 2025)** Í∞ôÏùÄ Training-Free Í≥ÑÏó¥ Ïó∞Íµ¨Î°ú Ïù¥Ïñ¥ÏßÄÎäî Í∏∞Î∞òÏùÑ ÎßàÎ†®Ìï®


---

### üß© Í≤∞Î°†

> **CIRCO (ICCV 2023)**Îäî **Textual Inversion Í∏∞Î∞ò Ï†úÎ°úÏÉ∑ CIR(ZS-CIR)**ÏùÑ Ï†úÏïàÌïòÍ≥†,  
> ÌòÑÏã§ÏÑ±Í≥º Ï†ïÍµêÌï®ÏùÑ Í∞ïÌôîÌïú ÏÉàÎ°úÏö¥ Îç∞Ïù¥ÌÑ∞ÏÖã(**CIRCO**)ÏùÑ Íµ¨Ï∂ïÌñàÏäµÎãàÎã§.  
> Ïù¥Îäî CIR Ïó∞Íµ¨Í∞Ä **‚ÄúÌïôÏäµ Í∏∞Î∞ò + Îã®Ïùº Ï†ïÎãµ‚Äù**ÏóêÏÑú **‚ÄúÏ†úÎ°úÏÉ∑ + Îã§Ï§ë Ï†ïÎãµ + Î≥µÏû° ÏßàÏùò‚Äù**Î°ú  
> ÏßÑÌôîÌïòÎäî Ï∂úÎ∞úÏ†êÏù¥ ÎêòÏóàÏäµÎãàÎã§.


---

### üß† (English) Zero-Shot Composed Image Retrieval with Textual Inversion!! **CIRCO**  
> In this work, the authors released the ZS-CIR model and also introduced the CIRCO dataset!!  

![Image](https://github.com/user-attachments/assets/1a4f2dcb-38b2-4a2d-a919-cadc21025f7d)

- **Title**: [Zero-Shot Composed Image Retrieval with Textual Inversion](https://arxiv.org/abs/2303.15247)  
- **Conference**: ICCV 2023 (Zhang et al.)  
- **Code**: [CIRCO (GitHub)](https://github.com/miccunifi/CIRCO)  
- **Key Keywords**: `Composed Image Retrieval`, `CIRCO`, `Textual Inversion`, `Zero-Shot`, `ICCV 2023`, `ZS-CIR`, `SEARLE`  
- Note!!: The terms `ZS-CIR` and `SEARLE` both refer to the model released in this paper.  
- `ZS-CIR` is the abbreviation of *Zero-Shot Composed Image Retrieval*, while `SEARLE` stands for *zero-Shot composEd imAge Retrieval with textuaL invErsion*.  

---

### üîç Background

CIRR (ICCV 2021) defined **Composed Image Retrieval (CIR)** but relied heavily on training-based methods and single ground-truth labels.  
However, in real-world scenarios, new demands have emerged:

> ‚ÄúWe need to retrieve images in unseen domains,  
> without additional training (Zero-Shot),  
> using reference images + textual modifications,  
> while allowing multiple correct answers!‚Äù  

To meet these demands, the ICCV 2023 paper proposed:  
- **ZS-CIR model** ‚Üí a Textual Inversion-based zero-shot CIR framework  
- **CIRCO dataset** ‚Üí a more realistic and fine-grained benchmark  

---

### üß† Key Contributions

1. #### Zero-Shot CIR Framework (ZS-CIR)  
   - Applied Textual Inversion to embed **reference images as new concept tokens**  
   - Combined with modification text to form **composed queries**  
   - Applicable across domains without dataset-specific training  

2. #### CIRCO Dataset  
   - Based on **COCO 2017** real-world images  
   - Object-centric queries including multiple objects  
   - Captures **attribute changes + object relationships** in natural scenes  

3. #### Benchmark & Zero-Shot Performance  
   - Evaluated on CIRR, FashionIQ, and CIRCO  
   - Achieved meaningful zero-shot performance without additional training  

---

### üß† Key Contributions (Detailed)

#### 1. Zero-Shot CIR Framework (**ZS-CIR**)  

![Image](https://github.com/user-attachments/assets/4973487e-1cc9-4000-a59f-dc9084e55a3b)

- **Problem**  
  - Previous datasets like CIRR and FashionIQ required **fine-tuning on training data**  
  - Performance dropped drastically on unseen domains or categories  

- **Core Idea**  
  - Incorporate Textual Inversion into CIR  
  - Convert reference images into **pseudo-word tokens (embeddings)**, treated like ‚Äúwords‚Äù  
  - Combine with modification text ‚Üí final **image+text composed query**  

- **Advantages**  
  - Enables retrieval without additional training (Zero-Shot)  
  - Domain-agnostic: works across fashion, real-life, and beyond  
  - Simple inference pipeline with efficient retrieval  

---

#### 2. CIRCO Dataset  

> CIRCO is not only the first to enable **zero-shot composed retrieval**,  
> but also advances CIR evaluation by providing:  
> - **Multiple ground truths**  
> - **Real-world images**  
> - **Complex queries**  
> ‚Üí raising the evaluation quality of CIR benchmarks  

![Image](https://github.com/user-attachments/assets/4285a3a1-18ba-4d4f-9dc5-e8e43488940e)  

- **Realism**  
  - Built on MS-COCO 2017  
  - Avoids domain bias (e.g., fashion-only) and covers diverse scenes, objects, and contexts  

- **Object-Centric**  
  - Queries reflect changes in specific objects, not only the global scene  
  - Example: ‚ÄúChange the car in the image to red, and replace the dog with a cat.‚Äù  

- **Multiple Ground Truths**  
  - On average, 4.53 target images per query  
  - Overcomes the single-ground-truth limitation of FashionIQ  
  - Mitigates False Negative issue ‚Üí fairer evaluation of retrieval systems  

- **Complex Queries**  
  - Includes not only attribute modifications but also **multi-object and relational changes**  
  - Beyond ‚Äúcolor change,‚Äù includes cases like:  
    - ‚ÄúA person sitting becomes another person standing‚Äù  
    - ‚ÄúReplace the dog with a cat‚Äù  

---

#### 3. Benchmark & Zero-Shot Performance  

![Image](https://github.com/user-attachments/assets/51f8721c-609a-4d2b-aa81-c147cf035d21)

- **Evaluation Datasets**: CIRR, FashionIQ, CIRCO  

- **FashionIQ (Validation Set)**  
  - **SEARLE (B/32)**: Avg R@10 = 22.89, R@50 = 42.53  
  - **SEARLE-XL (L/14)**: Avg R@10 = 25.56, R@50 = 46.23  
  - In some cases, plain SEARLE outperformed the optimized OTI version  

- **CIRR (Test Set)**  
  - **SEARLE (B/32)**: Recall@1 = 24.27, Recall@5 = 53.22, Recall@10 = 66.82  
  - **SEARLE-XL (L/14)**: Recall@1 = 24.22, Recall@5 = 52.48, Recall@10 = 66.29  
  - SEARLE achieved better results than OTI-trained prompts in some settings  
  - Subset Recall: SEARLE-XL reached **Recall@3 = 88.19**, achieving SOTA-level performance  

- **Significance**  
  - Even with a pure Zero-Shot setup, SEARLE achieved **competitive performance compared to training-based approaches**  
  - On CIRR, Recall@1 exceeded 24%, proving **high-quality retrieval without training**  
  - This milestone validated the feasibility of Zero-Shot CIR, laying the groundwork for follow-up works such as **CIReVL (ICLR 2024)** and **OSrCIR (CVPR 2025)**  

---

### üß© Conclusion

> **CIRCO (ICCV 2023)** introduced **Textual Inversion-based Zero-Shot CIR (ZS-CIR / SEARLE)**  
> and established a new, more realistic dataset (**CIRCO**).  
> This work marked the evolution of CIR from **‚Äútraining-based + single ground-truth‚Äù**  
> to **‚Äúzero-shot + multiple ground-truths + complex queries.‚Äù**
